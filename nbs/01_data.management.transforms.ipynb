{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.management.transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management Transforms\n",
    "\n",
    "> This module contains all of the transforms that can be applied to code related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "\n",
    "from fast_trees.core import FastParser\n",
    "from random import shuffle\n",
    "from typing import Callable, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def filter_df(\n",
    "    df: pd.DataFrame, filter_fn: Callable, col: str, n: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter the given pandas dataframe using the given transformation.\n",
    "\n",
    "    :param df: the dataframe containing each method to be transformed\n",
    "    :param filter_fn: the filter function that will be applied to each method in the dataframe\n",
    "    :param col: the column to get the examples from\n",
    "    :param n: the number of examples to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a modified dataframe with the rows filtered\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    df = df.iloc[:n].copy()\n",
    "    df = df[df[col].apply(filter_fn)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def transform_df(\n",
    "    df: pd.DataFrame, transform_fn: Callable, col: str, n: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform the given pandas dataframe using the given transformation.\n",
    "\n",
    "    :param df: the dataframe containing each method to be transformed\n",
    "    :param transform_fn: the transformation that will be applied to each example in the dataframe\n",
    "    :param col: the column to get the examples from\n",
    "    :param n: the number of examples to evaluate. If none, the entire dataframe will be used\n",
    "    :returns: returns a modified dataframe with the examples transformed\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = len(df)\n",
    "\n",
    "    df = df.iloc[:n].copy()\n",
    "    df[col] = df[col].apply(transform_fn)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Preserving\n",
    "Semantic preserving transformations do not change the functionality or meaning of a piece of data, e.g., comment removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_ascii(example: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given example contains only ASCII characters. From https://stackoverflow.com/a/27084708/5768407.\n",
    "\n",
    "    :param example: the data to verify contains only ASCII characters\n",
    "    :returns: returns a boolean representing whether or not the given example contains only ASCII characters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        example.encode(encoding=\"utf-8\").decode(\"ascii\")\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst\n",
    "df_fake = pd.DataFrame([\"this is a test\", \"भारत test\"], columns=[\"code\"])\n",
    "\n",
    "NON_ASCII_DF = pd.DataFrame([\"this is a test\"], columns=[\"code\"])\n",
    "df_non_ascii = filter_df(df_fake, is_ascii, \"code\")\n",
    "\n",
    "assert (NON_ASCII_DF == df_non_ascii).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def remove_comments(parser: FastParser, code: str) -> str:\n",
    "    inline_comments = parser.get_method_inline_comments(code)\n",
    "    for c in inline_comments:\n",
    "        code = code.replace(c, \"\")\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already exists, continuing.\n"
     ]
    }
   ],
   "source": [
    "# tst\n",
    "df_fake = pd.DataFrame(\n",
    "    [\n",
    "        \"\"\"\\\n",
    "public static void main(String[] args) {\n",
    "    // inline comment\n",
    "    System.out.println(\"Hello, world!\")\n",
    "    /**\n",
    "        multi-line inline comment\n",
    "    */\n",
    "}\"\"\"\n",
    "    ],\n",
    "    columns=[\"code\"],\n",
    ")\n",
    "\n",
    "NO_COMMENTS_DF = pd.DataFrame(\n",
    "    [\n",
    "        \"\"\"\\\n",
    "public static void main(String[] args) {\n",
    "    \n",
    "    System.out.println(\"Hello, world!\")\n",
    "    \n",
    "}\"\"\"\n",
    "    ],\n",
    "    columns=[\"code\"],\n",
    ")\n",
    "\n",
    "parser = FastParser(\"java\")\n",
    "df_no_comments = transform_df(\n",
    "    df_fake, lambda example: remove_comments(parser, example), \"code\"\n",
    ")\n",
    "\n",
    "assert (NO_COMMENTS_DF == df_no_comments).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Semantic Preserving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def randomize_lines(example: str) -> str:\n",
    "    \"\"\"\n",
    "    Randomize the lines in a given example.\n",
    "\n",
    "    :param example: the example to have its lines randomized\n",
    "    :returns: returns the method with its lines randomized\n",
    "    \"\"\"\n",
    "    example = example.split(\"\\n\")\n",
    "    shuffle(example)\n",
    "\n",
    "    return \"\\n\".join(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already exists, continuing.\n"
     ]
    }
   ],
   "source": [
    "# tst\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "df_fake = pd.DataFrame(\n",
    "    [\n",
    "        \"\"\"\\\n",
    "public static void main(String[] args) {\n",
    "    System.out.println(\"Hello, world!\")\n",
    "}\"\"\"\n",
    "    ],\n",
    "    columns=[\"code\"],\n",
    ")\n",
    "\n",
    "RANDOM_LINES_DF = pd.DataFrame(\n",
    "    [\n",
    "        \"\"\"\\\n",
    "    System.out.println(\"Hello, world!\")\n",
    "public static void main(String[] args) {\n",
    "}\"\"\"\n",
    "    ],\n",
    "    columns=[\"code\"],\n",
    ")\n",
    "\n",
    "parser = FastParser(\"java\")\n",
    "df_random_lines = transform_df(df_fake, randomize_lines, \"code\")\n",
    "# df_random_lines.code.values[0]\n",
    "\n",
    "assert (RANDOM_LINES_DF == df_random_lines).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def randomize_tokens(example: str) -> str:\n",
    "    \"\"\"\n",
    "    Randomize the tokens in a given method.\n",
    "\n",
    "    :param mthd: the method to have its code tokens randomized\n",
    "    :returns: returns the method with its code tokens randomized\n",
    "    \"\"\"\n",
    "    example = example.split(\" \")\n",
    "    shuffle(example)\n",
    "\n",
    "    return \" \".join(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already exists, continuing.\n"
     ]
    }
   ],
   "source": [
    "# tst\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "df_fake = pd.DataFrame(\n",
    "    [\n",
    "        \"\"\"\\\n",
    "public static void main(String[] args) {\n",
    "    System.out.println(\"Hello, world!\")\n",
    "}\"\"\"\n",
    "    ],\n",
    "    columns=[\"code\"],\n",
    ")\n",
    "\n",
    "RANDOM_TOKENS_DF = pd.DataFrame(\n",
    "    [\n",
    "        \"\"\"\\\n",
    " main(String[] void  {\n",
    "  System.out.println(\"Hello, args) public static world!\")\n",
    "}\"\"\"\n",
    "    ],\n",
    "    columns=[\"code\"],\n",
    ")\n",
    "\n",
    "parser = FastParser(\"java\")\n",
    "df_random_tokens = transform_df(df_fake, randomize_tokens, \"code\")\n",
    "\n",
    "assert (RANDOM_TOKENS_DF == df_random_tokens).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "Composes multiple transformations to apply to a set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
