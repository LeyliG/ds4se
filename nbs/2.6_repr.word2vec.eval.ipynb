{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp repr.word2vec.eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Word2Vec for SE\n",
    "\n",
    "> This module is dedicated to evaluate word2vec training with a proxy dataset:\n",
    ">\n",
    "> Author: @danaderp April 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Imports\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from itertools import product \n",
    "from random import sample \n",
    "import functools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyemd\n",
      "  Downloading pyemd-0.5.1.tar.gz (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 921 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pyemd) (1.17.1)\n",
      "Building wheels for collected packages: pyemd\n",
      "  Building wheel for pyemd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyemd: filename=pyemd-0.5.1-cp36-cp36m-linux_x86_64.whl size=377295 sha256=acbaa45233923d2a3bb706ba1aad8d5fb2acfc2100aa6548c0fb643162c6f1b0\n",
      "  Stored in directory: /root/.cache/pip/wheels/f9/f0/23/aefbdde40e915c67830ebecb55be2344a8b6e95fe3ce3ccf96\n",
      "Successfully built pyemd\n",
      "Installing collected packages: pyemd\n",
      "Successfully installed pyemd-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 15:31:14,292 : INFO : loading Word2Vec object from word2vec_libest.model\n",
      "2020-04-15 15:31:14,343 : INFO : loading wv recursively from word2vec_libest.model.wv.* with mmap=None\n",
      "2020-04-15 15:31:14,345 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-04-15 15:31:14,350 : INFO : loading vocabulary recursively from word2vec_libest.model.vocabulary.* with mmap=None\n",
      "2020-04-15 15:31:14,352 : INFO : loading trainables recursively from word2vec_libest.model.trainables.* with mmap=None\n",
      "2020-04-15 15:31:14,354 : INFO : setting ignored attribute cum_table to None\n",
      "2020-04-15 15:31:14,356 : INFO : loaded word2vec_libest.model\n"
     ]
    }
   ],
   "source": [
    "new_model = gensim.models.Word2Vec.load(\"word2vec_libest.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 21:40:51,447 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "new_model.init_sims(replace=True)  # Normalizes the vectors in the word2vec class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>requir http uri control est server must suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>requir server side key generat respons request...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>requir http base client authent est server may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>requir csr attribut request est client request...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>requir server side key generat est client may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ids  \\\n",
       "0  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "1  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "2  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "3  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "4  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "\n",
       "                                                text  \n",
       "0  requir http uri control est server must suppor...  \n",
       "1  requir server side key generat respons request...  \n",
       "2  requir http base client authent est server may...  \n",
       "3  requir csr attribut request est client request...  \n",
       "4  requir server side key generat est client may ...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_path = '/tf/main/benchmarking/traceability/testbeds/nltk/[libest-pre-req].csv'\n",
    "target_path = '/tf/main/benchmarking/traceability/testbeds/nltk/[libest-pre-tc].csv'\n",
    "df_source = pd.read_csv(source_path, names=['ids', 'text'], header=None, sep=' ')\n",
    "df_source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_data/LibEST_semeru_format/test/us903.c</td>\n",
       "      <td>unit test user stori server simpl enrol august...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_data/LibEST_semeru_format/test/us3496.c</td>\n",
       "      <td>unit test uri path segment extens support marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_data/LibEST_semeru_format/test/us899.c</td>\n",
       "      <td>unit test user stori client simpl enrol septem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_data/LibEST_semeru_format/test/us4020.c</td>\n",
       "      <td>unit test user stori unit test client proxi mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_data/LibEST_semeru_format/test/us897.c</td>\n",
       "      <td>unit test user stori client cacert june copyri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ids  \\\n",
       "0   test_data/LibEST_semeru_format/test/us903.c   \n",
       "1  test_data/LibEST_semeru_format/test/us3496.c   \n",
       "2   test_data/LibEST_semeru_format/test/us899.c   \n",
       "3  test_data/LibEST_semeru_format/test/us4020.c   \n",
       "4   test_data/LibEST_semeru_format/test/us897.c   \n",
       "\n",
       "                                                text  \n",
       "0  unit test user stori server simpl enrol august...  \n",
       "1  unit test uri path segment extens support marc...  \n",
       "2  unit test user stori client simpl enrol septem...  \n",
       "3  unit test user stori unit test client proxi mo...  \n",
       "4  unit test user stori client cacert june copyri...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv(target_path, names=['ids', 'text'], header=None, sep=' ')\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idss = df_source['ids'][0]\n",
    "idss = df_source['ids'] == idss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['requir',\n",
       " 'http',\n",
       " 'uri',\n",
       " 'control',\n",
       " 'est',\n",
       " 'server',\n",
       " 'must',\n",
       " 'support',\n",
       " 'use',\n",
       " 'path',\n",
       " 'prefix',\n",
       " 'well',\n",
       " 'known',\n",
       " 'defin',\n",
       " 'rfc',\n",
       " 'regist',\n",
       " 'name',\n",
       " 'est',\n",
       " 'thus',\n",
       " 'valid',\n",
       " 'est',\n",
       " 'server',\n",
       " 'uri',\n",
       " 'path',\n",
       " 'begin',\n",
       " 'https',\n",
       " 'www',\n",
       " 'exampl',\n",
       " 'com',\n",
       " 'well',\n",
       " 'known',\n",
       " 'est',\n",
       " 'est',\n",
       " 'oper',\n",
       " 'indic',\n",
       " 'path',\n",
       " 'suffix',\n",
       " 'indic',\n",
       " 'intend',\n",
       " 'oper',\n",
       " 'oper',\n",
       " 'correspond',\n",
       " 'uri',\n",
       " 'oper',\n",
       " 'oper',\n",
       " 'path',\n",
       " 'detail',\n",
       " 'distribut',\n",
       " 'cacert',\n",
       " 'section',\n",
       " 'certif',\n",
       " 'must',\n",
       " 'enrol',\n",
       " 'simpleenrol',\n",
       " 'section',\n",
       " 'client',\n",
       " 'must',\n",
       " 'enrol',\n",
       " 'simplereenrol',\n",
       " 'section',\n",
       " 'client',\n",
       " 'must',\n",
       " 'full',\n",
       " 'cmc',\n",
       " 'option',\n",
       " 'fullcmc',\n",
       " 'section',\n",
       " 'server',\n",
       " 'side',\n",
       " 'key',\n",
       " 'serverkeygen',\n",
       " 'section',\n",
       " 'generat',\n",
       " 'option',\n",
       " 'csr',\n",
       " 'attribut',\n",
       " 'csrattr',\n",
       " 'section',\n",
       " 'option',\n",
       " 'figur',\n",
       " 'oper',\n",
       " 'path',\n",
       " 'figur',\n",
       " 'append',\n",
       " 'path',\n",
       " 'prefix',\n",
       " 'form',\n",
       " 'uri',\n",
       " 'use',\n",
       " 'http',\n",
       " 'get',\n",
       " 'post',\n",
       " 'perform',\n",
       " 'desir',\n",
       " 'est',\n",
       " 'oper',\n",
       " 'exampl',\n",
       " 'valid',\n",
       " 'uri',\n",
       " 'absolut',\n",
       " 'path',\n",
       " 'cacert',\n",
       " 'oper',\n",
       " '\"/.',\n",
       " 'well',\n",
       " 'known',\n",
       " 'est',\n",
       " 'cacert',\n",
       " 'retriev',\n",
       " 'certif',\n",
       " 'est',\n",
       " 'client',\n",
       " 'would',\n",
       " 'use',\n",
       " 'follow',\n",
       " 'http',\n",
       " 'request',\n",
       " 'line',\n",
       " 'get',\n",
       " 'well',\n",
       " 'known',\n",
       " 'est',\n",
       " 'cacert',\n",
       " 'http',\n",
       " 'likewis',\n",
       " 'request',\n",
       " 'new',\n",
       " 'certif',\n",
       " 'exampl',\n",
       " 'scheme',\n",
       " 'est',\n",
       " 'client',\n",
       " 'would',\n",
       " 'use',\n",
       " 'follow',\n",
       " 'request',\n",
       " 'line',\n",
       " 'post',\n",
       " 'well',\n",
       " 'known',\n",
       " 'est',\n",
       " 'simpleenrol',\n",
       " 'http',\n",
       " 'use',\n",
       " 'distinct',\n",
       " 'oper',\n",
       " 'path',\n",
       " 'simplifi',\n",
       " 'implement',\n",
       " 'server',\n",
       " 'perform',\n",
       " 'client',\n",
       " 'authent',\n",
       " 'distribut',\n",
       " 'cacert',\n",
       " 'respons',\n",
       " 'est',\n",
       " 'server',\n",
       " 'may',\n",
       " 'provid',\n",
       " 'servic',\n",
       " 'multipl',\n",
       " 'cas',\n",
       " 'indic',\n",
       " 'option',\n",
       " 'addit',\n",
       " 'path',\n",
       " 'segment',\n",
       " 'regist',\n",
       " 'applic',\n",
       " 'name',\n",
       " 'oper',\n",
       " 'path',\n",
       " 'avoid',\n",
       " 'conflict',\n",
       " 'label',\n",
       " 'must',\n",
       " 'defin',\n",
       " 'oper',\n",
       " 'path',\n",
       " 'segment',\n",
       " 'est',\n",
       " 'server',\n",
       " 'must',\n",
       " 'provid',\n",
       " 'servic',\n",
       " 'regardless',\n",
       " 'whether',\n",
       " 'addit',\n",
       " 'path',\n",
       " 'segment',\n",
       " 'present',\n",
       " 'follow',\n",
       " 'three',\n",
       " 'exampl',\n",
       " 'valid',\n",
       " 'uri',\n",
       " 'https',\n",
       " '://',\n",
       " 'www',\n",
       " 'exampl',\n",
       " 'com',\n",
       " 'well',\n",
       " 'known',\n",
       " 'est',\n",
       " 'cacert',\n",
       " 'https',\n",
       " '://',\n",
       " 'www',\n",
       " 'exampl',\n",
       " 'com',\n",
       " 'well',\n",
       " 'known',\n",
       " 'est',\n",
       " 'arbitrari',\n",
       " 'label1',\n",
       " 'cacert',\n",
       " 'https',\n",
       " '://',\n",
       " 'www',\n",
       " 'exampl',\n",
       " 'com',\n",
       " 'well',\n",
       " 'known',\n",
       " 'est',\n",
       " 'arbitrari',\n",
       " 'label2',\n",
       " 'cacert',\n",
       " 'specif',\n",
       " 'distinct',\n",
       " 'enrol',\n",
       " 'renew',\n",
       " 'rekey',\n",
       " 'explicit',\n",
       " 'indic',\n",
       " 'http',\n",
       " 'uri',\n",
       " 'request',\n",
       " 'fullcmc',\n",
       " 'oper',\n",
       " 'cmc',\n",
       " 'rfc5272',\n",
       " 'use',\n",
       " 'messag',\n",
       " 'certif',\n",
       " 'renew',\n",
       " 'certif',\n",
       " 'rekey',\n",
       " 'est',\n",
       " 'server',\n",
       " 'provid',\n",
       " 'addit',\n",
       " 'servic',\n",
       " 'use',\n",
       " 'uri']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_source[idss]['text'])[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>requir http uri control est server must suppor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ids  \\\n",
       "0  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "\n",
       "                                                text  \n",
       "0  requir http uri control est server must suppor...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source[df_source['ids'] == link[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samplingLinks(corpusI, corpusII, samples):\n",
    "    links = list(product(list(corpusI['ids']),list(corpusII['ids'])))\n",
    "    return sample(links,samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = samplingLinks(df_source,df_target,20)\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = list(product(list(df_source['ids']),list(df_target['ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092 (52, 2) (21, 2)\n"
     ]
    }
   ],
   "source": [
    "print(len(links), df_source.shape, df_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeWMDArtificts(corpusI, corpusII):\n",
    "    #links = samplingLinks(corpusI,corpusII,100)\n",
    "    links = list(product(list(corpusI['ids']),list(corpusII['ids'])))\n",
    "    docs = [(link[0], link[1], \n",
    "             new_model.wv.wmdistance(list(corpusI[corpusI['ids'] == link[0]]['text'])[0].split(), \n",
    "             list(corpusII[corpusII['ids'] == link[1]]['text'])[0].split() ) \n",
    "             ) for link in links]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:33:14,069 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:14,074 : INFO : built Dictionary(808 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2178 corpus positions)\n",
      "2020-04-15 23:33:29,314 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:29,317 : INFO : built Dictionary(477 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 1968 corpus positions)\n",
      "2020-04-15 23:33:31,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:31,355 : INFO : built Dictionary(752 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 3784 corpus positions)\n",
      "2020-04-15 23:33:44,883 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:44,885 : INFO : built Dictionary(379 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2354 corpus positions)\n",
      "2020-04-15 23:33:46,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:46,621 : INFO : built Dictionary(361 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2860 corpus positions)\n",
      "2020-04-15 23:33:47,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:47,607 : INFO : built Dictionary(505 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 1844 corpus positions)\n",
      "2020-04-15 23:33:50,887 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:50,889 : INFO : built Dictionary(496 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2927 corpus positions)\n",
      "2020-04-15 23:33:53,243 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:53,245 : INFO : built Dictionary(374 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 1091 corpus positions)\n",
      "2020-04-15 23:33:54,957 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:54,959 : INFO : built Dictionary(589 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 3081 corpus positions)\n",
      "2020-04-15 23:33:58,320 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:58,322 : INFO : built Dictionary(360 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 1711 corpus positions)\n",
      "2020-04-15 23:33:59,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:33:59,267 : INFO : built Dictionary(455 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2904 corpus positions)\n",
      "2020-04-15 23:34:00,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:34:00,795 : INFO : built Dictionary(720 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2637 corpus positions)\n",
      "2020-04-15 23:34:09,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:34:09,609 : INFO : built Dictionary(1185 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 3193 corpus positions)\n",
      "2020-04-15 23:34:48,737 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:34:48,740 : INFO : built Dictionary(809 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2131 corpus positions)\n",
      "2020-04-15 23:35:03,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:35:03,958 : INFO : built Dictionary(359 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 1346 corpus positions)\n",
      "2020-04-15 23:35:05,100 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:35:05,103 : INFO : built Dictionary(537 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2491 corpus positions)\n",
      "2020-04-15 23:35:09,445 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:35:09,447 : INFO : built Dictionary(674 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 1292 corpus positions)\n",
      "2020-04-15 23:35:17,731 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:35:17,733 : INFO : built Dictionary(474 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2403 corpus positions)\n",
      "2020-04-15 23:35:19,544 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:35:19,548 : INFO : built Dictionary(1169 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2711 corpus positions)\n",
      "2020-04-15 23:36:01,339 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:01,342 : INFO : built Dictionary(576 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2719 corpus positions)\n",
      "2020-04-15 23:36:05,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:05,259 : INFO : built Dictionary(491 unique tokens: ['\"/.', '://', 'absolut', 'addit', 'append']...) from 2 documents (total 2694 corpus positions)\n",
      "2020-04-15 23:36:08,657 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:08,660 : INFO : built Dictionary(833 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2344 corpus positions)\n",
      "2020-04-15 23:36:28,017 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:28,023 : INFO : built Dictionary(502 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2134 corpus positions)\n",
      "2020-04-15 23:36:30,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:30,988 : INFO : built Dictionary(769 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 3950 corpus positions)\n",
      "2020-04-15 23:36:48,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:48,164 : INFO : built Dictionary(401 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2520 corpus positions)\n",
      "2020-04-15 23:36:50,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:50,579 : INFO : built Dictionary(383 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 3026 corpus positions)\n",
      "2020-04-15 23:36:51,889 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:51,891 : INFO : built Dictionary(529 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2010 corpus positions)\n",
      "2020-04-15 23:36:55,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:55,746 : INFO : built Dictionary(518 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 3093 corpus positions)\n",
      "2020-04-15 23:36:59,093 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:36:59,095 : INFO : built Dictionary(395 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 1257 corpus positions)\n",
      "2020-04-15 23:37:01,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:37:01,287 : INFO : built Dictionary(606 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 3247 corpus positions)\n",
      "2020-04-15 23:37:06,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:37:06,103 : INFO : built Dictionary(385 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 1877 corpus positions)\n",
      "2020-04-15 23:37:07,357 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:37:07,360 : INFO : built Dictionary(472 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 3070 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:37:09,520 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:37:09,525 : INFO : built Dictionary(749 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2803 corpus positions)\n",
      "2020-04-15 23:37:20,462 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:37:20,466 : INFO : built Dictionary(1206 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 3359 corpus positions)\n",
      "2020-04-15 23:38:06,450 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:38:06,453 : INFO : built Dictionary(833 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2297 corpus positions)\n",
      "2020-04-15 23:38:25,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:38:25,303 : INFO : built Dictionary(380 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 1512 corpus positions)\n",
      "2020-04-15 23:38:26,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:38:26,703 : INFO : built Dictionary(554 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2657 corpus positions)\n",
      "2020-04-15 23:38:32,993 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:38:32,997 : INFO : built Dictionary(696 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 1458 corpus positions)\n",
      "2020-04-15 23:38:42,862 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:38:42,865 : INFO : built Dictionary(489 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2569 corpus positions)\n",
      "2020-04-15 23:38:45,333 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:38:45,341 : INFO : built Dictionary(1190 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2877 corpus positions)\n",
      "2020-04-15 23:39:29,737 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:39:29,740 : INFO : built Dictionary(597 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2885 corpus positions)\n",
      "2020-04-15 23:39:34,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:39:34,737 : INFO : built Dictionary(511 unique tokens: ['accompani', 'addit', 'agre', 'agreement', 'algorithm']...) from 2 documents (total 2860 corpus positions)\n",
      "2020-04-15 23:39:39,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:39:39,540 : INFO : built Dictionary(800 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2128 corpus positions)\n",
      "2020-04-15 23:39:51,657 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:39:51,661 : INFO : built Dictionary(474 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 1918 corpus positions)\n",
      "2020-04-15 23:39:53,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:39:53,918 : INFO : built Dictionary(744 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 3734 corpus positions)\n",
      "2020-04-15 23:40:02,504 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:02,506 : INFO : built Dictionary(368 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2304 corpus positions)\n",
      "2020-04-15 23:40:04,052 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:04,057 : INFO : built Dictionary(353 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2810 corpus positions)\n",
      "2020-04-15 23:40:04,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:04,957 : INFO : built Dictionary(495 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 1794 corpus positions)\n",
      "2020-04-15 23:40:07,341 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:07,347 : INFO : built Dictionary(488 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2877 corpus positions)\n",
      "2020-04-15 23:40:09,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:09,577 : INFO : built Dictionary(366 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 1041 corpus positions)\n",
      "2020-04-15 23:40:11,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:11,116 : INFO : built Dictionary(573 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 3031 corpus positions)\n",
      "2020-04-15 23:40:14,442 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:14,446 : INFO : built Dictionary(353 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 1661 corpus positions)\n",
      "2020-04-15 23:40:15,556 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:15,563 : INFO : built Dictionary(447 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2854 corpus positions)\n",
      "2020-04-15 23:40:17,044 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:17,052 : INFO : built Dictionary(724 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2587 corpus positions)\n",
      "2020-04-15 23:40:24,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:24,622 : INFO : built Dictionary(1180 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 3143 corpus positions)\n",
      "2020-04-15 23:40:57,558 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:40:57,560 : INFO : built Dictionary(799 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2081 corpus positions)\n",
      "2020-04-15 23:41:09,795 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:09,803 : INFO : built Dictionary(350 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 1296 corpus positions)\n",
      "2020-04-15 23:41:10,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:10,900 : INFO : built Dictionary(518 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2441 corpus positions)\n",
      "2020-04-15 23:41:14,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:14,280 : INFO : built Dictionary(656 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 1242 corpus positions)\n",
      "2020-04-15 23:41:19,336 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:19,339 : INFO : built Dictionary(460 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2353 corpus positions)\n",
      "2020-04-15 23:41:20,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:21,003 : INFO : built Dictionary(1162 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2661 corpus positions)\n",
      "2020-04-15 23:41:50,123 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:50,129 : INFO : built Dictionary(562 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2669 corpus positions)\n",
      "2020-04-15 23:41:53,493 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:53,500 : INFO : built Dictionary(481 unique tokens: ['addit', 'anon', 'appropri', 'aris', 'associ']...) from 2 documents (total 2644 corpus positions)\n",
      "2020-04-15 23:41:56,602 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:56,606 : INFO : built Dictionary(754 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 1943 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:41:57,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:57,539 : INFO : built Dictionary(421 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 1733 corpus positions)\n",
      "2020-04-15 23:41:57,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:57,792 : INFO : built Dictionary(701 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 3549 corpus positions)\n",
      "2020-04-15 23:41:58,720 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:58,726 : INFO : built Dictionary(320 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2119 corpus positions)\n",
      "2020-04-15 23:41:58,931 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:58,933 : INFO : built Dictionary(302 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2625 corpus positions)\n",
      "2020-04-15 23:41:59,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:59,069 : INFO : built Dictionary(449 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 1609 corpus positions)\n",
      "2020-04-15 23:41:59,406 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:59,408 : INFO : built Dictionary(431 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2692 corpus positions)\n",
      "2020-04-15 23:41:59,660 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:59,662 : INFO : built Dictionary(307 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 856 corpus positions)\n",
      "2020-04-15 23:41:59,866 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:41:59,873 : INFO : built Dictionary(531 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2846 corpus positions)\n",
      "2020-04-15 23:42:00,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:00,234 : INFO : built Dictionary(299 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 1476 corpus positions)\n",
      "2020-04-15 23:42:00,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:00,379 : INFO : built Dictionary(396 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2669 corpus positions)\n",
      "2020-04-15 23:42:00,595 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:00,604 : INFO : built Dictionary(668 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2402 corpus positions)\n",
      "2020-04-15 23:42:01,192 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:01,196 : INFO : built Dictionary(1138 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2958 corpus positions)\n",
      "2020-04-15 23:42:02,961 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:02,968 : INFO : built Dictionary(753 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 1896 corpus positions)\n",
      "2020-04-15 23:42:03,931 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:03,934 : INFO : built Dictionary(298 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 1111 corpus positions)\n",
      "2020-04-15 23:42:04,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:04,081 : INFO : built Dictionary(477 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2256 corpus positions)\n",
      "2020-04-15 23:42:04,429 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:04,431 : INFO : built Dictionary(613 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 1057 corpus positions)\n",
      "2020-04-15 23:42:05,013 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:05,019 : INFO : built Dictionary(412 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2168 corpus positions)\n",
      "2020-04-15 23:42:05,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:05,256 : INFO : built Dictionary(1117 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2476 corpus positions)\n",
      "2020-04-15 23:42:06,943 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:06,946 : INFO : built Dictionary(516 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2484 corpus positions)\n",
      "2020-04-15 23:42:07,308 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:07,315 : INFO : built Dictionary(424 unique tokens: ['attribut', 'client', 'csr', 'csrattr', 'desir']...) from 2 documents (total 2459 corpus positions)\n",
      "2020-04-15 23:42:07,684 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:07,687 : INFO : built Dictionary(786 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2081 corpus positions)\n",
      "2020-04-15 23:42:13,482 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:13,485 : INFO : built Dictionary(454 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 1871 corpus positions)\n",
      "2020-04-15 23:42:15,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:15,116 : INFO : built Dictionary(729 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 3687 corpus positions)\n",
      "2020-04-15 23:42:20,834 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:20,836 : INFO : built Dictionary(353 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2257 corpus positions)\n",
      "2020-04-15 23:42:22,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:22,028 : INFO : built Dictionary(335 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2763 corpus positions)\n",
      "2020-04-15 23:42:22,724 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:22,726 : INFO : built Dictionary(481 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 1747 corpus positions)\n",
      "2020-04-15 23:42:24,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:24,584 : INFO : built Dictionary(470 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2830 corpus positions)\n",
      "2020-04-15 23:42:26,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:26,095 : INFO : built Dictionary(347 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 994 corpus positions)\n",
      "2020-04-15 23:42:27,124 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:27,129 : INFO : built Dictionary(562 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2984 corpus positions)\n",
      "2020-04-15 23:42:29,385 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:29,391 : INFO : built Dictionary(337 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 1614 corpus positions)\n",
      "2020-04-15 23:42:30,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:30,178 : INFO : built Dictionary(428 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2807 corpus positions)\n",
      "2020-04-15 23:42:31,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:31,203 : INFO : built Dictionary(703 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2540 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:42:35,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:35,677 : INFO : built Dictionary(1164 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 3096 corpus positions)\n",
      "2020-04-15 23:42:55,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:42:55,584 : INFO : built Dictionary(785 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2034 corpus positions)\n",
      "2020-04-15 23:43:01,801 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:01,804 : INFO : built Dictionary(330 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 1249 corpus positions)\n",
      "2020-04-15 23:43:02,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:02,547 : INFO : built Dictionary(509 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2394 corpus positions)\n",
      "2020-04-15 23:43:04,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:04,797 : INFO : built Dictionary(649 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 1195 corpus positions)\n",
      "2020-04-15 23:43:08,411 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:08,413 : INFO : built Dictionary(444 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2306 corpus positions)\n",
      "2020-04-15 23:43:09,626 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:09,629 : INFO : built Dictionary(1146 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2614 corpus positions)\n",
      "2020-04-15 23:43:29,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:29,220 : INFO : built Dictionary(551 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2622 corpus positions)\n",
      "2020-04-15 23:43:31,760 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:31,767 : INFO : built Dictionary(463 unique tokens: ['addit', 'algorithm', 'appli', 'archiv', 'associ']...) from 2 documents (total 2597 corpus positions)\n",
      "2020-04-15 23:43:33,139 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:33,141 : INFO : built Dictionary(785 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2021 corpus positions)\n",
      "2020-04-15 23:43:39,696 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:39,703 : INFO : built Dictionary(458 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 1811 corpus positions)\n",
      "2020-04-15 23:43:41,041 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:41,045 : INFO : built Dictionary(731 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 3627 corpus positions)\n",
      "2020-04-15 23:43:46,596 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:46,598 : INFO : built Dictionary(351 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2197 corpus positions)\n",
      "2020-04-15 23:43:47,610 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:47,619 : INFO : built Dictionary(336 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2703 corpus positions)\n",
      "2020-04-15 23:43:48,228 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:48,230 : INFO : built Dictionary(481 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 1687 corpus positions)\n",
      "2020-04-15 23:43:50,104 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:50,107 : INFO : built Dictionary(471 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2770 corpus positions)\n",
      "2020-04-15 23:43:51,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:51,504 : INFO : built Dictionary(346 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 934 corpus positions)\n",
      "2020-04-15 23:43:52,569 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:52,576 : INFO : built Dictionary(559 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2924 corpus positions)\n",
      "2020-04-15 23:43:54,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:54,358 : INFO : built Dictionary(335 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 1554 corpus positions)\n",
      "2020-04-15 23:43:54,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:54,983 : INFO : built Dictionary(425 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2747 corpus positions)\n",
      "2020-04-15 23:43:55,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:43:55,902 : INFO : built Dictionary(708 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2480 corpus positions)\n",
      "2020-04-15 23:44:00,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:00,068 : INFO : built Dictionary(1168 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 3036 corpus positions)\n",
      "2020-04-15 23:44:22,460 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:22,463 : INFO : built Dictionary(785 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 1974 corpus positions)\n",
      "2020-04-15 23:44:28,388 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:28,389 : INFO : built Dictionary(335 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 1189 corpus positions)\n",
      "2020-04-15 23:44:29,058 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:29,064 : INFO : built Dictionary(506 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2334 corpus positions)\n",
      "2020-04-15 23:44:31,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:31,303 : INFO : built Dictionary(646 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 1135 corpus positions)\n",
      "2020-04-15 23:44:35,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:35,399 : INFO : built Dictionary(444 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2246 corpus positions)\n",
      "2020-04-15 23:44:36,494 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:36,500 : INFO : built Dictionary(1152 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2554 corpus positions)\n",
      "2020-04-15 23:44:59,168 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:44:59,173 : INFO : built Dictionary(546 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2562 corpus positions)\n",
      "2020-04-15 23:45:01,290 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:01,297 : INFO : built Dictionary(464 unique tokens: ['accept', 'access', 'act', 'addit', 'alway']...) from 2 documents (total 2537 corpus positions)\n",
      "2020-04-15 23:45:03,481 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:03,484 : INFO : built Dictionary(776 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 1988 corpus positions)\n",
      "2020-04-15 23:45:06,574 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:06,576 : INFO : built Dictionary(446 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 1778 corpus positions)\n",
      "2020-04-15 23:45:07,388 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:45:07,396 : INFO : built Dictionary(718 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 3594 corpus positions)\n",
      "2020-04-15 23:45:10,402 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:10,404 : INFO : built Dictionary(342 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2164 corpus positions)\n",
      "2020-04-15 23:45:11,040 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:11,042 : INFO : built Dictionary(322 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2670 corpus positions)\n",
      "2020-04-15 23:45:11,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:11,421 : INFO : built Dictionary(471 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 1654 corpus positions)\n",
      "2020-04-15 23:45:12,476 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:12,478 : INFO : built Dictionary(455 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2737 corpus positions)\n",
      "2020-04-15 23:45:13,249 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:13,251 : INFO : built Dictionary(330 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 901 corpus positions)\n",
      "2020-04-15 23:45:13,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:13,849 : INFO : built Dictionary(548 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2891 corpus positions)\n",
      "2020-04-15 23:45:14,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:14,848 : INFO : built Dictionary(322 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 1521 corpus positions)\n",
      "2020-04-15 23:45:15,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:15,260 : INFO : built Dictionary(415 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2714 corpus positions)\n",
      "2020-04-15 23:45:15,840 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:15,842 : INFO : built Dictionary(693 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2447 corpus positions)\n",
      "2020-04-15 23:45:17,917 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:17,925 : INFO : built Dictionary(1160 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 3003 corpus positions)\n",
      "2020-04-15 23:45:26,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:26,938 : INFO : built Dictionary(775 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 1941 corpus positions)\n",
      "2020-04-15 23:45:30,019 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:30,026 : INFO : built Dictionary(320 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 1156 corpus positions)\n",
      "2020-04-15 23:45:30,471 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:30,474 : INFO : built Dictionary(496 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2301 corpus positions)\n",
      "2020-04-15 23:45:31,862 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:31,864 : INFO : built Dictionary(632 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 1102 corpus positions)\n",
      "2020-04-15 23:45:33,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:33,738 : INFO : built Dictionary(429 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2213 corpus positions)\n",
      "2020-04-15 23:45:34,400 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:34,406 : INFO : built Dictionary(1138 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2521 corpus positions)\n",
      "2020-04-15 23:45:42,048 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:42,051 : INFO : built Dictionary(535 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2529 corpus positions)\n",
      "2020-04-15 23:45:43,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:43,179 : INFO : built Dictionary(449 unique tokens: ['accord', 'addit', 'advis', 'allow', 'attribut']...) from 2 documents (total 2504 corpus positions)\n",
      "2020-04-15 23:45:44,464 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:44,472 : INFO : built Dictionary(796 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2111 corpus positions)\n",
      "2020-04-15 23:45:55,824 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:55,831 : INFO : built Dictionary(467 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 1901 corpus positions)\n",
      "2020-04-15 23:45:57,548 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:45:57,556 : INFO : built Dictionary(735 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 3717 corpus positions)\n",
      "2020-04-15 23:46:05,892 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:05,897 : INFO : built Dictionary(366 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2287 corpus positions)\n",
      "2020-04-15 23:46:07,343 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:07,345 : INFO : built Dictionary(351 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2793 corpus positions)\n",
      "2020-04-15 23:46:08,171 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:08,175 : INFO : built Dictionary(496 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 1777 corpus positions)\n",
      "2020-04-15 23:46:10,801 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:10,803 : INFO : built Dictionary(487 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2860 corpus positions)\n",
      "2020-04-15 23:46:12,691 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:12,695 : INFO : built Dictionary(363 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 1024 corpus positions)\n",
      "2020-04-15 23:46:13,995 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:14,000 : INFO : built Dictionary(575 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 3014 corpus positions)\n",
      "2020-04-15 23:46:16,972 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:16,975 : INFO : built Dictionary(347 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 1644 corpus positions)\n",
      "2020-04-15 23:46:17,890 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:17,895 : INFO : built Dictionary(438 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2837 corpus positions)\n",
      "2020-04-15 23:46:19,150 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:19,152 : INFO : built Dictionary(715 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2570 corpus positions)\n",
      "2020-04-15 23:46:24,934 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:24,938 : INFO : built Dictionary(1176 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 3126 corpus positions)\n",
      "2020-04-15 23:46:56,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:46:56,030 : INFO : built Dictionary(797 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2064 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:47:06,900 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:06,907 : INFO : built Dictionary(349 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 1279 corpus positions)\n",
      "2020-04-15 23:47:07,900 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:07,907 : INFO : built Dictionary(521 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2424 corpus positions)\n",
      "2020-04-15 23:47:10,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:10,608 : INFO : built Dictionary(657 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 1225 corpus positions)\n",
      "2020-04-15 23:47:16,274 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:16,276 : INFO : built Dictionary(456 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2336 corpus positions)\n",
      "2020-04-15 23:47:17,771 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:17,775 : INFO : built Dictionary(1158 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2644 corpus positions)\n",
      "2020-04-15 23:47:49,317 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:49,323 : INFO : built Dictionary(560 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2652 corpus positions)\n",
      "2020-04-15 23:47:52,370 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:52,375 : INFO : built Dictionary(481 unique tokens: ['access', 'addit', 'advanc', 'alt', 'applic']...) from 2 documents (total 2627 corpus positions)\n",
      "2020-04-15 23:47:54,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:47:54,179 : INFO : built Dictionary(793 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2031 corpus positions)\n",
      "2020-04-15 23:48:02,661 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:02,663 : INFO : built Dictionary(468 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 1821 corpus positions)\n",
      "2020-04-15 23:48:04,289 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:04,295 : INFO : built Dictionary(739 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 3637 corpus positions)\n",
      "2020-04-15 23:48:12,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:12,519 : INFO : built Dictionary(368 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2207 corpus positions)\n",
      "2020-04-15 23:48:13,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:13,921 : INFO : built Dictionary(348 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2713 corpus positions)\n",
      "2020-04-15 23:48:14,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:14,710 : INFO : built Dictionary(493 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 1697 corpus positions)\n",
      "2020-04-15 23:48:17,260 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:17,262 : INFO : built Dictionary(470 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2780 corpus positions)\n",
      "2020-04-15 23:48:18,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:18,708 : INFO : built Dictionary(350 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 944 corpus positions)\n",
      "2020-04-15 23:48:19,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:20,000 : INFO : built Dictionary(569 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2934 corpus positions)\n",
      "2020-04-15 23:48:22,271 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:22,279 : INFO : built Dictionary(347 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 1564 corpus positions)\n",
      "2020-04-15 23:48:23,037 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:23,043 : INFO : built Dictionary(440 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2757 corpus positions)\n",
      "2020-04-15 23:48:24,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:24,278 : INFO : built Dictionary(714 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2490 corpus positions)\n",
      "2020-04-15 23:48:30,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:30,181 : INFO : built Dictionary(1177 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 3046 corpus positions)\n",
      "2020-04-15 23:48:55,357 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:48:55,362 : INFO : built Dictionary(793 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 1984 corpus positions)\n",
      "2020-04-15 23:49:05,302 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:05,305 : INFO : built Dictionary(349 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 1199 corpus positions)\n",
      "2020-04-15 23:49:06,157 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:06,163 : INFO : built Dictionary(513 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2344 corpus positions)\n",
      "2020-04-15 23:49:09,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:09,085 : INFO : built Dictionary(656 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 1145 corpus positions)\n",
      "2020-04-15 23:49:14,277 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:14,279 : INFO : built Dictionary(455 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2256 corpus positions)\n",
      "2020-04-15 23:49:15,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:15,636 : INFO : built Dictionary(1157 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2564 corpus positions)\n",
      "2020-04-15 23:49:43,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:43,355 : INFO : built Dictionary(552 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2572 corpus positions)\n",
      "2020-04-15 23:49:45,823 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:45,826 : INFO : built Dictionary(466 unique tokens: ['accept', 'agent', 'also', 'applic', 'appropri']...) from 2 documents (total 2547 corpus positions)\n",
      "2020-04-15 23:49:47,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:47,147 : INFO : built Dictionary(778 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2010 corpus positions)\n",
      "2020-04-15 23:49:51,626 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:51,628 : INFO : built Dictionary(446 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 1800 corpus positions)\n",
      "2020-04-15 23:49:52,483 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:52,488 : INFO : built Dictionary(724 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 3616 corpus positions)\n",
      "2020-04-15 23:49:56,480 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:56,482 : INFO : built Dictionary(344 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2186 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:49:57,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:57,256 : INFO : built Dictionary(329 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2692 corpus positions)\n",
      "2020-04-15 23:49:57,697 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:57,699 : INFO : built Dictionary(473 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 1676 corpus positions)\n",
      "2020-04-15 23:49:59,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:49:59,094 : INFO : built Dictionary(461 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2759 corpus positions)\n",
      "2020-04-15 23:50:00,112 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:00,117 : INFO : built Dictionary(338 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 923 corpus positions)\n",
      "2020-04-15 23:50:00,934 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:00,940 : INFO : built Dictionary(552 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2913 corpus positions)\n",
      "2020-04-15 23:50:02,260 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:02,263 : INFO : built Dictionary(328 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 1543 corpus positions)\n",
      "2020-04-15 23:50:02,737 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:02,742 : INFO : built Dictionary(423 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2736 corpus positions)\n",
      "2020-04-15 23:50:03,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:03,427 : INFO : built Dictionary(697 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2469 corpus positions)\n",
      "2020-04-15 23:50:05,849 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:05,855 : INFO : built Dictionary(1158 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 3025 corpus positions)\n",
      "2020-04-15 23:50:19,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:19,885 : INFO : built Dictionary(777 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 1963 corpus positions)\n",
      "2020-04-15 23:50:24,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:24,197 : INFO : built Dictionary(324 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 1178 corpus positions)\n",
      "2020-04-15 23:50:24,734 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:24,736 : INFO : built Dictionary(498 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2323 corpus positions)\n",
      "2020-04-15 23:50:26,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:26,534 : INFO : built Dictionary(637 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 1124 corpus positions)\n",
      "2020-04-15 23:50:29,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:29,135 : INFO : built Dictionary(437 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2235 corpus positions)\n",
      "2020-04-15 23:50:29,876 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:29,880 : INFO : built Dictionary(1142 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2543 corpus positions)\n",
      "2020-04-15 23:50:41,798 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:41,804 : INFO : built Dictionary(543 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2551 corpus positions)\n",
      "2020-04-15 23:50:43,179 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:43,183 : INFO : built Dictionary(454 unique tokens: ['addit', 'also', 'associ', 'authent', 'avail']...) from 2 documents (total 2526 corpus positions)\n",
      "2020-04-15 23:50:44,931 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:44,936 : INFO : built Dictionary(772 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2057 corpus positions)\n",
      "2020-04-15 23:50:48,954 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:48,956 : INFO : built Dictionary(442 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 1847 corpus positions)\n",
      "2020-04-15 23:50:49,943 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:49,946 : INFO : built Dictionary(717 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 3663 corpus positions)\n",
      "2020-04-15 23:50:53,574 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:53,579 : INFO : built Dictionary(341 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2233 corpus positions)\n",
      "2020-04-15 23:50:54,403 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:54,407 : INFO : built Dictionary(321 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2739 corpus positions)\n",
      "2020-04-15 23:50:54,860 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:54,862 : INFO : built Dictionary(468 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 1723 corpus positions)\n",
      "2020-04-15 23:50:56,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:56,164 : INFO : built Dictionary(458 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2806 corpus positions)\n",
      "2020-04-15 23:50:57,202 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:57,204 : INFO : built Dictionary(334 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 970 corpus positions)\n",
      "2020-04-15 23:50:57,961 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:57,968 : INFO : built Dictionary(546 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2960 corpus positions)\n",
      "2020-04-15 23:50:59,417 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:59,423 : INFO : built Dictionary(323 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 1590 corpus positions)\n",
      "2020-04-15 23:50:59,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:50:59,939 : INFO : built Dictionary(415 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2783 corpus positions)\n",
      "2020-04-15 23:51:00,676 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:00,679 : INFO : built Dictionary(692 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2516 corpus positions)\n",
      "2020-04-15 23:51:03,421 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:03,433 : INFO : built Dictionary(1152 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 3072 corpus positions)\n",
      "2020-04-15 23:51:15,193 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:15,200 : INFO : built Dictionary(771 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2010 corpus positions)\n",
      "2020-04-15 23:51:18,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:18,787 : INFO : built Dictionary(322 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 1225 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:51:19,335 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:19,337 : INFO : built Dictionary(495 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2370 corpus positions)\n",
      "2020-04-15 23:51:21,124 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:21,131 : INFO : built Dictionary(635 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 1171 corpus positions)\n",
      "2020-04-15 23:51:23,738 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:23,741 : INFO : built Dictionary(439 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2282 corpus positions)\n",
      "2020-04-15 23:51:24,634 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:24,641 : INFO : built Dictionary(1136 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2590 corpus positions)\n",
      "2020-04-15 23:51:38,223 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:38,225 : INFO : built Dictionary(536 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2598 corpus positions)\n",
      "2020-04-15 23:51:39,874 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:39,876 : INFO : built Dictionary(453 unique tokens: ['abl', 'accept', 'administr', 'authent', 'author']...) from 2 documents (total 2573 corpus positions)\n",
      "2020-04-15 23:51:41,435 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:51:41,444 : INFO : built Dictionary(931 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2432 corpus positions)\n",
      "2020-04-15 23:53:01,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:53:01,792 : INFO : built Dictionary(615 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2222 corpus positions)\n",
      "2020-04-15 23:53:17,076 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:53:17,079 : INFO : built Dictionary(870 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 4038 corpus positions)\n",
      "2020-04-15 23:54:26,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:54:26,991 : INFO : built Dictionary(508 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2608 corpus positions)\n",
      "2020-04-15 23:54:36,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:54:36,291 : INFO : built Dictionary(490 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 3114 corpus positions)\n",
      "2020-04-15 23:54:44,726 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:54:44,729 : INFO : built Dictionary(627 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2098 corpus positions)\n",
      "2020-04-15 23:55:05,851 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:55:05,859 : INFO : built Dictionary(628 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 3181 corpus positions)\n",
      "2020-04-15 23:55:34,468 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:55:34,470 : INFO : built Dictionary(507 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 1345 corpus positions)\n",
      "2020-04-15 23:55:44,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:55:44,200 : INFO : built Dictionary(701 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 3335 corpus positions)\n",
      "2020-04-15 23:56:02,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:56:02,314 : INFO : built Dictionary(489 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 1965 corpus positions)\n",
      "2020-04-15 23:56:09,097 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:56:09,100 : INFO : built Dictionary(575 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 3158 corpus positions)\n",
      "2020-04-15 23:56:17,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:56:17,969 : INFO : built Dictionary(847 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2891 corpus positions)\n",
      "2020-04-15 23:56:58,212 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:56:58,216 : INFO : built Dictionary(1303 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 3447 corpus positions)\n",
      "2020-04-15 23:59:49,972 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-15 23:59:49,975 : INFO : built Dictionary(931 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2385 corpus positions)\n",
      "2020-04-16 00:01:12,268 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:01:12,275 : INFO : built Dictionary(491 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 1600 corpus positions)\n",
      "2020-04-16 00:01:20,724 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:01:20,727 : INFO : built Dictionary(654 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2745 corpus positions)\n",
      "2020-04-16 00:01:49,529 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:01:49,532 : INFO : built Dictionary(802 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 1546 corpus positions)\n",
      "2020-04-16 00:02:42,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:02:42,901 : INFO : built Dictionary(594 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2657 corpus positions)\n",
      "2020-04-16 00:02:54,083 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:02:54,089 : INFO : built Dictionary(1290 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2965 corpus positions)\n",
      "2020-04-16 00:05:51,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:05:51,552 : INFO : built Dictionary(696 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2973 corpus positions)\n",
      "2020-04-16 00:06:12,943 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:12,948 : INFO : built Dictionary(625 unique tokens: ['abl', 'accept', 'access', 'act', 'activ']...) from 2 documents (total 2948 corpus positions)\n",
      "2020-04-16 00:06:42,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:42,035 : INFO : built Dictionary(763 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 1983 corpus positions)\n",
      "2020-04-16 00:06:44,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:44,467 : INFO : built Dictionary(433 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 1773 corpus positions)\n",
      "2020-04-16 00:06:45,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:45,042 : INFO : built Dictionary(708 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 3589 corpus positions)\n",
      "2020-04-16 00:06:47,499 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:47,501 : INFO : built Dictionary(329 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2159 corpus positions)\n",
      "2020-04-16 00:06:47,997 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:47,999 : INFO : built Dictionary(310 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2665 corpus positions)\n",
      "2020-04-16 00:06:48,285 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:06:48,290 : INFO : built Dictionary(457 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 1649 corpus positions)\n",
      "2020-04-16 00:06:49,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:49,244 : INFO : built Dictionary(445 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2732 corpus positions)\n",
      "2020-04-16 00:06:49,867 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:49,869 : INFO : built Dictionary(320 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 896 corpus positions)\n",
      "2020-04-16 00:06:50,317 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:50,319 : INFO : built Dictionary(536 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2886 corpus positions)\n",
      "2020-04-16 00:06:51,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:51,167 : INFO : built Dictionary(312 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 1516 corpus positions)\n",
      "2020-04-16 00:06:51,511 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:51,514 : INFO : built Dictionary(408 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2709 corpus positions)\n",
      "2020-04-16 00:06:51,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:51,996 : INFO : built Dictionary(684 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2442 corpus positions)\n",
      "2020-04-16 00:06:53,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:53,485 : INFO : built Dictionary(1145 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2998 corpus positions)\n",
      "2020-04-16 00:06:59,354 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:06:59,357 : INFO : built Dictionary(762 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 1936 corpus positions)\n",
      "2020-04-16 00:07:01,785 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:01,787 : INFO : built Dictionary(310 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 1151 corpus positions)\n",
      "2020-04-16 00:07:02,124 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:02,127 : INFO : built Dictionary(481 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2296 corpus positions)\n",
      "2020-04-16 00:07:03,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:03,138 : INFO : built Dictionary(621 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 1097 corpus positions)\n",
      "2020-04-16 00:07:04,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:04,607 : INFO : built Dictionary(424 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2208 corpus positions)\n",
      "2020-04-16 00:07:05,188 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:05,191 : INFO : built Dictionary(1125 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2516 corpus positions)\n",
      "2020-04-16 00:07:11,309 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:11,316 : INFO : built Dictionary(528 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2524 corpus positions)\n",
      "2020-04-16 00:07:12,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:12,285 : INFO : built Dictionary(438 unique tokens: ['accept', 'appli', 'authent', 'author', 'bootstrap']...) from 2 documents (total 2499 corpus positions)\n",
      "2020-04-16 00:07:13,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:13,260 : INFO : built Dictionary(841 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2277 corpus positions)\n",
      "2020-04-16 00:07:42,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:42,242 : INFO : built Dictionary(516 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2067 corpus positions)\n",
      "2020-04-16 00:07:46,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:07:46,207 : INFO : built Dictionary(783 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 3883 corpus positions)\n",
      "2020-04-16 00:08:09,276 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:09,283 : INFO : built Dictionary(412 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2453 corpus positions)\n",
      "2020-04-16 00:08:12,288 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:12,295 : INFO : built Dictionary(395 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2959 corpus positions)\n",
      "2020-04-16 00:08:14,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:14,048 : INFO : built Dictionary(546 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 1943 corpus positions)\n",
      "2020-04-16 00:08:20,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:20,137 : INFO : built Dictionary(528 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 3026 corpus positions)\n",
      "2020-04-16 00:08:27,678 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:27,683 : INFO : built Dictionary(410 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 1190 corpus positions)\n",
      "2020-04-16 00:08:30,711 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:30,714 : INFO : built Dictionary(618 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 3180 corpus positions)\n",
      "2020-04-16 00:08:37,226 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:37,229 : INFO : built Dictionary(392 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 1810 corpus positions)\n",
      "2020-04-16 00:08:39,362 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:39,365 : INFO : built Dictionary(481 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 3003 corpus positions)\n",
      "2020-04-16 00:08:42,149 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:42,158 : INFO : built Dictionary(760 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2736 corpus positions)\n",
      "2020-04-16 00:08:56,629 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:08:56,638 : INFO : built Dictionary(1221 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 3292 corpus positions)\n",
      "2020-04-16 00:10:09,281 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:10:09,284 : INFO : built Dictionary(844 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2230 corpus positions)\n",
      "2020-04-16 00:10:37,457 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:10:37,463 : INFO : built Dictionary(394 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 1445 corpus positions)\n",
      "2020-04-16 00:10:39,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:10:39,542 : INFO : built Dictionary(567 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2590 corpus positions)\n",
      "2020-04-16 00:10:47,762 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:10:47,768 : INFO : built Dictionary(709 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 1391 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:11:04,900 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:11:04,908 : INFO : built Dictionary(490 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2502 corpus positions)\n",
      "2020-04-16 00:11:08,169 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:11:08,173 : INFO : built Dictionary(1205 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2810 corpus positions)\n",
      "2020-04-16 00:12:19,410 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:19,413 : INFO : built Dictionary(601 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2818 corpus positions)\n",
      "2020-04-16 00:12:26,709 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:26,712 : INFO : built Dictionary(523 unique tokens: ['10045', '132', '840', 'access', 'addit']...) from 2 documents (total 2793 corpus positions)\n",
      "2020-04-16 00:12:34,426 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:34,431 : INFO : built Dictionary(749 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 1937 corpus positions)\n",
      "2020-04-16 00:12:34,962 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:34,966 : INFO : built Dictionary(414 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 1727 corpus positions)\n",
      "2020-04-16 00:12:35,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:35,125 : INFO : built Dictionary(694 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 3543 corpus positions)\n",
      "2020-04-16 00:12:35,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:35,714 : INFO : built Dictionary(312 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2113 corpus positions)\n",
      "2020-04-16 00:12:35,850 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:35,853 : INFO : built Dictionary(295 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2619 corpus positions)\n",
      "2020-04-16 00:12:35,940 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:35,942 : INFO : built Dictionary(445 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 1603 corpus positions)\n",
      "2020-04-16 00:12:36,172 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:36,174 : INFO : built Dictionary(428 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2686 corpus positions)\n",
      "2020-04-16 00:12:36,321 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:36,326 : INFO : built Dictionary(303 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 850 corpus positions)\n",
      "2020-04-16 00:12:36,454 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:36,456 : INFO : built Dictionary(528 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2840 corpus positions)\n",
      "2020-04-16 00:12:36,679 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:36,680 : INFO : built Dictionary(294 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 1470 corpus positions)\n",
      "2020-04-16 00:12:36,768 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:36,770 : INFO : built Dictionary(392 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2663 corpus positions)\n",
      "2020-04-16 00:12:36,895 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:36,897 : INFO : built Dictionary(667 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2396 corpus positions)\n",
      "2020-04-16 00:12:37,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:37,244 : INFO : built Dictionary(1133 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2952 corpus positions)\n",
      "2020-04-16 00:12:38,342 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:38,345 : INFO : built Dictionary(748 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 1890 corpus positions)\n",
      "2020-04-16 00:12:38,802 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:38,804 : INFO : built Dictionary(292 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 1105 corpus positions)\n",
      "2020-04-16 00:12:38,891 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:38,894 : INFO : built Dictionary(474 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2250 corpus positions)\n",
      "2020-04-16 00:12:39,159 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:39,162 : INFO : built Dictionary(607 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 1051 corpus positions)\n",
      "2020-04-16 00:12:39,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:39,517 : INFO : built Dictionary(406 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2162 corpus positions)\n",
      "2020-04-16 00:12:39,660 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:39,664 : INFO : built Dictionary(1111 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2470 corpus positions)\n",
      "2020-04-16 00:12:40,625 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:40,628 : INFO : built Dictionary(513 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2478 corpus positions)\n",
      "2020-04-16 00:12:40,859 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:40,861 : INFO : built Dictionary(421 unique tokens: ['certif', 'client', 'est', 'generat', 'key']...) from 2 documents (total 2453 corpus positions)\n",
      "2020-04-16 00:12:41,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:41,100 : INFO : built Dictionary(812 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2176 corpus positions)\n",
      "2020-04-16 00:12:56,577 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:56,580 : INFO : built Dictionary(487 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 1966 corpus positions)\n",
      "2020-04-16 00:12:59,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:12:59,418 : INFO : built Dictionary(756 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 3782 corpus positions)\n",
      "2020-04-16 00:13:13,529 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:13,531 : INFO : built Dictionary(386 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2352 corpus positions)\n",
      "2020-04-16 00:13:15,495 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:15,500 : INFO : built Dictionary(362 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2858 corpus positions)\n",
      "2020-04-16 00:13:16,638 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:16,642 : INFO : built Dictionary(508 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 1842 corpus positions)\n",
      "2020-04-16 00:13:20,181 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:20,183 : INFO : built Dictionary(502 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2925 corpus positions)\n",
      "2020-04-16 00:13:24,542 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:24,547 : INFO : built Dictionary(377 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 1089 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:13:26,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:26,543 : INFO : built Dictionary(586 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 3079 corpus positions)\n",
      "2020-04-16 00:13:30,772 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:30,774 : INFO : built Dictionary(369 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 1709 corpus positions)\n",
      "2020-04-16 00:13:31,974 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:31,976 : INFO : built Dictionary(457 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2902 corpus positions)\n",
      "2020-04-16 00:13:33,948 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:33,956 : INFO : built Dictionary(735 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2635 corpus positions)\n",
      "2020-04-16 00:13:43,905 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:13:43,909 : INFO : built Dictionary(1192 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 3191 corpus positions)\n",
      "2020-04-16 00:14:25,159 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:14:25,163 : INFO : built Dictionary(813 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2129 corpus positions)\n",
      "2020-04-16 00:14:40,651 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:14:40,653 : INFO : built Dictionary(370 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 1344 corpus positions)\n",
      "2020-04-16 00:14:42,125 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:14:42,129 : INFO : built Dictionary(532 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2489 corpus positions)\n",
      "2020-04-16 00:14:46,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:14:46,879 : INFO : built Dictionary(680 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 1290 corpus positions)\n",
      "2020-04-16 00:14:56,649 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:14:56,651 : INFO : built Dictionary(479 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2401 corpus positions)\n",
      "2020-04-16 00:14:58,961 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:14:58,969 : INFO : built Dictionary(1178 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2709 corpus positions)\n",
      "2020-04-16 00:15:40,396 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:15:40,399 : INFO : built Dictionary(571 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2717 corpus positions)\n",
      "2020-04-16 00:15:45,255 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:15:45,258 : INFO : built Dictionary(497 unique tokens: ['abl', 'abort', 'accept', 'addit', 'also']...) from 2 documents (total 2692 corpus positions)\n",
      "2020-04-16 00:15:49,449 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:15:49,452 : INFO : built Dictionary(831 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2232 corpus positions)\n",
      "2020-04-16 00:16:16,953 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:16,957 : INFO : built Dictionary(506 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2022 corpus positions)\n",
      "2020-04-16 00:16:20,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:20,535 : INFO : built Dictionary(769 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 3838 corpus positions)\n",
      "2020-04-16 00:16:40,938 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:40,945 : INFO : built Dictionary(400 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2408 corpus positions)\n",
      "2020-04-16 00:16:43,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:43,235 : INFO : built Dictionary(381 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2914 corpus positions)\n",
      "2020-04-16 00:16:44,610 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:44,613 : INFO : built Dictionary(531 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 1898 corpus positions)\n",
      "2020-04-16 00:16:50,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:50,851 : INFO : built Dictionary(522 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2981 corpus positions)\n",
      "2020-04-16 00:16:54,939 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:54,943 : INFO : built Dictionary(397 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 1145 corpus positions)\n",
      "2020-04-16 00:16:57,757 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:16:57,764 : INFO : built Dictionary(604 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 3135 corpus positions)\n",
      "2020-04-16 00:17:03,335 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:17:03,338 : INFO : built Dictionary(383 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 1765 corpus positions)\n",
      "2020-04-16 00:17:04,997 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:17:04,999 : INFO : built Dictionary(471 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2958 corpus positions)\n",
      "2020-04-16 00:17:07,257 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:17:07,260 : INFO : built Dictionary(746 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2691 corpus positions)\n",
      "2020-04-16 00:17:20,534 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:17:20,541 : INFO : built Dictionary(1208 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 3247 corpus positions)\n",
      "2020-04-16 00:18:29,336 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:18:29,340 : INFO : built Dictionary(831 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2185 corpus positions)\n",
      "2020-04-16 00:18:57,887 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:18:57,889 : INFO : built Dictionary(381 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 1400 corpus positions)\n",
      "2020-04-16 00:18:59,654 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:18:59,660 : INFO : built Dictionary(554 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2545 corpus positions)\n",
      "2020-04-16 00:19:07,277 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:19:07,283 : INFO : built Dictionary(698 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 1346 corpus positions)\n",
      "2020-04-16 00:19:22,991 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:19:22,998 : INFO : built Dictionary(493 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2457 corpus positions)\n",
      "2020-04-16 00:19:25,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:19:25,996 : INFO : built Dictionary(1193 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2765 corpus positions)\n",
      "2020-04-16 00:20:38,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:20:38,586 : INFO : built Dictionary(592 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2773 corpus positions)\n",
      "2020-04-16 00:20:44,730 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:20:44,736 : INFO : built Dictionary(518 unique tokens: ['abl', 'absent', 'altern', 'applic', 'associ']...) from 2 documents (total 2748 corpus positions)\n",
      "2020-04-16 00:20:48,748 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:20:48,756 : INFO : built Dictionary(783 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2043 corpus positions)\n",
      "2020-04-16 00:20:57,795 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:20:57,798 : INFO : built Dictionary(462 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 1833 corpus positions)\n",
      "2020-04-16 00:20:59,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:20:59,159 : INFO : built Dictionary(733 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 3649 corpus positions)\n",
      "2020-04-16 00:21:06,406 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:06,408 : INFO : built Dictionary(354 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2219 corpus positions)\n",
      "2020-04-16 00:21:07,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:07,768 : INFO : built Dictionary(340 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2725 corpus positions)\n",
      "2020-04-16 00:21:08,457 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:08,459 : INFO : built Dictionary(490 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 1709 corpus positions)\n",
      "2020-04-16 00:21:10,918 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:10,923 : INFO : built Dictionary(475 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2792 corpus positions)\n",
      "2020-04-16 00:21:12,511 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:12,519 : INFO : built Dictionary(352 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 956 corpus positions)\n",
      "2020-04-16 00:21:13,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:13,794 : INFO : built Dictionary(563 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2946 corpus positions)\n",
      "2020-04-16 00:21:15,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:15,903 : INFO : built Dictionary(344 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 1576 corpus positions)\n",
      "2020-04-16 00:21:16,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:16,685 : INFO : built Dictionary(434 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2769 corpus positions)\n",
      "2020-04-16 00:21:17,834 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:17,837 : INFO : built Dictionary(707 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2502 corpus positions)\n",
      "2020-04-16 00:21:21,779 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:21,789 : INFO : built Dictionary(1169 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 3058 corpus positions)\n",
      "2020-04-16 00:21:51,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:21:51,936 : INFO : built Dictionary(785 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 1996 corpus positions)\n",
      "2020-04-16 00:22:00,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:00,859 : INFO : built Dictionary(343 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 1211 corpus positions)\n",
      "2020-04-16 00:22:01,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:01,722 : INFO : built Dictionary(510 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2356 corpus positions)\n",
      "2020-04-16 00:22:04,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:04,112 : INFO : built Dictionary(650 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 1157 corpus positions)\n",
      "2020-04-16 00:22:09,669 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:09,671 : INFO : built Dictionary(451 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2268 corpus positions)\n",
      "2020-04-16 00:22:10,953 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:10,957 : INFO : built Dictionary(1152 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2576 corpus positions)\n",
      "2020-04-16 00:22:39,227 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:39,229 : INFO : built Dictionary(549 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2584 corpus positions)\n",
      "2020-04-16 00:22:41,386 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:41,392 : INFO : built Dictionary(470 unique tokens: ['addit', 'administr', 'advis', 'alreadi', 'applic']...) from 2 documents (total 2559 corpus positions)\n",
      "2020-04-16 00:22:43,012 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:43,019 : INFO : built Dictionary(797 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2068 corpus positions)\n",
      "2020-04-16 00:22:51,487 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:51,491 : INFO : built Dictionary(466 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 1858 corpus positions)\n",
      "2020-04-16 00:22:53,329 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:22:53,334 : INFO : built Dictionary(739 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 3674 corpus positions)\n",
      "2020-04-16 00:23:00,399 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:00,401 : INFO : built Dictionary(363 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2244 corpus positions)\n",
      "2020-04-16 00:23:01,747 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:01,751 : INFO : built Dictionary(342 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2750 corpus positions)\n",
      "2020-04-16 00:23:02,470 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:02,472 : INFO : built Dictionary(489 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 1734 corpus positions)\n",
      "2020-04-16 00:23:04,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:04,672 : INFO : built Dictionary(480 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2817 corpus positions)\n",
      "2020-04-16 00:23:07,407 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:07,409 : INFO : built Dictionary(354 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 981 corpus positions)\n",
      "2020-04-16 00:23:08,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:08,652 : INFO : built Dictionary(568 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2971 corpus positions)\n",
      "2020-04-16 00:23:11,283 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:23:11,291 : INFO : built Dictionary(345 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 1601 corpus positions)\n",
      "2020-04-16 00:23:12,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:12,058 : INFO : built Dictionary(437 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2794 corpus positions)\n",
      "2020-04-16 00:23:13,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:13,255 : INFO : built Dictionary(712 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2527 corpus positions)\n",
      "2020-04-16 00:23:18,588 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:18,592 : INFO : built Dictionary(1172 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 3083 corpus positions)\n",
      "2020-04-16 00:23:44,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:44,964 : INFO : built Dictionary(796 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2021 corpus positions)\n",
      "2020-04-16 00:23:52,896 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:52,898 : INFO : built Dictionary(342 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 1236 corpus positions)\n",
      "2020-04-16 00:23:53,825 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:53,827 : INFO : built Dictionary(517 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2381 corpus positions)\n",
      "2020-04-16 00:23:56,866 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:23:56,872 : INFO : built Dictionary(656 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 1182 corpus positions)\n",
      "2020-04-16 00:24:01,849 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:01,855 : INFO : built Dictionary(456 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2293 corpus positions)\n",
      "2020-04-16 00:24:03,286 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:03,289 : INFO : built Dictionary(1156 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2601 corpus positions)\n",
      "2020-04-16 00:24:29,702 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:29,704 : INFO : built Dictionary(561 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2609 corpus positions)\n",
      "2020-04-16 00:24:32,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:32,811 : INFO : built Dictionary(475 unique tokens: ['addit', 'allow', 'anchor', 'assum', 'authent']...) from 2 documents (total 2584 corpus positions)\n",
      "2020-04-16 00:24:35,409 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:35,416 : INFO : built Dictionary(763 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 1965 corpus positions)\n",
      "2020-04-16 00:24:37,200 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:37,202 : INFO : built Dictionary(427 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 1755 corpus positions)\n",
      "2020-04-16 00:24:37,722 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:37,725 : INFO : built Dictionary(709 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 3571 corpus positions)\n",
      "2020-04-16 00:24:39,558 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:39,561 : INFO : built Dictionary(327 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2141 corpus positions)\n",
      "2020-04-16 00:24:39,970 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:39,972 : INFO : built Dictionary(309 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2647 corpus positions)\n",
      "2020-04-16 00:24:40,221 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:40,224 : INFO : built Dictionary(456 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 1631 corpus positions)\n",
      "2020-04-16 00:24:40,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:40,917 : INFO : built Dictionary(443 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2714 corpus positions)\n",
      "2020-04-16 00:24:41,449 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:41,451 : INFO : built Dictionary(318 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 878 corpus positions)\n",
      "2020-04-16 00:24:41,822 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:41,825 : INFO : built Dictionary(539 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2868 corpus positions)\n",
      "2020-04-16 00:24:42,569 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:42,571 : INFO : built Dictionary(310 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 1498 corpus positions)\n",
      "2020-04-16 00:24:42,842 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:42,844 : INFO : built Dictionary(403 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2691 corpus positions)\n",
      "2020-04-16 00:24:43,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:43,242 : INFO : built Dictionary(682 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2424 corpus positions)\n",
      "2020-04-16 00:24:44,627 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:44,634 : INFO : built Dictionary(1148 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2980 corpus positions)\n",
      "2020-04-16 00:24:48,537 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:48,540 : INFO : built Dictionary(763 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 1918 corpus positions)\n",
      "2020-04-16 00:24:50,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:50,351 : INFO : built Dictionary(309 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 1133 corpus positions)\n",
      "2020-04-16 00:24:50,630 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:50,632 : INFO : built Dictionary(484 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2278 corpus positions)\n",
      "2020-04-16 00:24:51,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:51,481 : INFO : built Dictionary(622 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 1079 corpus positions)\n",
      "2020-04-16 00:24:52,776 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:52,778 : INFO : built Dictionary(423 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2190 corpus positions)\n",
      "2020-04-16 00:24:53,214 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:53,218 : INFO : built Dictionary(1128 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2498 corpus positions)\n",
      "2020-04-16 00:24:57,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:57,399 : INFO : built Dictionary(523 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2506 corpus positions)\n",
      "2020-04-16 00:24:58,169 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:58,171 : INFO : built Dictionary(437 unique tokens: ['accord', 'certif', 'check', 'client', 'cmc']...) from 2 documents (total 2481 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:24:58,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:24:58,986 : INFO : built Dictionary(766 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2016 corpus positions)\n",
      "2020-04-16 00:25:02,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:02,102 : INFO : built Dictionary(437 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 1806 corpus positions)\n",
      "2020-04-16 00:25:02,828 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:02,836 : INFO : built Dictionary(716 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 3622 corpus positions)\n",
      "2020-04-16 00:25:05,848 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:05,853 : INFO : built Dictionary(336 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2192 corpus positions)\n",
      "2020-04-16 00:25:06,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:06,421 : INFO : built Dictionary(318 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2698 corpus positions)\n",
      "2020-04-16 00:25:06,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:06,808 : INFO : built Dictionary(466 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 1682 corpus positions)\n",
      "2020-04-16 00:25:08,011 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:08,015 : INFO : built Dictionary(453 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2765 corpus positions)\n",
      "2020-04-16 00:25:08,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:08,751 : INFO : built Dictionary(329 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 929 corpus positions)\n",
      "2020-04-16 00:25:09,363 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:09,366 : INFO : built Dictionary(542 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2919 corpus positions)\n",
      "2020-04-16 00:25:10,385 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:10,391 : INFO : built Dictionary(321 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 1549 corpus positions)\n",
      "2020-04-16 00:25:10,811 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:10,815 : INFO : built Dictionary(414 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2742 corpus positions)\n",
      "2020-04-16 00:25:11,426 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:11,430 : INFO : built Dictionary(690 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2475 corpus positions)\n",
      "2020-04-16 00:25:13,191 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:13,196 : INFO : built Dictionary(1148 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 3031 corpus positions)\n",
      "2020-04-16 00:25:22,885 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:22,888 : INFO : built Dictionary(767 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 1969 corpus positions)\n",
      "2020-04-16 00:25:26,362 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:26,363 : INFO : built Dictionary(319 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 1184 corpus positions)\n",
      "2020-04-16 00:25:26,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:26,792 : INFO : built Dictionary(488 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2329 corpus positions)\n",
      "2020-04-16 00:25:27,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:27,986 : INFO : built Dictionary(629 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 1130 corpus positions)\n",
      "2020-04-16 00:25:30,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:30,235 : INFO : built Dictionary(429 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2241 corpus positions)\n",
      "2020-04-16 00:25:30,905 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:30,915 : INFO : built Dictionary(1131 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2549 corpus positions)\n",
      "2020-04-16 00:25:39,501 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:39,504 : INFO : built Dictionary(531 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2557 corpus positions)\n",
      "2020-04-16 00:25:40,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:40,578 : INFO : built Dictionary(446 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cert']...) from 2 documents (total 2532 corpus positions)\n",
      "2020-04-16 00:25:41,727 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:41,729 : INFO : built Dictionary(758 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 1962 corpus positions)\n",
      "2020-04-16 00:25:42,666 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:42,675 : INFO : built Dictionary(425 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 1752 corpus positions)\n",
      "2020-04-16 00:25:42,996 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:42,999 : INFO : built Dictionary(703 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 3568 corpus positions)\n",
      "2020-04-16 00:25:44,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:44,097 : INFO : built Dictionary(324 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2138 corpus positions)\n",
      "2020-04-16 00:25:44,361 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:44,367 : INFO : built Dictionary(305 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2644 corpus positions)\n",
      "2020-04-16 00:25:44,534 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:44,540 : INFO : built Dictionary(454 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 1628 corpus positions)\n",
      "2020-04-16 00:25:44,997 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:44,999 : INFO : built Dictionary(439 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2711 corpus positions)\n",
      "2020-04-16 00:25:45,342 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:45,344 : INFO : built Dictionary(314 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 875 corpus positions)\n",
      "2020-04-16 00:25:45,570 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:45,573 : INFO : built Dictionary(535 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2865 corpus positions)\n",
      "2020-04-16 00:25:46,016 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:46,017 : INFO : built Dictionary(304 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 1495 corpus positions)\n",
      "2020-04-16 00:25:46,184 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:46,187 : INFO : built Dictionary(401 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2688 corpus positions)\n",
      "2020-04-16 00:25:46,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:46,506 : INFO : built Dictionary(677 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2421 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:25:47,339 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:47,345 : INFO : built Dictionary(1142 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2977 corpus positions)\n",
      "2020-04-16 00:25:49,727 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:49,732 : INFO : built Dictionary(758 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 1915 corpus positions)\n",
      "2020-04-16 00:25:50,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:50,721 : INFO : built Dictionary(301 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 1130 corpus positions)\n",
      "2020-04-16 00:25:50,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:50,917 : INFO : built Dictionary(481 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2275 corpus positions)\n",
      "2020-04-16 00:25:51,411 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:51,413 : INFO : built Dictionary(616 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 1076 corpus positions)\n",
      "2020-04-16 00:25:52,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:52,137 : INFO : built Dictionary(415 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2187 corpus positions)\n",
      "2020-04-16 00:25:52,429 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:52,434 : INFO : built Dictionary(1120 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2495 corpus positions)\n",
      "2020-04-16 00:25:54,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:54,725 : INFO : built Dictionary(522 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2503 corpus positions)\n",
      "2020-04-16 00:25:55,213 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:55,220 : INFO : built Dictionary(431 unique tokens: ['access', 'afford', 'cmc', 'defin', 'discuss']...) from 2 documents (total 2478 corpus positions)\n",
      "2020-04-16 00:25:55,664 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:55,666 : INFO : built Dictionary(773 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 1985 corpus positions)\n",
      "2020-04-16 00:25:58,701 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:58,707 : INFO : built Dictionary(442 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 1775 corpus positions)\n",
      "2020-04-16 00:25:59,397 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:25:59,408 : INFO : built Dictionary(716 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 3591 corpus positions)\n",
      "2020-04-16 00:26:02,273 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:02,275 : INFO : built Dictionary(339 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2161 corpus positions)\n",
      "2020-04-16 00:26:02,851 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:02,853 : INFO : built Dictionary(321 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2667 corpus positions)\n",
      "2020-04-16 00:26:03,226 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:03,228 : INFO : built Dictionary(467 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 1651 corpus positions)\n",
      "2020-04-16 00:26:04,303 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:04,305 : INFO : built Dictionary(455 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2734 corpus positions)\n",
      "2020-04-16 00:26:05,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:05,028 : INFO : built Dictionary(330 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 898 corpus positions)\n",
      "2020-04-16 00:26:05,587 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:05,590 : INFO : built Dictionary(548 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2888 corpus positions)\n",
      "2020-04-16 00:26:06,481 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:06,483 : INFO : built Dictionary(321 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 1518 corpus positions)\n",
      "2020-04-16 00:26:06,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:06,858 : INFO : built Dictionary(414 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2711 corpus positions)\n",
      "2020-04-16 00:26:07,412 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:07,420 : INFO : built Dictionary(691 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2444 corpus positions)\n",
      "2020-04-16 00:26:09,362 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:09,367 : INFO : built Dictionary(1155 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 3000 corpus positions)\n",
      "2020-04-16 00:26:18,906 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:18,912 : INFO : built Dictionary(773 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 1938 corpus positions)\n",
      "2020-04-16 00:26:21,795 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:21,802 : INFO : built Dictionary(317 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 1153 corpus positions)\n",
      "2020-04-16 00:26:22,212 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:22,220 : INFO : built Dictionary(495 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2298 corpus positions)\n",
      "2020-04-16 00:26:23,571 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:23,575 : INFO : built Dictionary(636 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 1099 corpus positions)\n",
      "2020-04-16 00:26:25,649 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:25,651 : INFO : built Dictionary(430 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2210 corpus positions)\n",
      "2020-04-16 00:26:26,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:26,234 : INFO : built Dictionary(1135 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2518 corpus positions)\n",
      "2020-04-16 00:26:33,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:33,848 : INFO : built Dictionary(536 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2526 corpus positions)\n",
      "2020-04-16 00:26:34,887 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:34,891 : INFO : built Dictionary(447 unique tokens: ['authent', 'base', 'cmc', 'connect', 'correspond']...) from 2 documents (total 2501 corpus positions)\n",
      "2020-04-16 00:26:36,168 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:36,171 : INFO : built Dictionary(803 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2082 corpus positions)\n",
      "2020-04-16 00:26:49,519 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:49,521 : INFO : built Dictionary(479 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 1872 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:26:51,820 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:26:51,823 : INFO : built Dictionary(750 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 3688 corpus positions)\n",
      "2020-04-16 00:27:02,698 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:02,700 : INFO : built Dictionary(374 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2258 corpus positions)\n",
      "2020-04-16 00:27:04,352 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:04,354 : INFO : built Dictionary(353 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2764 corpus positions)\n",
      "2020-04-16 00:27:05,229 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:05,235 : INFO : built Dictionary(496 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 1748 corpus positions)\n",
      "2020-04-16 00:27:08,409 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:08,411 : INFO : built Dictionary(493 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2831 corpus positions)\n",
      "2020-04-16 00:27:10,581 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:10,587 : INFO : built Dictionary(366 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 995 corpus positions)\n",
      "2020-04-16 00:27:12,305 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:12,312 : INFO : built Dictionary(572 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2985 corpus positions)\n",
      "2020-04-16 00:27:15,592 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:15,594 : INFO : built Dictionary(357 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 1615 corpus positions)\n",
      "2020-04-16 00:27:16,574 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:16,576 : INFO : built Dictionary(449 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2808 corpus positions)\n",
      "2020-04-16 00:27:18,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:18,034 : INFO : built Dictionary(725 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2541 corpus positions)\n",
      "2020-04-16 00:27:25,007 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:27:25,013 : INFO : built Dictionary(1184 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 3097 corpus positions)\n",
      "2020-04-16 00:28:06,528 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:28:06,531 : INFO : built Dictionary(803 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2035 corpus positions)\n",
      "2020-04-16 00:28:19,599 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:28:19,601 : INFO : built Dictionary(355 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 1250 corpus positions)\n",
      "2020-04-16 00:28:20,805 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:28:20,808 : INFO : built Dictionary(519 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2395 corpus positions)\n",
      "2020-04-16 00:28:24,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:28:24,536 : INFO : built Dictionary(666 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 1196 corpus positions)\n",
      "2020-04-16 00:28:33,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:28:33,494 : INFO : built Dictionary(464 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2307 corpus positions)\n",
      "2020-04-16 00:28:35,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:28:35,225 : INFO : built Dictionary(1166 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2615 corpus positions)\n",
      "2020-04-16 00:29:13,496 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:13,499 : INFO : built Dictionary(567 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2623 corpus positions)\n",
      "2020-04-16 00:29:17,787 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:17,791 : INFO : built Dictionary(486 unique tokens: ['accept', 'access', 'allow', 'altern', 'anchor']...) from 2 documents (total 2598 corpus positions)\n",
      "2020-04-16 00:29:21,497 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:21,503 : INFO : built Dictionary(765 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 1976 corpus positions)\n",
      "2020-04-16 00:29:23,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:23,694 : INFO : built Dictionary(434 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 1766 corpus positions)\n",
      "2020-04-16 00:29:24,276 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:24,279 : INFO : built Dictionary(708 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 3582 corpus positions)\n",
      "2020-04-16 00:29:26,329 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:26,335 : INFO : built Dictionary(330 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2152 corpus positions)\n",
      "2020-04-16 00:29:26,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:26,799 : INFO : built Dictionary(314 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2658 corpus positions)\n",
      "2020-04-16 00:29:27,071 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:27,075 : INFO : built Dictionary(459 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 1642 corpus positions)\n",
      "2020-04-16 00:29:27,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:27,939 : INFO : built Dictionary(447 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2725 corpus positions)\n",
      "2020-04-16 00:29:28,505 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:28,506 : INFO : built Dictionary(322 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 889 corpus positions)\n",
      "2020-04-16 00:29:28,942 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:28,944 : INFO : built Dictionary(537 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2879 corpus positions)\n",
      "2020-04-16 00:29:29,734 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:29,735 : INFO : built Dictionary(310 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 1509 corpus positions)\n",
      "2020-04-16 00:29:30,041 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:30,045 : INFO : built Dictionary(406 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2702 corpus positions)\n",
      "2020-04-16 00:29:30,464 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:30,466 : INFO : built Dictionary(685 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2435 corpus positions)\n",
      "2020-04-16 00:29:31,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:31,960 : INFO : built Dictionary(1146 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2991 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:29:37,200 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:37,203 : INFO : built Dictionary(764 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 1929 corpus positions)\n",
      "2020-04-16 00:29:39,278 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:39,282 : INFO : built Dictionary(308 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 1144 corpus positions)\n",
      "2020-04-16 00:29:39,609 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:39,612 : INFO : built Dictionary(483 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2289 corpus positions)\n",
      "2020-04-16 00:29:40,596 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:40,603 : INFO : built Dictionary(622 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 1090 corpus positions)\n",
      "2020-04-16 00:29:41,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:41,968 : INFO : built Dictionary(422 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2201 corpus positions)\n",
      "2020-04-16 00:29:42,483 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:42,487 : INFO : built Dictionary(1127 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2509 corpus positions)\n",
      "2020-04-16 00:29:47,585 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:47,589 : INFO : built Dictionary(527 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2517 corpus positions)\n",
      "2020-04-16 00:29:48,565 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:48,571 : INFO : built Dictionary(440 unique tokens: ['addit', 'also', 'approach', 'authent', 'base']...) from 2 documents (total 2492 corpus positions)\n",
      "2020-04-16 00:29:49,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:29:49,420 : INFO : built Dictionary(808 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2088 corpus positions)\n",
      "2020-04-16 00:30:00,398 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:00,403 : INFO : built Dictionary(472 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 1878 corpus positions)\n",
      "2020-04-16 00:30:02,229 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:02,232 : INFO : built Dictionary(754 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 3694 corpus positions)\n",
      "2020-04-16 00:30:12,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:12,939 : INFO : built Dictionary(376 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2264 corpus positions)\n",
      "2020-04-16 00:30:14,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:14,651 : INFO : built Dictionary(358 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2770 corpus positions)\n",
      "2020-04-16 00:30:15,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:15,539 : INFO : built Dictionary(498 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 1754 corpus positions)\n",
      "2020-04-16 00:30:18,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:18,371 : INFO : built Dictionary(492 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2837 corpus positions)\n",
      "2020-04-16 00:30:20,370 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:20,371 : INFO : built Dictionary(368 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 1001 corpus positions)\n",
      "2020-04-16 00:30:21,975 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:21,979 : INFO : built Dictionary(580 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2991 corpus positions)\n",
      "2020-04-16 00:30:24,627 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:24,635 : INFO : built Dictionary(356 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 1621 corpus positions)\n",
      "2020-04-16 00:30:25,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:25,587 : INFO : built Dictionary(450 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2814 corpus positions)\n",
      "2020-04-16 00:30:27,066 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:27,071 : INFO : built Dictionary(716 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2547 corpus positions)\n",
      "2020-04-16 00:30:33,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:30:33,359 : INFO : built Dictionary(1182 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 3103 corpus positions)\n",
      "2020-04-16 00:31:10,335 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:31:10,339 : INFO : built Dictionary(807 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2041 corpus positions)\n",
      "2020-04-16 00:31:22,597 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:31:22,598 : INFO : built Dictionary(354 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 1256 corpus positions)\n",
      "2020-04-16 00:31:23,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:31:23,670 : INFO : built Dictionary(527 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2401 corpus positions)\n",
      "2020-04-16 00:31:27,452 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:31:27,454 : INFO : built Dictionary(664 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 1202 corpus positions)\n",
      "2020-04-16 00:31:35,265 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:31:35,267 : INFO : built Dictionary(463 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2313 corpus positions)\n",
      "2020-04-16 00:31:36,890 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:31:36,894 : INFO : built Dictionary(1164 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2621 corpus positions)\n",
      "2020-04-16 00:32:11,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:11,156 : INFO : built Dictionary(571 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2629 corpus positions)\n",
      "2020-04-16 00:32:14,237 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:14,241 : INFO : built Dictionary(485 unique tokens: ['abil', 'abl', 'along', 'also', 'applic']...) from 2 documents (total 2604 corpus positions)\n",
      "2020-04-16 00:32:17,760 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:17,762 : INFO : built Dictionary(769 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2020 corpus positions)\n",
      "2020-04-16 00:32:19,843 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:19,846 : INFO : built Dictionary(436 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 1810 corpus positions)\n",
      "2020-04-16 00:32:20,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:20,569 : INFO : built Dictionary(714 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 3626 corpus positions)\n",
      "2020-04-16 00:32:22,313 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:22,315 : INFO : built Dictionary(334 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2196 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 00:32:22,840 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:22,841 : INFO : built Dictionary(316 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2702 corpus positions)\n",
      "2020-04-16 00:32:23,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:23,223 : INFO : built Dictionary(467 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 1686 corpus positions)\n",
      "2020-04-16 00:32:24,076 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:24,080 : INFO : built Dictionary(447 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2769 corpus positions)\n",
      "2020-04-16 00:32:24,811 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:24,819 : INFO : built Dictionary(326 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 933 corpus positions)\n",
      "2020-04-16 00:32:25,289 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:25,296 : INFO : built Dictionary(548 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2923 corpus positions)\n",
      "2020-04-16 00:32:26,236 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:26,243 : INFO : built Dictionary(317 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 1553 corpus positions)\n",
      "2020-04-16 00:32:26,585 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:26,591 : INFO : built Dictionary(414 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2746 corpus positions)\n",
      "2020-04-16 00:32:27,196 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:27,199 : INFO : built Dictionary(687 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2479 corpus positions)\n",
      "2020-04-16 00:32:28,810 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:28,814 : INFO : built Dictionary(1154 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 3035 corpus positions)\n",
      "2020-04-16 00:32:33,906 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:33,909 : INFO : built Dictionary(769 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 1973 corpus positions)\n",
      "2020-04-16 00:32:35,953 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:35,958 : INFO : built Dictionary(312 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 1188 corpus positions)\n",
      "2020-04-16 00:32:36,316 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:36,319 : INFO : built Dictionary(494 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2333 corpus positions)\n",
      "2020-04-16 00:32:37,327 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:37,330 : INFO : built Dictionary(629 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 1134 corpus positions)\n",
      "2020-04-16 00:32:38,601 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:38,603 : INFO : built Dictionary(425 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2245 corpus positions)\n",
      "2020-04-16 00:32:39,229 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:39,233 : INFO : built Dictionary(1134 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2553 corpus positions)\n",
      "2020-04-16 00:32:44,301 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:44,311 : INFO : built Dictionary(534 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2561 corpus positions)\n",
      "2020-04-16 00:32:45,348 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:45,355 : INFO : built Dictionary(440 unique tokens: ['agreement', 'asn', 'asymm', 'asymmetr', 'attribut']...) from 2 documents (total 2536 corpus positions)\n",
      "2020-04-16 00:32:46,317 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:32:46,325 : INFO : built Dictionary(1288 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2564 corpus positions)\n",
      "2020-04-16 00:34:50,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:34:50,464 : INFO : built Dictionary(965 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2354 corpus positions)\n",
      "2020-04-16 00:35:35,585 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:35:35,593 : INFO : built Dictionary(1243 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 4170 corpus positions)\n",
      "2020-04-16 00:42:26,554 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:42:26,560 : INFO : built Dictionary(871 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2740 corpus positions)\n",
      "2020-04-16 00:42:58,084 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:42:58,092 : INFO : built Dictionary(849 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3246 corpus positions)\n",
      "2020-04-16 00:43:28,223 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:43:28,230 : INFO : built Dictionary(991 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2230 corpus positions)\n",
      "2020-04-16 00:46:11,351 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:46:11,355 : INFO : built Dictionary(981 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3313 corpus positions)\n",
      "2020-04-16 00:46:55,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:46:55,569 : INFO : built Dictionary(858 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 1477 corpus positions)\n",
      "2020-04-16 00:47:26,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:47:26,059 : INFO : built Dictionary(1068 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3467 corpus positions)\n",
      "2020-04-16 00:48:34,881 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:48:34,884 : INFO : built Dictionary(856 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2097 corpus positions)\n",
      "2020-04-16 00:49:08,848 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:49:08,857 : INFO : built Dictionary(948 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3290 corpus positions)\n",
      "2020-04-16 00:49:52,237 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:49:52,241 : INFO : built Dictionary(1213 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3023 corpus positions)\n",
      "2020-04-16 00:51:36,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 00:51:36,485 : INFO : built Dictionary(1671 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3579 corpus positions)\n",
      "2020-04-16 01:07:42,803 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:07:42,813 : INFO : built Dictionary(1288 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2517 corpus positions)\n",
      "2020-04-16 01:14:49,376 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:14:49,379 : INFO : built Dictionary(853 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 1732 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 01:15:20,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:15:20,579 : INFO : built Dictionary(1011 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2877 corpus positions)\n",
      "2020-04-16 01:18:47,259 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:18:47,262 : INFO : built Dictionary(1157 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 1678 corpus positions)\n",
      "2020-04-16 01:24:04,351 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:24:04,354 : INFO : built Dictionary(965 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 2789 corpus positions)\n",
      "2020-04-16 01:24:56,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:24:56,883 : INFO : built Dictionary(1650 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3097 corpus positions)\n",
      "2020-04-16 01:39:26,572 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:39:26,576 : INFO : built Dictionary(1055 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3105 corpus positions)\n",
      "2020-04-16 01:40:36,553 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:40:36,556 : INFO : built Dictionary(977 unique tokens: ['0ze', '1zi', '2qd', '2w8yt', '3w0tn2ufuxdw']...) from 2 documents (total 3080 corpus positions)\n",
      "2020-04-16 01:41:20,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:20,739 : INFO : built Dictionary(752 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 1945 corpus positions)\n",
      "2020-04-16 01:41:21,725 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:21,731 : INFO : built Dictionary(418 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 1735 corpus positions)\n",
      "2020-04-16 01:41:21,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:21,991 : INFO : built Dictionary(702 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 3551 corpus positions)\n",
      "2020-04-16 01:41:23,108 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:23,110 : INFO : built Dictionary(318 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2121 corpus positions)\n",
      "2020-04-16 01:41:23,335 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:23,339 : INFO : built Dictionary(301 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2627 corpus positions)\n",
      "2020-04-16 01:41:23,489 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:23,495 : INFO : built Dictionary(448 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 1611 corpus positions)\n",
      "2020-04-16 01:41:23,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:23,936 : INFO : built Dictionary(432 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2694 corpus positions)\n",
      "2020-04-16 01:41:24,234 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:24,238 : INFO : built Dictionary(308 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 858 corpus positions)\n",
      "2020-04-16 01:41:24,471 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:24,475 : INFO : built Dictionary(529 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2848 corpus positions)\n",
      "2020-04-16 01:41:24,866 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:24,869 : INFO : built Dictionary(300 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 1478 corpus positions)\n",
      "2020-04-16 01:41:25,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:25,030 : INFO : built Dictionary(398 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2671 corpus positions)\n",
      "2020-04-16 01:41:25,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:25,263 : INFO : built Dictionary(670 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2404 corpus positions)\n",
      "2020-04-16 01:41:25,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:25,888 : INFO : built Dictionary(1137 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2960 corpus positions)\n",
      "2020-04-16 01:41:28,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:28,164 : INFO : built Dictionary(752 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 1898 corpus positions)\n",
      "2020-04-16 01:41:29,200 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:29,202 : INFO : built Dictionary(297 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 1113 corpus positions)\n",
      "2020-04-16 01:41:29,354 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:29,356 : INFO : built Dictionary(478 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2258 corpus positions)\n",
      "2020-04-16 01:41:29,800 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:29,802 : INFO : built Dictionary(613 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 1059 corpus positions)\n",
      "2020-04-16 01:41:30,524 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:30,526 : INFO : built Dictionary(412 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2170 corpus positions)\n",
      "2020-04-16 01:41:30,782 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:30,785 : INFO : built Dictionary(1116 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2478 corpus positions)\n",
      "2020-04-16 01:41:33,123 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:33,125 : INFO : built Dictionary(517 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2486 corpus positions)\n",
      "2020-04-16 01:41:33,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:33,541 : INFO : built Dictionary(425 unique tokens: ['certif', 'client', 'cmc', 'est', 'full']...) from 2 documents (total 2461 corpus positions)\n",
      "2020-04-16 01:41:33,975 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:33,978 : INFO : built Dictionary(771 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2005 corpus positions)\n",
      "2020-04-16 01:41:36,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:36,375 : INFO : built Dictionary(436 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 1795 corpus positions)\n",
      "2020-04-16 01:41:37,127 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:37,131 : INFO : built Dictionary(710 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 3611 corpus positions)\n",
      "2020-04-16 01:41:39,798 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:39,807 : INFO : built Dictionary(338 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2181 corpus positions)\n",
      "2020-04-16 01:41:40,490 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:40,492 : INFO : built Dictionary(321 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2687 corpus positions)\n",
      "2020-04-16 01:41:40,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:40,916 : INFO : built Dictionary(464 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 1671 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 01:41:41,859 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:41,861 : INFO : built Dictionary(454 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2754 corpus positions)\n",
      "2020-04-16 01:41:42,602 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:42,607 : INFO : built Dictionary(330 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 918 corpus positions)\n",
      "2020-04-16 01:41:43,207 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:43,210 : INFO : built Dictionary(544 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2908 corpus positions)\n",
      "2020-04-16 01:41:44,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:44,252 : INFO : built Dictionary(314 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 1538 corpus positions)\n",
      "2020-04-16 01:41:44,642 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:44,645 : INFO : built Dictionary(412 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2731 corpus positions)\n",
      "2020-04-16 01:41:45,287 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:45,291 : INFO : built Dictionary(686 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2464 corpus positions)\n",
      "2020-04-16 01:41:47,199 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:47,204 : INFO : built Dictionary(1152 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 3020 corpus positions)\n",
      "2020-04-16 01:41:55,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:55,965 : INFO : built Dictionary(769 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 1958 corpus positions)\n",
      "2020-04-16 01:41:58,412 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:58,414 : INFO : built Dictionary(318 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 1173 corpus positions)\n",
      "2020-04-16 01:41:58,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:41:58,886 : INFO : built Dictionary(494 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2318 corpus positions)\n",
      "2020-04-16 01:42:00,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:00,168 : INFO : built Dictionary(630 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 1119 corpus positions)\n",
      "2020-04-16 01:42:01,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:01,999 : INFO : built Dictionary(428 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2230 corpus positions)\n",
      "2020-04-16 01:42:02,708 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:02,712 : INFO : built Dictionary(1132 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2538 corpus positions)\n",
      "2020-04-16 01:42:10,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:10,705 : INFO : built Dictionary(528 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2546 corpus positions)\n",
      "2020-04-16 01:42:11,942 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:11,944 : INFO : built Dictionary(447 unique tokens: ['alt', 'attribut', 'certif', 'chang', 'client']...) from 2 documents (total 2521 corpus positions)\n",
      "2020-04-16 01:42:13,089 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:13,092 : INFO : built Dictionary(784 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2036 corpus positions)\n",
      "2020-04-16 01:42:19,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:19,860 : INFO : built Dictionary(459 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 1826 corpus positions)\n",
      "2020-04-16 01:42:21,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:21,025 : INFO : built Dictionary(729 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 3642 corpus positions)\n",
      "2020-04-16 01:42:25,962 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:25,964 : INFO : built Dictionary(356 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2212 corpus positions)\n",
      "2020-04-16 01:42:27,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:27,129 : INFO : built Dictionary(337 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2718 corpus positions)\n",
      "2020-04-16 01:42:27,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:27,739 : INFO : built Dictionary(480 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 1702 corpus positions)\n",
      "2020-04-16 01:42:29,683 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:29,685 : INFO : built Dictionary(472 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2785 corpus positions)\n",
      "2020-04-16 01:42:32,271 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:32,279 : INFO : built Dictionary(349 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 949 corpus positions)\n",
      "2020-04-16 01:42:33,296 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:33,298 : INFO : built Dictionary(556 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2939 corpus positions)\n",
      "2020-04-16 01:42:35,214 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:35,216 : INFO : built Dictionary(337 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 1569 corpus positions)\n",
      "2020-04-16 01:42:35,927 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:35,929 : INFO : built Dictionary(432 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2762 corpus positions)\n",
      "2020-04-16 01:42:37,009 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:37,015 : INFO : built Dictionary(709 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2495 corpus positions)\n",
      "2020-04-16 01:42:41,064 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:42:41,068 : INFO : built Dictionary(1166 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 3051 corpus positions)\n",
      "2020-04-16 01:43:04,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:04,138 : INFO : built Dictionary(784 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 1989 corpus positions)\n",
      "2020-04-16 01:43:10,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:10,219 : INFO : built Dictionary(336 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 1204 corpus positions)\n",
      "2020-04-16 01:43:10,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:10,969 : INFO : built Dictionary(502 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2349 corpus positions)\n",
      "2020-04-16 01:43:13,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:13,271 : INFO : built Dictionary(648 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 1150 corpus positions)\n",
      "2020-04-16 01:43:16,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 01:43:16,919 : INFO : built Dictionary(445 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2261 corpus positions)\n",
      "2020-04-16 01:43:18,152 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:18,155 : INFO : built Dictionary(1150 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2569 corpus positions)\n",
      "2020-04-16 01:43:38,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:38,052 : INFO : built Dictionary(553 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2577 corpus positions)\n",
      "2020-04-16 01:43:40,320 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:40,322 : INFO : built Dictionary(465 unique tokens: ['accept', 'access', 'also', 'altern', 'assur']...) from 2 documents (total 2552 corpus positions)\n",
      "2020-04-16 01:43:42,689 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:42,692 : INFO : built Dictionary(773 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 1989 corpus positions)\n",
      "2020-04-16 01:43:45,776 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:45,778 : INFO : built Dictionary(443 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 1779 corpus positions)\n",
      "2020-04-16 01:43:46,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:46,587 : INFO : built Dictionary(716 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 3595 corpus positions)\n",
      "2020-04-16 01:43:49,512 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:49,514 : INFO : built Dictionary(336 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2165 corpus positions)\n",
      "2020-04-16 01:43:50,167 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:50,169 : INFO : built Dictionary(319 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2671 corpus positions)\n",
      "2020-04-16 01:43:50,524 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:50,526 : INFO : built Dictionary(467 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 1655 corpus positions)\n",
      "2020-04-16 01:43:51,687 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:51,689 : INFO : built Dictionary(456 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2738 corpus positions)\n",
      "2020-04-16 01:43:52,443 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:52,448 : INFO : built Dictionary(331 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 902 corpus positions)\n",
      "2020-04-16 01:43:53,074 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:53,076 : INFO : built Dictionary(548 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2892 corpus positions)\n",
      "2020-04-16 01:43:54,137 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:54,142 : INFO : built Dictionary(321 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 1522 corpus positions)\n",
      "2020-04-16 01:43:54,525 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:54,529 : INFO : built Dictionary(412 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2715 corpus positions)\n",
      "2020-04-16 01:43:55,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:55,108 : INFO : built Dictionary(694 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2448 corpus positions)\n",
      "2020-04-16 01:43:57,242 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:43:57,246 : INFO : built Dictionary(1156 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 3004 corpus positions)\n",
      "2020-04-16 01:44:05,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:05,549 : INFO : built Dictionary(772 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 1942 corpus positions)\n",
      "2020-04-16 01:44:08,876 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:08,883 : INFO : built Dictionary(317 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 1157 corpus positions)\n",
      "2020-04-16 01:44:09,336 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:09,343 : INFO : built Dictionary(492 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2302 corpus positions)\n",
      "2020-04-16 01:44:10,781 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:10,787 : INFO : built Dictionary(631 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 1103 corpus positions)\n",
      "2020-04-16 01:44:12,798 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:12,801 : INFO : built Dictionary(432 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2214 corpus positions)\n",
      "2020-04-16 01:44:13,518 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:13,524 : INFO : built Dictionary(1137 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2522 corpus positions)\n",
      "2020-04-16 01:44:21,084 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:21,087 : INFO : built Dictionary(533 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2530 corpus positions)\n",
      "2020-04-16 01:44:22,295 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:22,297 : INFO : built Dictionary(450 unique tokens: ['acquir', 'authent', 'author', 'band', 'base']...) from 2 documents (total 2505 corpus positions)\n",
      "2020-04-16 01:44:23,472 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:23,475 : INFO : built Dictionary(765 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 1996 corpus positions)\n",
      "2020-04-16 01:44:25,768 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:25,771 : INFO : built Dictionary(432 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 1786 corpus positions)\n",
      "2020-04-16 01:44:26,400 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:26,408 : INFO : built Dictionary(703 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 3602 corpus positions)\n",
      "2020-04-16 01:44:28,449 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:28,455 : INFO : built Dictionary(328 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2172 corpus positions)\n",
      "2020-04-16 01:44:28,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:28,967 : INFO : built Dictionary(311 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2678 corpus positions)\n",
      "2020-04-16 01:44:29,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:29,269 : INFO : built Dictionary(460 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 1662 corpus positions)\n",
      "2020-04-16 01:44:30,030 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:30,032 : INFO : built Dictionary(444 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2745 corpus positions)\n",
      "2020-04-16 01:44:30,626 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:30,627 : INFO : built Dictionary(319 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 909 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 01:44:31,059 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:31,064 : INFO : built Dictionary(541 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2899 corpus positions)\n",
      "2020-04-16 01:44:31,957 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:31,959 : INFO : built Dictionary(311 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 1529 corpus positions)\n",
      "2020-04-16 01:44:32,274 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:32,277 : INFO : built Dictionary(408 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2722 corpus positions)\n",
      "2020-04-16 01:44:32,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:32,768 : INFO : built Dictionary(684 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2455 corpus positions)\n",
      "2020-04-16 01:44:34,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:34,573 : INFO : built Dictionary(1149 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 3011 corpus positions)\n",
      "2020-04-16 01:44:39,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:39,078 : INFO : built Dictionary(764 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 1949 corpus positions)\n",
      "2020-04-16 01:44:41,150 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:41,152 : INFO : built Dictionary(308 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 1164 corpus positions)\n",
      "2020-04-16 01:44:41,487 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:41,489 : INFO : built Dictionary(487 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2309 corpus positions)\n",
      "2020-04-16 01:44:42,480 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:42,485 : INFO : built Dictionary(622 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 1110 corpus positions)\n",
      "2020-04-16 01:44:43,834 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:43,842 : INFO : built Dictionary(421 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2221 corpus positions)\n",
      "2020-04-16 01:44:44,438 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:44,441 : INFO : built Dictionary(1129 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2529 corpus positions)\n",
      "2020-04-16 01:44:48,782 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:48,784 : INFO : built Dictionary(527 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2537 corpus positions)\n",
      "2020-04-16 01:44:49,848 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:49,853 : INFO : built Dictionary(438 unique tokens: ['alt', 'altern', 'authent', 'cannot', 'certif']...) from 2 documents (total 2512 corpus positions)\n",
      "2020-04-16 01:44:50,669 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:44:50,672 : INFO : built Dictionary(1032 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2361 corpus positions)\n",
      "2020-04-16 01:45:43,828 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:45:43,831 : INFO : built Dictionary(711 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2151 corpus positions)\n",
      "2020-04-16 01:46:03,877 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:46:03,885 : INFO : built Dictionary(979 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 3967 corpus positions)\n",
      "2020-04-16 01:48:38,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:48:38,675 : INFO : built Dictionary(614 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2537 corpus positions)\n",
      "2020-04-16 01:48:50,399 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:48:50,402 : INFO : built Dictionary(596 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 3043 corpus positions)\n",
      "2020-04-16 01:49:00,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:49:00,517 : INFO : built Dictionary(732 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2027 corpus positions)\n",
      "2020-04-16 01:49:49,314 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:49:49,317 : INFO : built Dictionary(729 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 3110 corpus positions)\n",
      "2020-04-16 01:50:12,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:50:12,084 : INFO : built Dictionary(608 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 1274 corpus positions)\n",
      "2020-04-16 01:50:21,905 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:50:21,912 : INFO : built Dictionary(802 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 3264 corpus positions)\n",
      "2020-04-16 01:50:45,321 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:50:45,323 : INFO : built Dictionary(593 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 1894 corpus positions)\n",
      "2020-04-16 01:50:55,683 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:50:55,685 : INFO : built Dictionary(681 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 3087 corpus positions)\n",
      "2020-04-16 01:51:10,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:51:10,993 : INFO : built Dictionary(956 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2820 corpus positions)\n",
      "2020-04-16 01:51:52,684 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:51:52,688 : INFO : built Dictionary(1414 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 3376 corpus positions)\n",
      "2020-04-16 01:57:39,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 01:57:39,648 : INFO : built Dictionary(1032 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2314 corpus positions)\n",
      "2020-04-16 02:00:11,591 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:00:11,593 : INFO : built Dictionary(597 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 1529 corpus positions)\n",
      "2020-04-16 02:00:21,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:00:21,668 : INFO : built Dictionary(748 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2674 corpus positions)\n",
      "2020-04-16 02:01:21,740 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:01:21,746 : INFO : built Dictionary(895 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 1475 corpus positions)\n",
      "2020-04-16 02:02:59,338 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:02:59,344 : INFO : built Dictionary(707 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2586 corpus positions)\n",
      "2020-04-16 02:03:16,336 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:03:16,345 : INFO : built Dictionary(1391 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2894 corpus positions)\n",
      "2020-04-16 02:08:14,866 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:08:14,876 : INFO : built Dictionary(793 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2902 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:08:39,483 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:08:39,492 : INFO : built Dictionary(724 unique tokens: ['0ja7', '0pf', '1122', '200', '2lmcnf']...) from 2 documents (total 2877 corpus positions)\n",
      "2020-04-16 02:09:01,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:01,234 : INFO : built Dictionary(779 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2022 corpus positions)\n",
      "2020-04-16 02:09:05,521 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:05,526 : INFO : built Dictionary(446 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 1812 corpus positions)\n",
      "2020-04-16 02:09:06,570 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:06,580 : INFO : built Dictionary(722 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 3628 corpus positions)\n",
      "2020-04-16 02:09:10,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:10,592 : INFO : built Dictionary(342 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2198 corpus positions)\n",
      "2020-04-16 02:09:11,431 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:11,439 : INFO : built Dictionary(325 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2704 corpus positions)\n",
      "2020-04-16 02:09:11,931 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:11,935 : INFO : built Dictionary(470 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 1688 corpus positions)\n",
      "2020-04-16 02:09:13,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:13,380 : INFO : built Dictionary(460 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2771 corpus positions)\n",
      "2020-04-16 02:09:14,481 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:14,487 : INFO : built Dictionary(337 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 935 corpus positions)\n",
      "2020-04-16 02:09:15,382 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:15,390 : INFO : built Dictionary(552 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2925 corpus positions)\n",
      "2020-04-16 02:09:16,979 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:16,987 : INFO : built Dictionary(326 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 1555 corpus positions)\n",
      "2020-04-16 02:09:17,554 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:17,560 : INFO : built Dictionary(420 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2748 corpus positions)\n",
      "2020-04-16 02:09:18,373 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:18,379 : INFO : built Dictionary(697 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2481 corpus positions)\n",
      "2020-04-16 02:09:21,653 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:21,658 : INFO : built Dictionary(1159 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 3037 corpus positions)\n",
      "2020-04-16 02:09:35,143 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:35,146 : INFO : built Dictionary(778 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 1975 corpus positions)\n",
      "2020-04-16 02:09:39,601 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:39,603 : INFO : built Dictionary(323 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 1190 corpus positions)\n",
      "2020-04-16 02:09:40,147 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:40,155 : INFO : built Dictionary(497 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2335 corpus positions)\n",
      "2020-04-16 02:09:42,102 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:42,104 : INFO : built Dictionary(637 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 1136 corpus positions)\n",
      "2020-04-16 02:09:44,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:44,883 : INFO : built Dictionary(437 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2247 corpus positions)\n",
      "2020-04-16 02:09:45,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:45,793 : INFO : built Dictionary(1139 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2555 corpus positions)\n",
      "2020-04-16 02:09:58,713 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:09:58,716 : INFO : built Dictionary(542 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2563 corpus positions)\n",
      "2020-04-16 02:10:00,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:00,502 : INFO : built Dictionary(453 unique tokens: ['assum', 'authent', 'author', 'base', 'bootstrap']...) from 2 documents (total 2538 corpus positions)\n",
      "2020-04-16 02:10:02,195 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:02,204 : INFO : built Dictionary(792 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2084 corpus positions)\n",
      "2020-04-16 02:10:10,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:10,234 : INFO : built Dictionary(463 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 1874 corpus positions)\n",
      "2020-04-16 02:10:11,869 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:11,872 : INFO : built Dictionary(731 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 3690 corpus positions)\n",
      "2020-04-16 02:10:18,207 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:18,210 : INFO : built Dictionary(359 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2260 corpus positions)\n",
      "2020-04-16 02:10:19,596 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:19,598 : INFO : built Dictionary(340 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2766 corpus positions)\n",
      "2020-04-16 02:10:20,314 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:20,317 : INFO : built Dictionary(487 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 1750 corpus positions)\n",
      "2020-04-16 02:10:22,609 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:22,612 : INFO : built Dictionary(477 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2833 corpus positions)\n",
      "2020-04-16 02:10:24,328 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:24,337 : INFO : built Dictionary(354 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 997 corpus positions)\n",
      "2020-04-16 02:10:25,697 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:25,701 : INFO : built Dictionary(565 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2987 corpus positions)\n",
      "2020-04-16 02:10:28,173 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:28,178 : INFO : built Dictionary(337 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 1617 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:10:28,973 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:28,979 : INFO : built Dictionary(431 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2810 corpus positions)\n",
      "2020-04-16 02:10:30,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:30,164 : INFO : built Dictionary(711 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2543 corpus positions)\n",
      "2020-04-16 02:10:36,093 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:10:36,100 : INFO : built Dictionary(1174 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 3099 corpus positions)\n",
      "2020-04-16 02:11:01,417 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:01,420 : INFO : built Dictionary(791 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2037 corpus positions)\n",
      "2020-04-16 02:11:08,859 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:08,863 : INFO : built Dictionary(341 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 1252 corpus positions)\n",
      "2020-04-16 02:11:09,767 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:09,771 : INFO : built Dictionary(510 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2397 corpus positions)\n",
      "2020-04-16 02:11:12,577 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:12,581 : INFO : built Dictionary(651 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 1198 corpus positions)\n",
      "2020-04-16 02:11:17,318 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:17,320 : INFO : built Dictionary(455 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2309 corpus positions)\n",
      "2020-04-16 02:11:18,793 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:18,797 : INFO : built Dictionary(1155 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2617 corpus positions)\n",
      "2020-04-16 02:11:43,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:43,748 : INFO : built Dictionary(554 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2625 corpus positions)\n",
      "2020-04-16 02:11:46,519 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:46,521 : INFO : built Dictionary(473 unique tokens: ['altern', 'appropri', 'assum', 'authent', 'author']...) from 2 documents (total 2600 corpus positions)\n",
      "2020-04-16 02:11:48,174 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:11:48,177 : INFO : built Dictionary(821 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2118 corpus positions)\n",
      "2020-04-16 02:12:04,598 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:04,600 : INFO : built Dictionary(488 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 1908 corpus positions)\n",
      "2020-04-16 02:12:06,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:06,851 : INFO : built Dictionary(761 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 3724 corpus positions)\n",
      "2020-04-16 02:12:20,596 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:20,602 : INFO : built Dictionary(386 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2294 corpus positions)\n",
      "2020-04-16 02:12:22,565 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:22,569 : INFO : built Dictionary(363 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2800 corpus positions)\n",
      "2020-04-16 02:12:23,596 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:23,598 : INFO : built Dictionary(510 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 1784 corpus positions)\n",
      "2020-04-16 02:12:27,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:27,463 : INFO : built Dictionary(504 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2867 corpus positions)\n",
      "2020-04-16 02:12:30,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:30,024 : INFO : built Dictionary(378 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 1031 corpus positions)\n",
      "2020-04-16 02:12:31,855 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:31,858 : INFO : built Dictionary(591 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 3021 corpus positions)\n",
      "2020-04-16 02:12:35,308 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:35,310 : INFO : built Dictionary(368 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 1651 corpus positions)\n",
      "2020-04-16 02:12:36,368 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:36,370 : INFO : built Dictionary(461 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2844 corpus positions)\n",
      "2020-04-16 02:12:38,070 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:38,076 : INFO : built Dictionary(737 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2577 corpus positions)\n",
      "2020-04-16 02:12:46,839 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:12:46,842 : INFO : built Dictionary(1201 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 3133 corpus positions)\n",
      "2020-04-16 02:13:34,091 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:13:34,094 : INFO : built Dictionary(822 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2071 corpus positions)\n",
      "2020-04-16 02:13:52,288 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:13:52,290 : INFO : built Dictionary(366 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 1286 corpus positions)\n",
      "2020-04-16 02:13:53,553 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:13:53,557 : INFO : built Dictionary(540 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2431 corpus positions)\n",
      "2020-04-16 02:13:58,433 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:13:58,436 : INFO : built Dictionary(679 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 1232 corpus positions)\n",
      "2020-04-16 02:14:08,321 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:14:08,332 : INFO : built Dictionary(477 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2343 corpus positions)\n",
      "2020-04-16 02:14:10,821 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:14:10,829 : INFO : built Dictionary(1180 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2651 corpus positions)\n",
      "2020-04-16 02:15:03,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:15:03,051 : INFO : built Dictionary(581 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2659 corpus positions)\n",
      "2020-04-16 02:15:06,936 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:15:06,943 : INFO : built Dictionary(497 unique tokens: ['addit', 'anchor', 'assum', 'authent', 'author']...) from 2 documents (total 2634 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:15:09,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:15:09,244 : INFO : built Dictionary(834 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2373 corpus positions)\n",
      "2020-04-16 02:15:41,757 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:15:41,760 : INFO : built Dictionary(512 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2163 corpus positions)\n",
      "2020-04-16 02:15:47,279 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:15:47,297 : INFO : built Dictionary(778 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 3979 corpus positions)\n",
      "2020-04-16 02:16:07,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:07,995 : INFO : built Dictionary(409 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2549 corpus positions)\n",
      "2020-04-16 02:16:10,720 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:10,722 : INFO : built Dictionary(388 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 3055 corpus positions)\n",
      "2020-04-16 02:16:12,298 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:12,301 : INFO : built Dictionary(533 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2039 corpus positions)\n",
      "2020-04-16 02:16:17,665 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:17,667 : INFO : built Dictionary(526 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 3122 corpus positions)\n",
      "2020-04-16 02:16:22,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:22,258 : INFO : built Dictionary(403 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 1286 corpus positions)\n",
      "2020-04-16 02:16:25,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:25,052 : INFO : built Dictionary(607 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 3276 corpus positions)\n",
      "2020-04-16 02:16:31,357 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:31,361 : INFO : built Dictionary(385 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 1906 corpus positions)\n",
      "2020-04-16 02:16:33,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:33,098 : INFO : built Dictionary(476 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 3099 corpus positions)\n",
      "2020-04-16 02:16:35,820 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:35,823 : INFO : built Dictionary(752 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2832 corpus positions)\n",
      "2020-04-16 02:16:50,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:16:50,419 : INFO : built Dictionary(1210 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 3388 corpus positions)\n",
      "2020-04-16 02:17:56,635 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:17:56,640 : INFO : built Dictionary(835 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2326 corpus positions)\n",
      "2020-04-16 02:18:23,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:18:23,266 : INFO : built Dictionary(392 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 1541 corpus positions)\n",
      "2020-04-16 02:18:25,154 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:18:25,157 : INFO : built Dictionary(553 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2686 corpus positions)\n",
      "2020-04-16 02:18:31,634 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:18:31,637 : INFO : built Dictionary(697 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 1487 corpus positions)\n",
      "2020-04-16 02:18:47,155 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:18:47,157 : INFO : built Dictionary(497 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2598 corpus positions)\n",
      "2020-04-16 02:18:50,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:18:50,431 : INFO : built Dictionary(1196 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2906 corpus positions)\n",
      "2020-04-16 02:19:57,905 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:19:57,907 : INFO : built Dictionary(597 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2914 corpus positions)\n",
      "2020-04-16 02:20:05,812 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:05,815 : INFO : built Dictionary(522 unique tokens: ['1ar', '802', 'also', 'anchor', 'aspect']...) from 2 documents (total 2889 corpus positions)\n",
      "2020-04-16 02:20:09,549 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:09,553 : INFO : built Dictionary(823 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2071 corpus positions)\n",
      "2020-04-16 02:20:23,542 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:23,545 : INFO : built Dictionary(495 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 1861 corpus positions)\n",
      "2020-04-16 02:20:25,399 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:25,408 : INFO : built Dictionary(769 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 3677 corpus positions)\n",
      "2020-04-16 02:20:39,629 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:39,632 : INFO : built Dictionary(394 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2247 corpus positions)\n",
      "2020-04-16 02:20:41,463 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:41,465 : INFO : built Dictionary(378 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2753 corpus positions)\n",
      "2020-04-16 02:20:42,435 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:42,437 : INFO : built Dictionary(519 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 1737 corpus positions)\n",
      "2020-04-16 02:20:45,622 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:45,631 : INFO : built Dictionary(509 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2820 corpus positions)\n",
      "2020-04-16 02:20:50,267 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:50,271 : INFO : built Dictionary(385 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 984 corpus positions)\n",
      "2020-04-16 02:20:52,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:52,206 : INFO : built Dictionary(600 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2974 corpus positions)\n",
      "2020-04-16 02:20:55,890 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:55,895 : INFO : built Dictionary(374 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 1604 corpus positions)\n",
      "2020-04-16 02:20:57,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:20:57,360 : INFO : built Dictionary(470 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2797 corpus positions)\n",
      "2020-04-16 02:20:58,799 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:20:58,802 : INFO : built Dictionary(745 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2530 corpus positions)\n",
      "2020-04-16 02:21:04,430 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:21:04,434 : INFO : built Dictionary(1213 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 3086 corpus positions)\n",
      "2020-04-16 02:21:51,053 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:21:51,056 : INFO : built Dictionary(822 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2024 corpus positions)\n",
      "2020-04-16 02:22:07,949 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:22:07,954 : INFO : built Dictionary(369 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 1239 corpus positions)\n",
      "2020-04-16 02:22:08,984 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:22:08,989 : INFO : built Dictionary(548 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2384 corpus positions)\n",
      "2020-04-16 02:22:12,982 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:22:12,985 : INFO : built Dictionary(684 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 1185 corpus positions)\n",
      "2020-04-16 02:22:20,802 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:22:20,804 : INFO : built Dictionary(485 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2296 corpus positions)\n",
      "2020-04-16 02:22:22,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:22:22,597 : INFO : built Dictionary(1191 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2604 corpus positions)\n",
      "2020-04-16 02:23:05,049 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:05,054 : INFO : built Dictionary(587 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2612 corpus positions)\n",
      "2020-04-16 02:23:07,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:07,745 : INFO : built Dictionary(500 unique tokens: [')\",', '180', '2012', '57_part1_rev3_gener', '800']...) from 2 documents (total 2587 corpus positions)\n",
      "2020-04-16 02:23:11,627 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:11,631 : INFO : built Dictionary(752 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 1942 corpus positions)\n",
      "2020-04-16 02:23:12,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:12,459 : INFO : built Dictionary(417 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 1732 corpus positions)\n",
      "2020-04-16 02:23:12,671 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:12,675 : INFO : built Dictionary(697 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 3548 corpus positions)\n",
      "2020-04-16 02:23:13,464 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:13,471 : INFO : built Dictionary(315 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2118 corpus positions)\n",
      "2020-04-16 02:23:13,648 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:13,650 : INFO : built Dictionary(298 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2624 corpus positions)\n",
      "2020-04-16 02:23:13,764 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:13,766 : INFO : built Dictionary(446 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 1608 corpus positions)\n",
      "2020-04-16 02:23:14,089 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:14,091 : INFO : built Dictionary(431 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2691 corpus positions)\n",
      "2020-04-16 02:23:14,298 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:14,300 : INFO : built Dictionary(306 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 855 corpus positions)\n",
      "2020-04-16 02:23:14,470 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:14,473 : INFO : built Dictionary(528 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2845 corpus positions)\n",
      "2020-04-16 02:23:14,771 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:14,773 : INFO : built Dictionary(298 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 1475 corpus positions)\n",
      "2020-04-16 02:23:14,900 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:14,902 : INFO : built Dictionary(395 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2668 corpus positions)\n",
      "2020-04-16 02:23:15,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:15,082 : INFO : built Dictionary(671 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2401 corpus positions)\n",
      "2020-04-16 02:23:15,569 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:15,576 : INFO : built Dictionary(1137 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2957 corpus positions)\n",
      "2020-04-16 02:23:17,378 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:17,381 : INFO : built Dictionary(751 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 1895 corpus positions)\n",
      "2020-04-16 02:23:18,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:18,163 : INFO : built Dictionary(293 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 1110 corpus positions)\n",
      "2020-04-16 02:23:18,281 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:18,285 : INFO : built Dictionary(474 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2255 corpus positions)\n",
      "2020-04-16 02:23:18,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:18,635 : INFO : built Dictionary(610 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 1056 corpus positions)\n",
      "2020-04-16 02:23:19,208 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:19,210 : INFO : built Dictionary(410 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2167 corpus positions)\n",
      "2020-04-16 02:23:19,413 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:19,417 : INFO : built Dictionary(1115 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2475 corpus positions)\n",
      "2020-04-16 02:23:21,227 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:21,230 : INFO : built Dictionary(515 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2483 corpus positions)\n",
      "2020-04-16 02:23:21,561 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:21,563 : INFO : built Dictionary(423 unique tokens: ['authent', 'certif', 'cipher', 'client', 'est']...) from 2 documents (total 2458 corpus positions)\n",
      "2020-04-16 02:23:21,877 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:21,880 : INFO : built Dictionary(811 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2084 corpus positions)\n",
      "2020-04-16 02:23:35,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:23:35,448 : INFO : built Dictionary(477 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 1874 corpus positions)\n",
      "2020-04-16 02:23:37,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:37,162 : INFO : built Dictionary(751 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 3690 corpus positions)\n",
      "2020-04-16 02:23:48,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:48,147 : INFO : built Dictionary(377 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2260 corpus positions)\n",
      "2020-04-16 02:23:49,896 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:49,903 : INFO : built Dictionary(364 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2766 corpus positions)\n",
      "2020-04-16 02:23:50,811 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:50,823 : INFO : built Dictionary(507 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 1750 corpus positions)\n",
      "2020-04-16 02:23:53,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:53,796 : INFO : built Dictionary(493 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2833 corpus positions)\n",
      "2020-04-16 02:23:55,807 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:55,809 : INFO : built Dictionary(371 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 997 corpus positions)\n",
      "2020-04-16 02:23:57,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:23:57,583 : INFO : built Dictionary(588 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2987 corpus positions)\n",
      "2020-04-16 02:24:00,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:24:00,564 : INFO : built Dictionary(362 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 1617 corpus positions)\n",
      "2020-04-16 02:24:01,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:24:01,539 : INFO : built Dictionary(454 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2810 corpus positions)\n",
      "2020-04-16 02:24:03,087 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:24:03,089 : INFO : built Dictionary(726 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2543 corpus positions)\n",
      "2020-04-16 02:24:09,034 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:24:09,041 : INFO : built Dictionary(1189 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 3099 corpus positions)\n",
      "2020-04-16 02:24:47,225 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:24:47,228 : INFO : built Dictionary(810 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2037 corpus positions)\n",
      "2020-04-16 02:25:02,665 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:25:02,670 : INFO : built Dictionary(357 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 1252 corpus positions)\n",
      "2020-04-16 02:25:03,770 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:25:03,775 : INFO : built Dictionary(537 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2397 corpus positions)\n",
      "2020-04-16 02:25:07,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:25:07,531 : INFO : built Dictionary(671 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 1198 corpus positions)\n",
      "2020-04-16 02:25:15,621 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:25:15,624 : INFO : built Dictionary(469 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2309 corpus positions)\n",
      "2020-04-16 02:25:17,308 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:25:17,312 : INFO : built Dictionary(1171 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2617 corpus positions)\n",
      "2020-04-16 02:25:55,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:25:55,588 : INFO : built Dictionary(570 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2625 corpus positions)\n",
      "2020-04-16 02:25:58,739 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:25:58,741 : INFO : built Dictionary(486 unique tokens: ['add', 'addit', 'address', 'anoth', 'applic']...) from 2 documents (total 2600 corpus positions)\n",
      "2020-04-16 02:26:00,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:00,884 : INFO : built Dictionary(764 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 1965 corpus positions)\n",
      "2020-04-16 02:26:02,464 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:02,471 : INFO : built Dictionary(429 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 1755 corpus positions)\n",
      "2020-04-16 02:26:02,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:02,964 : INFO : built Dictionary(707 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 3571 corpus positions)\n",
      "2020-04-16 02:26:04,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:04,533 : INFO : built Dictionary(326 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2141 corpus positions)\n",
      "2020-04-16 02:26:04,911 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:04,913 : INFO : built Dictionary(310 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2647 corpus positions)\n",
      "2020-04-16 02:26:05,154 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:05,156 : INFO : built Dictionary(457 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 1631 corpus positions)\n",
      "2020-04-16 02:26:05,808 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:05,810 : INFO : built Dictionary(444 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2714 corpus positions)\n",
      "2020-04-16 02:26:06,306 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:06,311 : INFO : built Dictionary(319 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 878 corpus positions)\n",
      "2020-04-16 02:26:06,644 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:06,651 : INFO : built Dictionary(538 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2868 corpus positions)\n",
      "2020-04-16 02:26:07,298 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:07,299 : INFO : built Dictionary(307 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 1498 corpus positions)\n",
      "2020-04-16 02:26:07,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:07,547 : INFO : built Dictionary(404 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2691 corpus positions)\n",
      "2020-04-16 02:26:07,932 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:07,935 : INFO : built Dictionary(682 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2424 corpus positions)\n",
      "2020-04-16 02:26:09,154 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:09,161 : INFO : built Dictionary(1146 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2980 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:26:12,754 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:12,760 : INFO : built Dictionary(763 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 1918 corpus positions)\n",
      "2020-04-16 02:26:14,359 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:14,367 : INFO : built Dictionary(308 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 1133 corpus positions)\n",
      "2020-04-16 02:26:14,633 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:14,635 : INFO : built Dictionary(483 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2278 corpus positions)\n",
      "2020-04-16 02:26:15,364 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:15,366 : INFO : built Dictionary(621 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 1079 corpus positions)\n",
      "2020-04-16 02:26:16,525 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:16,527 : INFO : built Dictionary(420 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2190 corpus positions)\n",
      "2020-04-16 02:26:16,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:16,959 : INFO : built Dictionary(1126 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2498 corpus positions)\n",
      "2020-04-16 02:26:20,745 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:20,748 : INFO : built Dictionary(526 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2506 corpus positions)\n",
      "2020-04-16 02:26:21,449 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:21,455 : INFO : built Dictionary(437 unique tokens: ['accord', 'authent', 'author', 'basi', 'certif']...) from 2 documents (total 2481 corpus positions)\n",
      "2020-04-16 02:26:22,087 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:22,090 : INFO : built Dictionary(766 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 1994 corpus positions)\n",
      "2020-04-16 02:26:25,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:25,035 : INFO : built Dictionary(433 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 1784 corpus positions)\n",
      "2020-04-16 02:26:25,709 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:25,713 : INFO : built Dictionary(713 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 3600 corpus positions)\n",
      "2020-04-16 02:26:28,523 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:28,527 : INFO : built Dictionary(333 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2170 corpus positions)\n",
      "2020-04-16 02:26:29,112 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:29,114 : INFO : built Dictionary(311 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2676 corpus positions)\n",
      "2020-04-16 02:26:29,454 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:29,456 : INFO : built Dictionary(462 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 1660 corpus positions)\n",
      "2020-04-16 02:26:30,509 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:30,515 : INFO : built Dictionary(448 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2743 corpus positions)\n",
      "2020-04-16 02:26:31,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:31,272 : INFO : built Dictionary(324 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 907 corpus positions)\n",
      "2020-04-16 02:26:31,872 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:31,879 : INFO : built Dictionary(541 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2897 corpus positions)\n",
      "2020-04-16 02:26:32,923 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:32,927 : INFO : built Dictionary(317 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 1527 corpus positions)\n",
      "2020-04-16 02:26:33,329 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:33,331 : INFO : built Dictionary(408 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2720 corpus positions)\n",
      "2020-04-16 02:26:33,920 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:33,923 : INFO : built Dictionary(684 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2453 corpus positions)\n",
      "2020-04-16 02:26:35,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:35,819 : INFO : built Dictionary(1145 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 3009 corpus positions)\n",
      "2020-04-16 02:26:42,694 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:42,700 : INFO : built Dictionary(765 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 1947 corpus positions)\n",
      "2020-04-16 02:26:45,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:45,466 : INFO : built Dictionary(309 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 1162 corpus positions)\n",
      "2020-04-16 02:26:45,917 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:45,921 : INFO : built Dictionary(488 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2307 corpus positions)\n",
      "2020-04-16 02:26:47,224 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:47,227 : INFO : built Dictionary(627 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 1108 corpus positions)\n",
      "2020-04-16 02:26:49,245 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:49,248 : INFO : built Dictionary(427 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2219 corpus positions)\n",
      "2020-04-16 02:26:49,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:49,966 : INFO : built Dictionary(1129 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2527 corpus positions)\n",
      "2020-04-16 02:26:58,516 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:58,520 : INFO : built Dictionary(529 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2535 corpus positions)\n",
      "2020-04-16 02:26:59,724 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:26:59,730 : INFO : built Dictionary(441 unique tokens: ['authent', 'author', 'base', 'cacert', 'certif']...) from 2 documents (total 2510 corpus positions)\n",
      "2020-04-16 02:27:00,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:00,903 : INFO : built Dictionary(788 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2027 corpus positions)\n",
      "2020-04-16 02:27:06,474 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:06,476 : INFO : built Dictionary(454 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 1817 corpus positions)\n",
      "2020-04-16 02:27:07,672 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:07,676 : INFO : built Dictionary(730 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 3633 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:27:12,101 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:12,103 : INFO : built Dictionary(350 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2203 corpus positions)\n",
      "2020-04-16 02:27:12,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:12,967 : INFO : built Dictionary(331 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2709 corpus positions)\n",
      "2020-04-16 02:27:13,515 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:13,517 : INFO : built Dictionary(477 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 1693 corpus positions)\n",
      "2020-04-16 02:27:15,067 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:15,069 : INFO : built Dictionary(469 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2776 corpus positions)\n",
      "2020-04-16 02:27:16,206 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:16,207 : INFO : built Dictionary(344 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 940 corpus positions)\n",
      "2020-04-16 02:27:17,081 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:17,088 : INFO : built Dictionary(559 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2930 corpus positions)\n",
      "2020-04-16 02:27:18,727 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:18,731 : INFO : built Dictionary(332 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 1560 corpus positions)\n",
      "2020-04-16 02:27:19,303 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:19,306 : INFO : built Dictionary(429 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2753 corpus positions)\n",
      "2020-04-16 02:27:20,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:20,206 : INFO : built Dictionary(702 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2486 corpus positions)\n",
      "2020-04-16 02:27:23,708 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:23,717 : INFO : built Dictionary(1166 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 3042 corpus positions)\n",
      "2020-04-16 02:27:38,428 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:38,431 : INFO : built Dictionary(787 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 1980 corpus positions)\n",
      "2020-04-16 02:27:43,508 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:43,510 : INFO : built Dictionary(331 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 1195 corpus positions)\n",
      "2020-04-16 02:27:44,156 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:44,159 : INFO : built Dictionary(503 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2340 corpus positions)\n",
      "2020-04-16 02:27:46,052 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:46,060 : INFO : built Dictionary(647 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 1141 corpus positions)\n",
      "2020-04-16 02:27:49,461 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:49,463 : INFO : built Dictionary(444 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2252 corpus positions)\n",
      "2020-04-16 02:27:50,533 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:27:50,541 : INFO : built Dictionary(1146 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2560 corpus positions)\n",
      "2020-04-16 02:28:06,007 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:06,011 : INFO : built Dictionary(549 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2568 corpus positions)\n",
      "2020-04-16 02:28:07,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:07,901 : INFO : built Dictionary(462 unique tokens: ['anchor', 'attack', 'authent', 'author', 'base']...) from 2 documents (total 2543 corpus positions)\n",
      "2020-04-16 02:28:09,011 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:09,013 : INFO : built Dictionary(763 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 1964 corpus positions)\n",
      "2020-04-16 02:28:10,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:10,661 : INFO : built Dictionary(431 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 1754 corpus positions)\n",
      "2020-04-16 02:28:11,115 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:11,118 : INFO : built Dictionary(712 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 3570 corpus positions)\n",
      "2020-04-16 02:28:12,836 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:12,843 : INFO : built Dictionary(331 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2140 corpus positions)\n",
      "2020-04-16 02:28:13,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:13,241 : INFO : built Dictionary(313 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2646 corpus positions)\n",
      "2020-04-16 02:28:13,489 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:13,491 : INFO : built Dictionary(462 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 1630 corpus positions)\n",
      "2020-04-16 02:28:14,216 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:14,218 : INFO : built Dictionary(446 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2713 corpus positions)\n",
      "2020-04-16 02:28:14,700 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:14,701 : INFO : built Dictionary(322 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 877 corpus positions)\n",
      "2020-04-16 02:28:15,098 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:15,102 : INFO : built Dictionary(537 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2867 corpus positions)\n",
      "2020-04-16 02:28:15,835 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:15,842 : INFO : built Dictionary(314 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 1497 corpus positions)\n",
      "2020-04-16 02:28:16,215 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:16,221 : INFO : built Dictionary(410 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2690 corpus positions)\n",
      "2020-04-16 02:28:16,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:16,663 : INFO : built Dictionary(684 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2423 corpus positions)\n",
      "2020-04-16 02:28:17,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:17,884 : INFO : built Dictionary(1146 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2979 corpus positions)\n",
      "2020-04-16 02:28:21,865 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:21,870 : INFO : built Dictionary(763 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 1917 corpus positions)\n",
      "2020-04-16 02:28:23,560 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:28:23,562 : INFO : built Dictionary(314 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 1132 corpus positions)\n",
      "2020-04-16 02:28:23,823 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:23,826 : INFO : built Dictionary(483 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2277 corpus positions)\n",
      "2020-04-16 02:28:24,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:24,696 : INFO : built Dictionary(623 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 1078 corpus positions)\n",
      "2020-04-16 02:28:25,894 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:25,898 : INFO : built Dictionary(424 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2189 corpus positions)\n",
      "2020-04-16 02:28:26,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:26,354 : INFO : built Dictionary(1126 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2497 corpus positions)\n",
      "2020-04-16 02:28:30,504 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:30,506 : INFO : built Dictionary(526 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2505 corpus positions)\n",
      "2020-04-16 02:28:31,169 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:31,171 : INFO : built Dictionary(439 unique tokens: ['applic', 'base', 'binari', 'bodi', 'cmc']...) from 2 documents (total 2480 corpus positions)\n",
      "2020-04-16 02:28:31,640 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:31,644 : INFO : built Dictionary(752 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 1937 corpus positions)\n",
      "2020-04-16 02:28:32,288 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:32,291 : INFO : built Dictionary(418 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 1727 corpus positions)\n",
      "2020-04-16 02:28:32,464 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:32,467 : INFO : built Dictionary(696 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 3543 corpus positions)\n",
      "2020-04-16 02:28:33,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:33,138 : INFO : built Dictionary(316 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2113 corpus positions)\n",
      "2020-04-16 02:28:33,319 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:33,321 : INFO : built Dictionary(297 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2619 corpus positions)\n",
      "2020-04-16 02:28:33,425 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:33,427 : INFO : built Dictionary(447 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 1603 corpus positions)\n",
      "2020-04-16 02:28:33,673 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:33,680 : INFO : built Dictionary(429 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2686 corpus positions)\n",
      "2020-04-16 02:28:33,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:33,922 : INFO : built Dictionary(304 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 850 corpus positions)\n",
      "2020-04-16 02:28:34,134 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:34,141 : INFO : built Dictionary(528 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2840 corpus positions)\n",
      "2020-04-16 02:28:34,420 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:34,422 : INFO : built Dictionary(296 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 1470 corpus positions)\n",
      "2020-04-16 02:28:34,518 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:34,520 : INFO : built Dictionary(394 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2663 corpus positions)\n",
      "2020-04-16 02:28:34,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:34,670 : INFO : built Dictionary(670 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2396 corpus positions)\n",
      "2020-04-16 02:28:35,068 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:35,072 : INFO : built Dictionary(1135 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2952 corpus positions)\n",
      "2020-04-16 02:28:36,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:36,823 : INFO : built Dictionary(751 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 1890 corpus positions)\n",
      "2020-04-16 02:28:37,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:37,399 : INFO : built Dictionary(295 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 1105 corpus positions)\n",
      "2020-04-16 02:28:37,494 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:37,498 : INFO : built Dictionary(474 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2250 corpus positions)\n",
      "2020-04-16 02:28:37,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:37,745 : INFO : built Dictionary(609 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 1051 corpus positions)\n",
      "2020-04-16 02:28:38,174 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:38,178 : INFO : built Dictionary(408 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2162 corpus positions)\n",
      "2020-04-16 02:28:38,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:38,369 : INFO : built Dictionary(1113 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2470 corpus positions)\n",
      "2020-04-16 02:28:39,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:39,679 : INFO : built Dictionary(514 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2478 corpus positions)\n",
      "2020-04-16 02:28:39,940 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:39,943 : INFO : built Dictionary(422 unique tokens: ['certif', 'client', 'copi', 'current', 'distribut']...) from 2 documents (total 2453 corpus positions)\n",
      "2020-04-16 02:28:40,268 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:28:40,277 : INFO : built Dictionary(1319 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2595 corpus positions)\n",
      "2020-04-16 02:31:03,907 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:31:03,916 : INFO : built Dictionary(998 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2385 corpus positions)\n",
      "2020-04-16 02:31:58,672 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:31:58,678 : INFO : built Dictionary(1269 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 4201 corpus positions)\n",
      "2020-04-16 02:39:25,807 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:39:25,810 : INFO : built Dictionary(901 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2771 corpus positions)\n",
      "2020-04-16 02:40:02,806 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 02:40:02,810 : INFO : built Dictionary(878 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3277 corpus positions)\n",
      "2020-04-16 02:40:37,652 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:40:37,656 : INFO : built Dictionary(1021 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2261 corpus positions)\n",
      "2020-04-16 02:41:27,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:41:27,976 : INFO : built Dictionary(1009 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3344 corpus positions)\n",
      "2020-04-16 02:42:15,772 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:42:15,775 : INFO : built Dictionary(889 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 1508 corpus positions)\n",
      "2020-04-16 02:42:54,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:42:54,570 : INFO : built Dictionary(1093 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3498 corpus positions)\n",
      "2020-04-16 02:44:16,126 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:44:16,132 : INFO : built Dictionary(882 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2128 corpus positions)\n",
      "2020-04-16 02:44:51,389 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:44:51,397 : INFO : built Dictionary(969 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3321 corpus positions)\n",
      "2020-04-16 02:45:42,671 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:45:42,681 : INFO : built Dictionary(1243 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3054 corpus positions)\n",
      "2020-04-16 02:47:54,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 02:47:54,037 : INFO : built Dictionary(1703 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3610 corpus positions)\n",
      "2020-04-16 03:05:26,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:05:26,835 : INFO : built Dictionary(1320 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2548 corpus positions)\n",
      "2020-04-16 03:14:37,801 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:14:37,808 : INFO : built Dictionary(881 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 1763 corpus positions)\n",
      "2020-04-16 03:15:10,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:15:10,256 : INFO : built Dictionary(1036 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2908 corpus positions)\n",
      "2020-04-16 03:19:01,093 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:19:01,096 : INFO : built Dictionary(1185 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 1709 corpus positions)\n",
      "2020-04-16 03:24:07,086 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:24:07,089 : INFO : built Dictionary(990 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 2820 corpus positions)\n",
      "2020-04-16 03:24:53,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:24:53,999 : INFO : built Dictionary(1681 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3128 corpus positions)\n",
      "2020-04-16 03:39:35,216 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:39:35,220 : INFO : built Dictionary(1083 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3136 corpus positions)\n",
      "2020-04-16 03:40:43,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:40:43,396 : INFO : built Dictionary(1005 unique tokens: ['0ue', '1958a6m9o', '1o9q', '4mgv', '4o38fup0en']...) from 2 documents (total 3111 corpus positions)\n",
      "2020-04-16 03:41:21,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:21,462 : INFO : built Dictionary(777 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2041 corpus positions)\n",
      "2020-04-16 03:41:24,976 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:24,978 : INFO : built Dictionary(448 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 1831 corpus positions)\n",
      "2020-04-16 03:41:25,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:25,819 : INFO : built Dictionary(725 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 3647 corpus positions)\n",
      "2020-04-16 03:41:29,383 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:29,385 : INFO : built Dictionary(348 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2217 corpus positions)\n",
      "2020-04-16 03:41:30,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:30,124 : INFO : built Dictionary(332 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2723 corpus positions)\n",
      "2020-04-16 03:41:30,607 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:30,610 : INFO : built Dictionary(476 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 1707 corpus positions)\n",
      "2020-04-16 03:41:32,030 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:32,033 : INFO : built Dictionary(461 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2790 corpus positions)\n",
      "2020-04-16 03:41:33,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:33,028 : INFO : built Dictionary(339 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 954 corpus positions)\n",
      "2020-04-16 03:41:33,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:33,768 : INFO : built Dictionary(557 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2944 corpus positions)\n",
      "2020-04-16 03:41:35,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:35,030 : INFO : built Dictionary(327 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 1574 corpus positions)\n",
      "2020-04-16 03:41:35,545 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:35,547 : INFO : built Dictionary(422 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2767 corpus positions)\n",
      "2020-04-16 03:41:36,291 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:36,294 : INFO : built Dictionary(696 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2500 corpus positions)\n",
      "2020-04-16 03:41:38,486 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:38,490 : INFO : built Dictionary(1160 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 3056 corpus positions)\n",
      "2020-04-16 03:41:45,884 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:45,887 : INFO : built Dictionary(777 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 1994 corpus positions)\n",
      "2020-04-16 03:41:49,304 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:49,306 : INFO : built Dictionary(329 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 1209 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 03:41:49,849 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:49,851 : INFO : built Dictionary(503 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2354 corpus positions)\n",
      "2020-04-16 03:41:51,421 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:51,424 : INFO : built Dictionary(638 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 1155 corpus positions)\n",
      "2020-04-16 03:41:53,777 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:53,779 : INFO : built Dictionary(442 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2266 corpus positions)\n",
      "2020-04-16 03:41:54,631 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:41:54,635 : INFO : built Dictionary(1141 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2574 corpus positions)\n",
      "2020-04-16 03:42:02,322 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:02,324 : INFO : built Dictionary(540 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2582 corpus positions)\n",
      "2020-04-16 03:42:03,674 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:03,676 : INFO : built Dictionary(454 unique tokens: ['applic', 'attribut', 'cacert', 'certif', 'client']...) from 2 documents (total 2557 corpus positions)\n",
      "2020-04-16 03:42:05,213 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:05,216 : INFO : built Dictionary(808 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2102 corpus positions)\n",
      "2020-04-16 03:42:13,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:13,121 : INFO : built Dictionary(484 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 1892 corpus positions)\n",
      "2020-04-16 03:42:15,020 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:15,023 : INFO : built Dictionary(751 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 3708 corpus positions)\n",
      "2020-04-16 03:42:22,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:22,065 : INFO : built Dictionary(378 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2278 corpus positions)\n",
      "2020-04-16 03:42:23,640 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:23,642 : INFO : built Dictionary(362 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2784 corpus positions)\n",
      "2020-04-16 03:42:24,591 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:24,593 : INFO : built Dictionary(506 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 1768 corpus positions)\n",
      "2020-04-16 03:42:27,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:27,581 : INFO : built Dictionary(497 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2851 corpus positions)\n",
      "2020-04-16 03:42:30,895 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:30,897 : INFO : built Dictionary(373 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 1015 corpus positions)\n",
      "2020-04-16 03:42:32,543 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:32,546 : INFO : built Dictionary(585 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 3005 corpus positions)\n",
      "2020-04-16 03:42:34,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:34,899 : INFO : built Dictionary(358 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 1635 corpus positions)\n",
      "2020-04-16 03:42:35,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:35,850 : INFO : built Dictionary(450 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2828 corpus positions)\n",
      "2020-04-16 03:42:37,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:37,267 : INFO : built Dictionary(727 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2561 corpus positions)\n",
      "2020-04-16 03:42:42,210 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:42:42,214 : INFO : built Dictionary(1189 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 3117 corpus positions)\n",
      "2020-04-16 03:43:03,285 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:03,288 : INFO : built Dictionary(807 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2055 corpus positions)\n",
      "2020-04-16 03:43:11,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:11,352 : INFO : built Dictionary(361 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 1270 corpus positions)\n",
      "2020-04-16 03:43:12,438 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:12,441 : INFO : built Dictionary(532 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2415 corpus positions)\n",
      "2020-04-16 03:43:15,774 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:15,777 : INFO : built Dictionary(669 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 1216 corpus positions)\n",
      "2020-04-16 03:43:21,085 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:21,087 : INFO : built Dictionary(467 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2327 corpus positions)\n",
      "2020-04-16 03:43:22,635 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:22,639 : INFO : built Dictionary(1169 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2635 corpus positions)\n",
      "2020-04-16 03:43:43,509 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:43,511 : INFO : built Dictionary(569 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2643 corpus positions)\n",
      "2020-04-16 03:43:46,384 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:46,386 : INFO : built Dictionary(490 unique tokens: ['addit', 'adopt', 'alloc', 'anoth', 'architectur']...) from 2 documents (total 2618 corpus positions)\n",
      "2020-04-16 03:43:49,427 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:43:49,431 : INFO : built Dictionary(816 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2164 corpus positions)\n",
      "2020-04-16 03:44:03,011 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:03,014 : INFO : built Dictionary(498 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 1954 corpus positions)\n",
      "2020-04-16 03:44:05,759 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:05,763 : INFO : built Dictionary(763 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 3770 corpus positions)\n",
      "2020-04-16 03:44:17,116 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:17,119 : INFO : built Dictionary(395 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2340 corpus positions)\n",
      "2020-04-16 03:44:19,272 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:19,274 : INFO : built Dictionary(375 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2846 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 03:44:20,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:20,578 : INFO : built Dictionary(519 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 1830 corpus positions)\n",
      "2020-04-16 03:44:24,911 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:24,913 : INFO : built Dictionary(514 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2913 corpus positions)\n",
      "2020-04-16 03:44:27,541 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:27,543 : INFO : built Dictionary(390 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 1077 corpus positions)\n",
      "2020-04-16 03:44:29,933 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:29,935 : INFO : built Dictionary(595 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 3067 corpus positions)\n",
      "2020-04-16 03:44:33,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:33,791 : INFO : built Dictionary(373 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 1697 corpus positions)\n",
      "2020-04-16 03:44:35,256 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:35,259 : INFO : built Dictionary(466 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2890 corpus positions)\n",
      "2020-04-16 03:44:37,263 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:37,266 : INFO : built Dictionary(742 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2623 corpus positions)\n",
      "2020-04-16 03:44:44,440 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:44:44,444 : INFO : built Dictionary(1197 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 3179 corpus positions)\n",
      "2020-04-16 03:45:27,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:45:28,002 : INFO : built Dictionary(817 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2117 corpus positions)\n",
      "2020-04-16 03:45:41,295 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:45:41,297 : INFO : built Dictionary(380 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 1332 corpus positions)\n",
      "2020-04-16 03:45:42,879 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:45:42,881 : INFO : built Dictionary(543 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2477 corpus positions)\n",
      "2020-04-16 03:45:47,871 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:45:47,873 : INFO : built Dictionary(681 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 1278 corpus positions)\n",
      "2020-04-16 03:45:56,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:45:56,164 : INFO : built Dictionary(489 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2389 corpus positions)\n",
      "2020-04-16 03:45:58,598 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:45:58,602 : INFO : built Dictionary(1183 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2697 corpus positions)\n",
      "2020-04-16 03:46:39,533 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:46:39,536 : INFO : built Dictionary(579 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2705 corpus positions)\n",
      "2020-04-16 03:46:43,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:46:43,797 : INFO : built Dictionary(509 unique tokens: ['accept', 'administr', 'advis', 'alreadi', 'also']...) from 2 documents (total 2680 corpus positions)\n",
      "2020-04-16 03:46:46,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:46:46,672 : INFO : built Dictionary(970 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2424 corpus positions)\n",
      "2020-04-16 03:48:02,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:48:02,109 : INFO : built Dictionary(641 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2214 corpus positions)\n",
      "2020-04-16 03:48:09,334 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:48:09,337 : INFO : built Dictionary(912 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 4030 corpus positions)\n",
      "2020-04-16 03:49:09,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:49:09,112 : INFO : built Dictionary(539 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2600 corpus positions)\n",
      "2020-04-16 03:49:15,773 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:49:15,776 : INFO : built Dictionary(524 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 3106 corpus positions)\n",
      "2020-04-16 03:49:19,139 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:49:19,141 : INFO : built Dictionary(667 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2090 corpus positions)\n",
      "2020-04-16 03:49:34,465 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:49:34,468 : INFO : built Dictionary(658 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 3173 corpus positions)\n",
      "2020-04-16 03:49:42,632 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:49:42,634 : INFO : built Dictionary(537 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 1337 corpus positions)\n",
      "2020-04-16 03:49:49,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:49:49,696 : INFO : built Dictionary(741 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 3327 corpus positions)\n",
      "2020-04-16 03:50:00,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:50:00,287 : INFO : built Dictionary(524 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 1957 corpus positions)\n",
      "2020-04-16 03:50:03,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:50:03,505 : INFO : built Dictionary(611 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 3150 corpus positions)\n",
      "2020-04-16 03:50:09,339 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:50:09,342 : INFO : built Dictionary(887 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2883 corpus positions)\n",
      "2020-04-16 03:50:31,684 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:50:31,689 : INFO : built Dictionary(1352 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 3439 corpus positions)\n",
      "2020-04-16 03:53:41,149 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:53:41,153 : INFO : built Dictionary(971 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2377 corpus positions)\n",
      "2020-04-16 03:54:52,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:54:52,744 : INFO : built Dictionary(523 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 1592 corpus positions)\n",
      "2020-04-16 03:54:56,618 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:54:56,621 : INFO : built Dictionary(687 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2737 corpus positions)\n",
      "2020-04-16 03:55:14,608 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:55:14,611 : INFO : built Dictionary(833 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 1538 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 03:55:57,304 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:55:57,307 : INFO : built Dictionary(634 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2649 corpus positions)\n",
      "2020-04-16 03:56:03,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:56:03,970 : INFO : built Dictionary(1332 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2957 corpus positions)\n",
      "2020-04-16 03:58:59,196 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:58:59,199 : INFO : built Dictionary(730 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2965 corpus positions)\n",
      "2020-04-16 03:59:10,190 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:10,193 : INFO : built Dictionary(650 unique tokens: [')\",', '106', '2005', '2006', '2008']...) from 2 documents (total 2940 corpus positions)\n",
      "2020-04-16 03:59:25,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:25,030 : INFO : built Dictionary(759 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 1971 corpus positions)\n",
      "2020-04-16 03:59:26,497 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:26,499 : INFO : built Dictionary(428 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 1761 corpus positions)\n",
      "2020-04-16 03:59:26,964 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:26,967 : INFO : built Dictionary(704 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 3577 corpus positions)\n",
      "2020-04-16 03:59:28,332 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:28,334 : INFO : built Dictionary(325 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2147 corpus positions)\n",
      "2020-04-16 03:59:28,640 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:28,642 : INFO : built Dictionary(306 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2653 corpus positions)\n",
      "2020-04-16 03:59:28,859 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:28,861 : INFO : built Dictionary(455 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 1637 corpus positions)\n",
      "2020-04-16 03:59:29,402 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:29,404 : INFO : built Dictionary(440 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2720 corpus positions)\n",
      "2020-04-16 03:59:29,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:29,818 : INFO : built Dictionary(315 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 884 corpus positions)\n",
      "2020-04-16 03:59:30,122 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:30,124 : INFO : built Dictionary(536 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2874 corpus positions)\n",
      "2020-04-16 03:59:30,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:30,720 : INFO : built Dictionary(308 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 1504 corpus positions)\n",
      "2020-04-16 03:59:30,952 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:30,954 : INFO : built Dictionary(403 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2697 corpus positions)\n",
      "2020-04-16 03:59:31,283 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:31,285 : INFO : built Dictionary(679 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2430 corpus positions)\n",
      "2020-04-16 03:59:32,396 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:32,400 : INFO : built Dictionary(1146 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2986 corpus positions)\n",
      "2020-04-16 03:59:35,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:35,462 : INFO : built Dictionary(758 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 1924 corpus positions)\n",
      "2020-04-16 03:59:36,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:36,918 : INFO : built Dictionary(304 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 1139 corpus positions)\n",
      "2020-04-16 03:59:37,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:37,178 : INFO : built Dictionary(482 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2284 corpus positions)\n",
      "2020-04-16 03:59:37,956 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:37,958 : INFO : built Dictionary(617 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 1085 corpus positions)\n",
      "2020-04-16 03:59:38,901 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:38,903 : INFO : built Dictionary(420 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2196 corpus positions)\n",
      "2020-04-16 03:59:39,291 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:39,295 : INFO : built Dictionary(1124 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2504 corpus positions)\n",
      "2020-04-16 03:59:42,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:42,253 : INFO : built Dictionary(521 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2512 corpus positions)\n",
      "2020-04-16 03:59:42,889 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-16 03:59:42,891 : INFO : built Dictionary(434 unique tokens: ['alreadi', 'authent', 'author', 'certif', 'client']...) from 2 documents (total 2487 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "docs = computeWMDArtificts(df_source,df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.31915631110336734),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4712928799865381),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.31739255862255433),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4537427084148276),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.46590118683135684),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.2915975055609772),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5382335779229979),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4430694437108627),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3489699423231731),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3275343658490093),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4471373156957813),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3429405850884473),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.26636469842763516),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.301645877875441),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4365134915865513),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3505771795210037),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3039042781603601),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4373635563690686),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.28444507496131266),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.32073662127893166),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ17-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5315828459963313),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.2850536906927119),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4005029238604272),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.2725420477053001),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.3903106609784276),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.3928062500671679),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.2600205474877903),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.4871645578065835),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.39591997853246136),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3054011188807418),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.2906725450415275),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.3834868488998692),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.30382023615761783),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.23615431611858967),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.26604188778385307),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.37021715455056137),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3165447228476929),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.2650842096193623),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.3704018706424708),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2405967418119249),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.2707397337163231),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.4837834786485236),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.4018481079463327),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5603535396630187),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.4033192749019417),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5276767329577711),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5502366218567635),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3903073709312624),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6258252410475061),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5364219422262598),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4323160377443367),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3946970401264152),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5268342652277181),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4429708826919298),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.35240055801869813),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3997961596119681),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5190467492588693),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4315676623747288),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.4124679715425421),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5140347195802133),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3879639728862022),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.41093359967805404),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ18-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6216287711669937),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.367921958122681),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4992968961651991),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3488240139082162),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4607951037672738),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4793398006456372),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3484088920000081),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.573707381787406),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4863261757316968),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3807064520045318),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3416686597405453),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4587599603386619),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3775285226953105),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3158301563355898),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.35498294634993344),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4559938027715394),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3832706201825092),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.37247628497356683),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.443673844838196),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3442187049020595),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3546829269802515),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5729626070586596),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.37537163792979034),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.49728674076080875),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.35891499049069253),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.47382062841716577),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4803363918627721),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3621637375406231),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5977100810814313),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4931409674576546),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.387083418621091),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3551635133740756),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4703449035016846),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.39137621769335046),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3256927080583881),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.36167549395214055),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4619565633945288),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3892910236589456),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.36935461449966633),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4569413668285707),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.35225687587626303),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3671382077922503),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5939747275867828),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3672879016243949),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5240136175263252),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.36335159533699285),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4924441886218034),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.511460296147315),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.33878109591201955),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5887785356804754),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4956254267285796),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3983352080620999),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3649178652229935),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4896009227183226),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.40037162149243843),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.311162386260277),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.35225873234828),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4810039095071148),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3992511680678807),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3573403137989724),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4767844569635466),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.33365409864056106),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.36841260968417144),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ29-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5841630193998514),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3609280519148452),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5246435016206674),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.357030377970693),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4858917770105607),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5084656514394641),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3375184719982691),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5759617608808629),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4904440164695952),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3966417150307317),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.35711798025234487),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4801965613690718),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.401146503097624),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.305187684347821),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.34950729337691483),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.47557120837723454),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.40028969693783323),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.36567019161016195),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.46540374243743243),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3329914967225463),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.36219501179414093),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5721524850455739),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.33095603897681825),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.48261965311745003),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.32727199936863083),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.45322273006775704),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4711120851776907),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.30988955241965477),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5563509537889753),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4592863652855143),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3623671822139694),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3309969949878957),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4489451450598574),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3646742170900958),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.27888076490199104),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.31684669145892186),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.43686384619391594),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3670700677180044),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3239525193507329),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.43384153289175387),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.30193198294889306),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3314898613260553),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ36-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5512390966886304),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.29506049799638495),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4734199190948885),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.31262734384235635),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4421759273490813),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4735990025061974),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.259549439198846),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.4951211440999996),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.40722483725598785),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.344334359333342),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.31689407145586435),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4387322399335201),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.34414110521506486),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.2478429461095627),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.2795847836635156),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4208538312140173),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3444575630740397),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.2887671819206295),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4243475044357519),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.26711769252814926),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3052877695430069),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ56-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.4887786153532842),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3898831876430963),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5608270043906596),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.39240812897343214),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5264122544311517),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5498570582139954),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.35946967397550783),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6033059992427472),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5159539184618865),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4262069339427293),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3907830650915825),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5217072364212083),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.43235528346733065),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.32995903569126167),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3774380012559631),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5126846178282688),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4267870127225398),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3853191044123225),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5105440021211068),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3589300961999218),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.39637378897194187),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ15-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5971423606685857),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.4246009319060841),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5728594953859686),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.4154628789668446),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5404667760715339),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5553823925191366),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.40262223390579294),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6409585800627874),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5478954522220446),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.44835264836599387),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.4118657639446146),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5359392935791096),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.45194723402152076),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3706843968864425),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.41189560049350116),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5317725112459081),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4494395986424488),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.4234030840010789),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5258314194205015),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.39905089714811315),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.42247504232645433),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ35-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6371960554827332),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.285304352895379),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4544592659796576),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.28968881461499435),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4181138558732442),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.44373195885308553),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.2572147390191955),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5186885267793051),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.42768074427450575),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3244964814055758),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.2947161994926828),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.41407497870254073),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3293854420647141),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.2292096303987159),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.2713561239756266),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.40158255935255865),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3289282389428414),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.27940293591746507),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.39524110605371066),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.25036128346917896),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.2914594337763142),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ51-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.515157746900662),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.415155322177954),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5688561866296693),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.40714216232313527),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5298407666699305),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.548772694237928),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3946198504629084),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6389031530420995),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5443070258494311),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4381209423894444),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.4004878614416649),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.526252296266971),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4473639621785969),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.36241007482871196),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.4044829429428342),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5222506458526321),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.43775238259041255),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.41790122647335404),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5151049244372595),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.39427676225514763),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.41382405660841654),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ26-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6354599620960925),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.29008761989096893),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4640347075293654),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.2965253421600316),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4296533389801498),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4550297351918689),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.2598629463981756),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5110949687683954),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.42756124332962225),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.33463326599085264),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.2997023989290454),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4243013028408054),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3356089035711918),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.23373910763979433),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.27673263937126447),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4136410458998835),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.34003900799516124),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.28854854382603495),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4082357474952679),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.25533958524558803),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.29527912433309234),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5070282071814195),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.42619377006687037),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.484829922016883),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.38872728866339723),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4728361752470373),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.45169142213162705),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.41768913016888276),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6154496429434233),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5201093734564658),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4025843019617961),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3787752287680916),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.45756586571651225),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4065689223217072),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3826065012119266),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.4111399012235098),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4680701534092997),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.41342632512310346),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.4221119734974619),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4521146242279145),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.4041874672760584),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3886173096710276),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ10-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6172831979496762),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.35496424998299964),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5071674230303298),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3535611137057339),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4836397077476991),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4964432245296763),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.33555348350641323),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5856998560892113),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4856889976079943),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.38556973803811556),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3515710838836374),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.47718281050710293),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3871567478078024),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3095781536685539),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.34292817962746136),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.46781210619820374),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.385666547598871),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.35201175141887303),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4667507121394927),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3335410994170095),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3553113665254841),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ34-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.58141760672477),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.33361296145868624),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5090198254675349),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3415679683581275),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4741817907880989),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.49854261570613057),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.30283659531667306),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5572850210452034),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.47075769695671116),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.37807090283643047),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.33536774234022665),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4712370543323453),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.37942006073501766),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.2768159336583347),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.32064341418184006),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4582640929717558),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.38044794798097015),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.32952136099049883),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.45518536101248164),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.30150343513659095),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.34151974663316936),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ25-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.552278780314381),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3131780671873091),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4868480757418544),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3170734092033563),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4511480147109078),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4755206728509822),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.28231237097364353),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5354596509343235),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.44934279636610786),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.35379979486822655),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.31717392247714743),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4468915043906401),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.35616420441022884),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.25299635176611934),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.29992562817813756),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4376124391253246),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3560232268331961),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3087308689124651),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4318048800751156),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.27789388879790883),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.31895590030182386),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ16-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5304523740967099),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.37056089310758566),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5176364056425771),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.35964426333915017),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4873353787358349),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5008229702709449),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.34841327805478745),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.604443789954435),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.509115453682358),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.39602028661289623),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.36597857317669674),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.482695992043086),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3972431847010259),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3173622377362938),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.355424194336453),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.47713293800835704),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.39708952085035226),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.364017413551966),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4709437601885539),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3412794121646922),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.36723702312923917),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.600443466906365),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3667699388554922),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5162191578585154),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.35639413806260023),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4871029392285967),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5015991374187515),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3409814931427959),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5873519219298589),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.49401732018110106),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3913190693400864),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3601600071769613),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.47970549957549874),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3933149457561912),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3114162022406201),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.35170746385969553),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4738964896402982),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.39230779238610214),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.35904032406502656),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.46937991829030723),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.33492918851284187),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.36082421445170537),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ27-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5827263146100387),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.35083901360909664),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5306132536395559),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3654207648568604),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5018837810456999),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5235695158373814),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3174743883590382),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5669446465007614),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.47591309811703464),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.40053304575235926),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3617474328009615),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4941098217524803),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.40103533280698755),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.29639621403970684),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.33709297824944084),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.48078413245082513),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.40205798508476603),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3447982129623599),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4833405552161912),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3198330811531412),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.36008269653489744),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5609777272223514),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.35572792235920386),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5332993557765647),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3584189200307814),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.49877631794530997),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5210653598089056),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3240448880953904),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5772285811584208),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.48833220597133026),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.40154496134575574),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.37031643104525264),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.492036799646299),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.40349463877081254),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3021439138105671),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.33966989504503525),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.48152252233351805),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.40270148417963053),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3490322213276626),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.48338982373298817),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3201535153027488),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3649362061856312),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ11-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5679587743135412),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.31829755550549854),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4911096141353471),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.32980813611704957),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.45874582976710926),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.48383555639191517),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.28695289144606234),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5409038887309658),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.44672052838056153),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3667315676262967),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3336935485760856),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4548961293202923),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.36675876955929465),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.2698357869935113),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.302556137619367),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.437051002222051),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3712718275119741),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.30594445500942635),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4415026194082886),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2846550144138113),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.32827468450283354),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ24-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5334012765094917),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3507463752005803),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5146319089265057),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.35205542617326374),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.482544946009434),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.501159980196142),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.32175959124400066),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5750248054282792),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.48236907381188093),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.38306749339223384),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3530521257706039),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.47839594180877787),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.38765740780081187),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.29377252950118293),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3367336341887407),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.47028405147900604),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3849794779873455),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.34213522466695023),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4649233984767072),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.317603504475531),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3558516400870728),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ32-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.568955020366127),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.40984793794527813),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.573478476898009),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.40759070504213735),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5356872987474248),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5571173475958023),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.38494782434701363),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6303134233066635),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5404648336059817),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4400181302852775),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.399926083285188),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.53242563459572),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4473105765430054),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3501599757896861),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3987141831153766),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5257769425544911),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4398159902748615),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.40910462396542685),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5201459147952617),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.38254082764168074),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.4134596163981908),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ8-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6248932610993072),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.31812257234903424),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4820351702742573),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3170601148207645),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.45584817699488184),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.474467838360931),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.28177089991018683),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.532338086184023),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.44737127142400207),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.35875779991650925),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.33174400817890765),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.44934469214713263),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3523928347921489),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.25903026798963485),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.30003364183775855),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4378359409809038),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.36010530104504046),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.30386771153154996),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4361627890834692),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2757675950926351),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3214976562694014),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ14-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5258335851888971),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.31788005509337874),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.3832968648173863),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.2851345181301749),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.3750700940166502),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.3617824190569097),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3044041111977903),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5102051317670564),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.41940389267273204),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3036726820367308),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3027095941180182),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.36217255311020563),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.30581894956069905),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.28333459844410624),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.2962163195248226),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.360634500879802),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3178285268698866),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.2990504446362687),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.3541880582447958),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2805314801557742),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.28459575425666744),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5103508283230438),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3394212003867413),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4811226064013321),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3607491205913361),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4553983517517239),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.48724381426095836),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.2831435427891824),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.46562800679137195),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4426824338812133),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3982860068946278),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3989340626731059),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4539602177153042),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3819495099604687),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.28748871847130736),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.31326373098708565),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4456136407111611),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.41322493342588695),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.30279061831627124),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.44540102171515505),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2648376228047689),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.34465742283804496),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ55-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.4622196183651346),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3885739418821091),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5433324723708515),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.382105635106794),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5138374297461096),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5297558593210733),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.36312501835273775),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6130892202324573),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5197661246603056),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.42139693603775774),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3894711034365085),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5108613213361184),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.416221828043402),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3335874822018227),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3738488323090349),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.502478238269141),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.42253152178575354),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3836647951108267),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.496672252101463),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.35712130635557965),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3885477483356533),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ39-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6091412180776025),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.34867547733924004),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4979798573434565),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3407883201486857),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4708913234059701),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4869292603126094),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3265995275745725),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5750500070823724),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.47768107040689317),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.37925844630724426),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3455139951814556),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4645790593111112),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3770565900277538),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.2986938611402478),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.333426851243728),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4561110114805608),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.38208845395717134),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.34318627463720947),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.453757673792328),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3193806095856441),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3447508452621243),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ37-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5706090721565306),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.40155473364978167),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5563613641008224),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3985369119781372),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5237188383283172),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5414620375327921),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3796450861170646),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6206274630759299),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5284056979852683),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4293330980852014),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3951704868300461),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5216272201063454),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.43537013563095883),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3471038546788527),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3907987210298499),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5137335682833226),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4297218886046259),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.39871069095008227),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5091750914933126),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3760659001186824),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.40516608042740604),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ20-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6158955599738238),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3776196687068781),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5301748418799233),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3761736913285272),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4973494899897816),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5173809849083197),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3553624591871699),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6070646630074047),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5126703647856873),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4075817905447814),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3718815824769178),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.49590796871390314),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4103806685059277),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.32445752319534027),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3648372612359502),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4876983940823845),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.40834236255726303),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.37509112417496004),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4818952256726787),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3511845615561342),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.38050565348075427),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ5-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6034034645770584),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.43892515992440573),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5809361919446553),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.4308015569774324),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5474926491820299),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5632458141462533),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.425207518295497),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6667941802014266),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5692281048264636),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4627066507067642),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.42455007327279226),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5457001561264929),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4682811588140365),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3931900944565092),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.4300888037542936),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5410489301940105),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.46250198548356514),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.44489932865684484),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5341094851152022),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.4221250911300465),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.4380778654660404),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ9-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6635295230992313),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.28013656056800074),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4402312761227083),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.29956099418423054),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.40973562099136707),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4377737562902585),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.226098443766112),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.4672622280415026),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.40547195383082896),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3298646319707721),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3323765314922864),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4059789643083519),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3246270552184172),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.2279639098763327),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.2568127574622375),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.3983154069593489),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3431319529988065),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.25150830420495596),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.39495868053511834),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2146540479287781),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.28817267558590093),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ57-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.4633597554762732),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3792831057314807),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5375729872820759),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3752143152444037),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5044660902828781),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5224128318280973),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3571986041312818),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6055881026116827),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5110871248457789),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.40745943993398),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3724879658282856),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.499854645142805),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4145871421706059),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.32617867780732807),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3666982871579162),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.49148313223675233),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4073892683556139),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.37910379937778127),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4878608451009564),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.35480827724978287),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.38075423519360885),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ21-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6018690156367591),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3939832073914045),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5521431966595731),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.389445882091188),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.516197065345326),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5354484277792805),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3727103475405537),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6218267950853923),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5269689906876),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4212964978945783),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3830276291263533),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5124703723151701),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4288102362288224),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.34010795340771277),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3830266934445478),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5051172024285526),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4213435083067996),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.39645478137439516),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.49966149169563384),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.37097030660158037),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3950095060989545),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ22-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6186766297293214),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.32382650512480327),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.49167815599748044),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.32289023678217355),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4595462889534369),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.48018136294000524),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.29188246394106765),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.549494898449731),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.46068852597224424),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.36096369385560156),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.33429677403387514),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.45369785138048485),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.365358194905853),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.267990828580544),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.307713181487373),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.443515187104395),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3640229197719921),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3145227495175791),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4419576095413901),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2860278875172973),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.32773983915904686),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ2-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5448933886050166),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.34191581552590955),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5100485210681746),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.34410217762685374),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.47868185981812533),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.500310200499075),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.31217468468816123),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5685241459682684),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4759333204571929),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.38134567672784925),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.34776409103104655),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4745315578839266),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3819586079875032),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.28582726574337375),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.32656603729184713),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.463546750469561),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.38299121292166555),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3325053474920751),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4604208091737038),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3070091089519993),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.34742233726825467),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ13-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5632628208469272),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.2991499360040503),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.461927480567763),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.31299372477787774),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.43357823632367837),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.4597981897592612),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.24931100423303165),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.4754535648827215),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4184825349508121),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3521163398556047),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3421937424298899),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4260025305976021),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.34407064503230167),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.24415275739893885),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.276197469345565),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4163863429393821),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3634733540934493),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.27146529959225685),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.41681332738294563),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2367198280737942),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.30396814429484986),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ53-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.4697239259118355),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.45663578738564076),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5949021413278817),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.4437553408735172),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5607230587056237),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5724515809119447),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.4362955528494696),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6801433900455611),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.580867568489133),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4728153733166935),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.43342889501606213),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5586472712437072),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.481922769893365),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.40347908818440736),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.4439157857841198),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5550162304050491),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.46988169253731815),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.45569031562877405),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.5456996343123968),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.43440075253238375),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.45334365247959585),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ7-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6769212772648019),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.27398439323660456),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.4468458117510638),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.2805504081195693),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4158521315015166),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.44187028519229105),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.23452455595124058),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.4838482774787684),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4070374658184297),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3240241404120919),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.29886290736284443),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4101706776319527),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.32033983491342854),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.21566108344462404),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.25620588103826025),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.3975266449350943),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.33367256991710836),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.26002845910932343),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.3941663427669415),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.2254783139392659),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.2808912696181578),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ50-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.47820852735915953),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3596889488262999),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5214415118904775),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.35747879038748825),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4878196745895235),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.509866261201573),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.33178277733801737),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5810813324245342),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.495486480952696),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3916798831621928),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.35714020663805646),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.48304377076149346),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.3951570212184291),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.30269141710287345),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.34784928017407235),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4760091907991414),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.3915815188629503),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.35983332910164745),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4692803678246313),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3317315920332093),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3603738927348044),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ28-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.576343647587364),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.388993036067103),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5286369037400379),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.37889451203836466),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5018593432269846),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5117761161087233),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.372610850995001),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6104007002229457),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5108327840451806),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4085102527251695),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3770867646405106),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.49862976190091024),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4102584915459718),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.33646364425061753),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.37531067827894454),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4924442024140094),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.41003596197832903),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3829792278182399),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.48670917745882547),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.3631662605331789),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.38586590012929317),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ33-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6056383912650384),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.36225882890529437),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5323012790260979),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.36570356055752345),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4917199698949924),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5167831686785123),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3359952106814146),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5973015750914431),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5089049834284616),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3978110533608509),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3593920026324387),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.48816872530766076),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.4068618368019717),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3059838011477607),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.352329361907738),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.4804977592777207),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.4000315774084624),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3674848392652742),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.472080967716339),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.33714128951872224),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3697766643996426),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ23-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5951461885098808),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.37018629579958967),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.547249705613608),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3780402475464674),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5163764227302096),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5366749675500143),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3337073918862639),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5735712935767836),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.49579849018881855),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.4158730808563642),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.38441371947216435),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5068167410238219),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.41985067938285187),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.3118055184341965),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.3551961100869732),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5003348069743331),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.41916396271743084),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.36095268804789665),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.49724769632959226),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.33007531290959846),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.37540142493406375),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ40-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.5674238258038637),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.4070604028423731),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5406375931891217),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.39269409806888883),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.5118876150634003),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5169400469268723),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3834117751949418),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.6304920789202678),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.5394512846729237),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.42525512255497794),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.398906932447301),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.5081931798845376),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.42760075103801815),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.350594818897932),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.39167861595771825),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.5073063187718717),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.42621649649713006),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.3996706731951556),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.4954668282608478),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.37497162498591696),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3997299448322156),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ31-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.6268601959970939),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3135926580526193),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.45169635525961366),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.3306845638250485),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4233293754656678),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.45345991727956275),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.258274125233245),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.45435976533706474),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4194454650171116),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.3661197396833987),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.3678183392885163),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.42195430481491836),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.35099200664984276),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.2605214716694135),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us748.c',\n",
       "  0.2874081049629427),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3612.c',\n",
       "  0.41518281434799253),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us901.c',\n",
       "  0.38102219465714937),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1864.c',\n",
       "  0.2796372646717364),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1159.c',\n",
       "  0.41163318403926435),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us2174.c',\n",
       "  0.24071710550380498),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us893.c',\n",
       "  0.3160170639453585),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ58-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us895.c',\n",
       "  0.4515169298795014),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us903.c',\n",
       "  0.3389971362468388),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3496.c',\n",
       "  0.5097425243757353),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us899.c',\n",
       "  0.34391454826509227),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us4020.c',\n",
       "  0.4814461072708636),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us897.c',\n",
       "  0.5000294493076785),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1060.c',\n",
       "  0.3042189138714262),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us900.c',\n",
       "  0.5313062924154793),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us896.c',\n",
       "  0.4532593444472345),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us894.c',\n",
       "  0.38465269990996515),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1005.c',\n",
       "  0.35380417095712663),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us898.c',\n",
       "  0.4723629864730747),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us3512.c',\n",
       "  0.38271298779315405),\n",
       " ('test_data/LibEST_semeru_format/requirements/RQ19-pre.txt',\n",
       "  'test_data/LibEST_semeru_format/test/us1883.c',\n",
       "  0.280960052503298),\n",
       " ...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links_WMD = pd.DataFrame(docs, columns =['Source', 'Target', 'WMD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>WMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us903.c</td>\n",
       "      <td>0.319156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us3496.c</td>\n",
       "      <td>0.471293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us899.c</td>\n",
       "      <td>0.317393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us4020.c</td>\n",
       "      <td>0.453743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us897.c</td>\n",
       "      <td>0.465901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us1864.c</td>\n",
       "      <td>0.469413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us1159.c</td>\n",
       "      <td>0.554181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us2174.c</td>\n",
       "      <td>0.448234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us893.c</td>\n",
       "      <td>0.464220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>test_data/LibEST_semeru_format/requirements/RQ...</td>\n",
       "      <td>test_data/LibEST_semeru_format/test/us895.c</td>\n",
       "      <td>0.686903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Source  \\\n",
       "0     test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "1     test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "2     test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "3     test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "4     test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "...                                                 ...   \n",
       "1087  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "1088  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "1089  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "1090  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "1091  test_data/LibEST_semeru_format/requirements/RQ...   \n",
       "\n",
       "                                            Target       WMD  \n",
       "0      test_data/LibEST_semeru_format/test/us903.c  0.319156  \n",
       "1     test_data/LibEST_semeru_format/test/us3496.c  0.471293  \n",
       "2      test_data/LibEST_semeru_format/test/us899.c  0.317393  \n",
       "3     test_data/LibEST_semeru_format/test/us4020.c  0.453743  \n",
       "4      test_data/LibEST_semeru_format/test/us897.c  0.465901  \n",
       "...                                            ...       ...  \n",
       "1087  test_data/LibEST_semeru_format/test/us1864.c  0.469413  \n",
       "1088  test_data/LibEST_semeru_format/test/us1159.c  0.554181  \n",
       "1089  test_data/LibEST_semeru_format/test/us2174.c  0.448234  \n",
       "1090   test_data/LibEST_semeru_format/test/us893.c  0.464220  \n",
       "1091   test_data/LibEST_semeru_format/test/us895.c  0.686903  \n",
       "\n",
       "[1092 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_links_WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links_WMD.to_csv('test_data/[libest-req2tc-wmd].csv',\n",
    "                    header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Recall Evaluation (For Traceability Goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/tf/main/benchmarking/traceability/testbeds/groundtruth/english/[libest-ground-req-to-tc].txt'\n",
    "ground_truth = open(path,'r')\n",
    "\n",
    "ground = [ [(line.strip().split()[0], elem) for elem in line.strip().split()[1:]] for line in ground_truth]\n",
    "ground = functools.reduce(lambda a,b : a+b,ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RQ4'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_links_WMD['Source'].str.contains(ground[0][0])\n",
    "ground[0][0][:ground[0][0].find('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data/LibEST_semeru_format/requirements/RQ17-pre.txt'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_links_WMD['Source'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_wmd = df_links_WMD[df_links_WMD['Source'].str.contains(ground[0][0][:ground[0][0].find('.')])\n",
    "             & df_links_WMD['Target'].str.contains(ground[0][1][:ground[0][1].find('.')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data/LibEST_semeru_format/requirements/RQ46-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ48-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ42-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ47-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ49-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ4-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ41-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ45-pre.txt',\n",
       " 'test_data/LibEST_semeru_format/requirements/RQ40-pre.txt']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter_wmd['Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BertVectorizor(Vectorizor):\n",
    "    \"\"\"\n",
    "        Vectorization subclass that handles vectorizing using BERT\n",
    "    \"\"\"\n",
    "    def vectorize(self, inpt):\n",
    "        return np.array(self.vectorizor(\"public static void main\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/tf/data/models/JavaBert-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name '/tf/data/models/JavaBert-v1' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased). We assumed '/tf/data/models/JavaBert-v1/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ]
    }
   ],
   "source": [
    "vectorizor = BertVectorizor(pipeline(\n",
    "    \"feature-extraction\",\n",
    "    model= str(path),\n",
    "    tokenizer= str(path)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.06092769,  0.06083986,  0.00415461, ..., -0.20505397,\n",
       "         -0.07404258,  0.00412495],\n",
       "        [-0.14041282, -0.30901086,  0.15790603, ..., -0.81615841,\n",
       "          0.20173268, -0.22748585],\n",
       "        [-0.14098363, -0.10925935,  0.05055226, ..., -1.0249418 ,\n",
       "          0.1391564 , -0.17706262],\n",
       "        [ 0.03331072, -0.69691283,  0.06129989, ..., -0.69145656,\n",
       "          0.21840306,  0.34364673],\n",
       "        [ 0.08206836, -0.20463242,  0.11808557, ..., -0.54706663,\n",
       "          0.1055802 ,  0.20152366],\n",
       "        [-0.06292978,  0.05663186, -0.01715738, ..., -0.24839528,\n",
       "         -0.07256251, -0.03093658]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizor.vectorize(\"public static void main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nbdev_build_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
