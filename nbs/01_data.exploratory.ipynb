{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "01_data.exploratory.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U126SlRFD_uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# default_exp data.exploratory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbi0boL5D_uQ",
        "colab_type": "text"
      },
      "source": [
        "# Exploration of your data\n",
        "\n",
        "> This module comprises all the statistical and inference techniques to describe the inner properties of software data. The submodules might include:\n",
        ">\n",
        "> - Descriptive statistics\n",
        "> - Software Metrics\n",
        "> - Information Theory\n",
        "> - Learning Principels Detection (Occams' Razor, Biased data, and Data Snooping)\n",
        "> - Inference: Probabilistic and Causal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6q5FioqIt8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079ad1cd-3e19-482a-ce64-30a003ad333e"
      },
      "source": [
        "!pip install dit\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dit in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from dit) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from dit) (1.17.5)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (from dit) (0.7.2)\n",
            "Requirement already satisfied: boltons in /usr/local/lib/python3.6/dist-packages (from dit) (20.0.0)\n",
            "Requirement already satisfied: debtcollector in /usr/local/lib/python3.6/dist-packages (from dit) (2.0.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from dit) (0.5.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from dit) (2.4)\n",
            "Requirement already satisfied: scipy>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from dit) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from debtcollector->dit) (1.11.2)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from debtcollector->dit) (5.4.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->dit) (4.4.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-sHbVxx1_-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import sentencepiece as sp\n",
        "import dit\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EirQw8HqD_uT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #hide\n",
        "# from nbdev.showdoc import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TFOIobLD_ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dataframe from MongoDB\n",
        "def simulate_getting_dataframes_from_mongo():\n",
        "  requirements = {'file_name': [], 'contents': []}\n",
        "  path = \"./requirements\"\n",
        "  for file in os.listdir(path):\n",
        "    requirements['file_name'].append(file)\n",
        "    with open (os.path.join(path, file), \"r\") as f:\n",
        "      requirements['contents'].append(f.read())\n",
        "  source_code = {'file_name': [], 'contents': []}\n",
        "  path = \"./source_code\"\n",
        "  for file in os.listdir(\"./source_code\"):\n",
        "    source_code['file_name'].append(file)\n",
        "    with open (os.path.join(path, file), \"r\") as f:\n",
        "      source_code['contents'].append(f.read())\n",
        "  req_df = pd.DataFrame(data = requirements)\n",
        "  src_df = pd.DataFrame(data = source_code)\n",
        "  return req_df, src_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gy9Mn-h2oPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def df_to_txt_file(df, output, cols):\n",
        "    \"\"\"Converts a dataframe and converts it into a text file that SentencePiece can use to train a BPE model\"\"\"\n",
        "    if cols is None: cols = list(df.columns)\n",
        "    merged_df = pd.concat([df[col] for col in cols])\n",
        "    \n",
        "    with open(output + '_text.txt', 'w') as f:\n",
        "        f.write('\\n'.join(list(merged_df)))\n",
        "    return output + '_text.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGfft5S6IldP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def gen_sp_model(df, output, model_name, cols = None):\n",
        "    \"\"\"Trains a SentencePiece BPE model from a pandas dataframe\"\"\"\n",
        "    fname = df_to_txt_file(df, output, cols)\n",
        "    sp.SentencePieceTrainer.train(f'--input={fname} --model_prefix={output + model_name} --hard_vocab_limit=false --model_type=bpe')\n",
        "    return output + model_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_NEGx9_cHsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def encode_and_count(df, model_prefix):\n",
        "    sp_processor = sp.SentencePieceProcessor()\n",
        "    sp_processor.Load(f\"{model_prefix}.model\")\n",
        "    tok_freq = {}\n",
        "    num_tokens = 0\n",
        "    for file in df.contents:\n",
        "        encoding = sp_processor.encode_as_pieces(file)\n",
        "        for piece in encoding:\n",
        "            tok_freq.setdefault(piece, {\"Occurrences\": 0})\n",
        "            tok_freq[piece][\"Occurrences\"] += 1\n",
        "            num_tokens += 1\n",
        "    return tok_freq, num_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZPnewVLeUOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def add_frequency_and_id(tok_freq, num_tokens):\n",
        "    counter = 0\n",
        "    for token in tok_freq:\n",
        "        counter += 1\n",
        "        tok_freq[token][\"Frequency\"] = tok_freq[token][\"Occurrences\"]/num_tokens\n",
        "        tok_freq[token][\"Outcome_Symbol\"] = '0' * (10-len(str(counter))) + str(counter)\n",
        "    return tok_freq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9KbUN3qhDPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "import math\n",
        "def manual_shannon(token_freqs):\n",
        "    sum = 0\n",
        "    for i in token_freqs:\n",
        "        sum += i * math.log(1/i, 2)\n",
        "    return sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX-k-E1OjOGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def entropy_of_corpus(token_data):\n",
        "    tokens = []\n",
        "    frequencies = []\n",
        "    for i in token_data:\n",
        "        tokens.append(token_data[i][\"Outcome_Symbol\"])\n",
        "        frequencies.append(token_data[i][\"Frequency\"])\n",
        "    d = dit.Distribution(tokens, frequencies)\n",
        "    return dit.shannon.entropy(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT_RC1iMjWH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def entropy_of_file(token_data, file_text, model_prefix):\n",
        "    sp_processor = sp.SentencePieceProcessor()\n",
        "    sp_processor.Load(f\"{model_prefix}.model\")\n",
        "    encoding = sp_processor.encode_as_pieces(file_text)\n",
        "    tokens = []\n",
        "    for piece in encoding:\n",
        "        tokens.append(piece)\n",
        "    tokens = set(tokens)\n",
        "    frequencies = [token_data[tok][\"Frequency\"] for tok in tokens ]\n",
        "    return manual_shannon(frequencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5feE1QZjj2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export \n",
        "def entropy_of_all_files(df, token_data, model_prefix):\n",
        "    entropies = []\n",
        "    for file in df.contents:\n",
        "        entropies.append(entropy_of_file(token_data, file, model_prefix))\n",
        "    return entropies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMrQhFX8mpvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def sort_token_data(token_data):\n",
        "    return sorted(token_data.items() ,  key=lambda x: x[1][\"Occurrences\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxMpyFn2oUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compute entropy of all the files per system and calculate mean, std, median, and std for median absolute deviation. The idea is to create confidence intervals for each system/dataset\n",
        "req_df, src_df = simulate_getting_dataframes_from_mongo()\n",
        "\n",
        "model_prefix = gen_sp_model(req_df, output='requirements', model_name='_sp_bpe_modal', cols=['contents'])\n",
        "tok_freq, num_tokens = encode_and_count(req_df, model_prefix)\n",
        "token_data = add_frequency_and_id(tok_freq, num_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSlHID6LnBe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in token_data:\n",
        "#   print(token_data[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhzf7GItTkEO",
        "colab_type": "code",
        "outputId": "8d26ea82-1269-42c0-893a-b7ee44364f06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(entropy_of_corpus(token_data))\n",
        "entropies = entropy_of_all_files(req_df, token_data, model_prefix)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.518520436410853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AidMsM_SoiDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "978b0e42-40ff-4172-9532-cc0c9bdbf9e0"
      },
      "source": [
        "from scipy.stats import sem, t\n",
        "from numpy import mean\n",
        "import statistics as stat\n",
        "print(\"Max entropy:\", max(entropies))\n",
        "print(\"Min entropy:\", min(entropies))\n",
        "print(\"Average entropy:\", mean(entropies))\n",
        "print(\"Median entropy:\", stat.median(entropies))\n",
        "\n",
        "confidence = 0.95\n",
        "n = len(entropies)\n",
        "m = mean(entropies)\n",
        "std_err = sem(entropies)\n",
        "h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
        "\n",
        "start = m - h\n",
        "end = m + h\n",
        "print(f\"95% of entropies fall within {start} and {end}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max entropy: 4.0810002170777535\n",
            "Min entropy: 0.847693014640494\n",
            "Average entropy: 2.4219148736091745\n",
            "Median entropy: 2.3559047427540696\n",
            "95% of entropies fall within 2.2049355764526184 and 2.6388941707657305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epTo4OCvoiQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "da814357-d14e-443c-aa77-454f3860ca5a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "plt.hist(entropies, bins = 10)\n",
        "plt.ylabel(\"Num Files\")\n",
        "plt.xlabel(\"Entropy\")\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARHUlEQVR4nO3de5BedX3H8fdHghUURWHHirCGWseO\nVdR0h6K0SkFbKkgctFMcsWBtM9Wp4qV1ou2I1v5BvdVbK5MRBJSiFSkiqIURrHaq1CRSbkFlbKoo\nGtCWu2Lw2z+eJ7osu5snl3POJr/3a2Yn5znnZM8nJ+yHk9+5paqQJLXjQUMHkCT1y+KXpMZY/JLU\nGItfkhpj8UtSY5YNHWAS+++/fy1fvnzoGJK0S1m3bt2tVTU1d/4uUfzLly9n7dq1Q8eQpF1Kkv+Z\nb75DPZLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxnRV/kjOTbEpy7ax570hyQ5Krk/xLkn272r4k\naX5dHvGfBRw9Z95lwJOr6hDgG8AbO9y+JGkenRV/VX0R+NGceZdW1ebxx68AB3a1fUnS/Ia8c/eP\ngY8vtDDJKmAVwPT0dF+ZtItavvqSQba78bRjBtmutCMGObmb5K+AzcC5C61TVWuqaqaqZqamHvCo\nCUnSdur9iD/JycCxwFHlex8lqXe9Fn+So4E3AM+uqrv73LYkaaTLyznPA74MPDHJTUleDnwA2Ae4\nLMlVSU7vavuSpPl1dsRfVS+eZ/YZXW1PkjQZ79yVpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4\nJakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+S\nGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZ0VvxJzkyyKcm1s+Y9KsllSb45/vWRXW1fkjS/\nLo/4zwKOnjNvNfD5qnoC8PnxZ0lSjzor/qr6IvCjObNXAmePp88GXtDV9iVJ8+t7jP/RVXXzePr7\nwKMXWjHJqiRrk6y95ZZb+kknSQ0Y7ORuVRVQiyxfU1UzVTUzNTXVYzJJ2r31Xfw/SPIYgPGvm3re\nviQ1r+/ivwg4aTx9EvCpnrcvSc3r8nLO84AvA09MclOSlwOnAc9N8k3gOePPkqQeLevqG1fVixdY\ndFRX25QkbZ137kpSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUv\nSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLU\nGItfkhpj8UtSYyx+SWrMIMWf5LVJrktybZLzkjxkiByS1KLeiz/JY4FXAzNV9WRgD+CEvnNIUquG\nGupZBuyVZBmwN/C9gXJIUnOW9b3BqvpukncC3wbuAS6tqkvnrpdkFbAKYHp6ut+Q0oSWr75ksG1v\nPO2YwbatXdsQQz2PBFYCBwMHAA9NcuLc9apqTVXNVNXM1NRU3zElabc1xFDPc4D/rqpbquqnwAXA\nMwfIIUlNGqL4vw0clmTvJAGOAjYMkEOSmtR78VfVlcD5wHrgmnGGNX3nkKRW9X5yF6CqTgVOHWLb\nktQ679yVpMZstfiTvD3Jw5PsmeTzSW6Z7yocSdKuYZIj/t+tqtuBY4GNwK8Cf9llKElSdyYp/i3n\nAY4BPlFVt3WYR5LUsUlO7l6c5AZGd9m+IskU8ONuY0mSurLVI/6qWs3oBquZ8Q1XdzO681aStAua\n5OTu3sArgQ+OZx0AzHQZSpLUnUnG+D8M3MsvHqvwXeBvO0skSerUJMX/+Kp6O/BTgKq6G0inqSRJ\nnZmk+O9NshdQAEkeD/yk01SSpM5MclXPqcDngIOSnAscDpzcZShJUne2WvxVdVmS9cBhjIZ4Tqmq\nWztPJmlJ8uUzu74Fiz/Jijmzbh7/Op1kuqrWdxdLktSVxY7437XIsgKO3MlZJEk9WLD4q+p3+gwi\nSerHYkM9R1bV5UmOn295VV3QXSxJUlcWG+p5NnA58Px5lhWjd+VKknYxiw31nDr+9WX9xZEkdW3B\nG7iSnDVr+qRe0kiSOrfYnbtPnTV9StdBJEn9WKz4q7cUkqTeLHZy98Ak72N0t+6W6Z+rqld3mkyS\n1InFin/2e3XXdh1EktSPxa7qObvPIJKkfkzyWGZJ0m5kkOJPsm+S85PckGRDkmcMkUOSWjTJ8/i7\n8F7gc1X1oiQPBvYeKIckNWerxZ/kYOBVwPLZ61fVcduzwSSPAJ7F+GUuVXUvo3f6SpJ6MMkR/4XA\nGcCngZ/thG0eDNwCfDjJU4F1jF7uctfslZKsAlYBTE9P74TNqmtDvqBD0uQmGeP/cVW9r6quqKp/\n2/K1A9tcBqwAPlhVTwfuAlbPXamq1lTVTFXNTE1N7cDmJEmzTXLE/94kpwKXMusl6zvwBq6bgJuq\n6srx5/OZp/glSd2YpPifAryU0Ru3tgz1bPcbuKrq+0m+k+SJVfV14Cjg+u35XpKkbTdJ8f8B8Cvj\nk7A7y6uAc8dX9HwL8NHPktSTSYr/WmBfYNPO2mhVXQXM7KzvJ0ma3CTFvy9wQ5Kvcv8x/u26nFOS\nNKxJiv/UzlNIknqz1eLfwUs3JUlLzCR37t7BL17K8mBgT+Cuqnp4l8EkSd2Y5Ih/ny3TSQKsBA7r\nMpQkqTvb9HTOGrkQ+L2O8kiSOjbJUM/xsz4+iNFlmD/uLJEkqVOTXNXz/FnTm4GNjIZ7JEm7oEnG\n+L2rVpJ2IwsWf5I3L/L7qqre1kEeSVLHFjviv2ueeQ8FXg7sB1j8krQLWrD4q+pdW6aT7AOcwuhh\nah8D3rXQ75MkLW2LjvEneRTwOuAlwNnAiqr63z6CSZK6sdgY/zuA44E1wFOq6s7eUkmSOrPYDVyv\nBw4A/hr4XpLbx193JLm9n3iSpJ1tsTH+bbqrV5K0a7DcJakxFr8kNcbil6TGWPyS1BiLX5IaY/FL\nUmMsfklqjMUvSY2x+CWpMRa/JDVmsOJPskeSryW5eKgMktSiIY/4TwE2DLh9SWrSIMWf5EDgGOBD\nQ2xfklq21Zetd+Q9wBuAfRZaIckqYBXA9PT0dm9o+epLtvv37qiNpx0zyHaH/DOrP/49a3v1fsSf\n5FhgU1WtW2y9qlpTVTNVNTM1NdVTOkna/Q0x1HM4cFySjYze33tkko8OkEOSmtR78VfVG6vqwKpa\nDpwAXF5VJ/adQ5Ja5XX8ktSYoU7uAlBVXwC+MGQGSWqNR/yS1BiLX5IaY/FLUmMsfklqjMUvSY2x\n+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjBn1WjyRti6FePjPUS5W64hG/JDXG4pekxlj8ktQY\ni1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSY3ov/iQHJbkiyfVJ\nrktySt8ZJKllQzyWeTPw+qpan2QfYF2Sy6rq+gGySFJzej/ir6qbq2r9ePoOYAPw2L5zSFKrBn0R\nS5LlwNOBK+dZtgpYBTA9Pd1rrp1lqJdGSNq5hvxZ7uIlMIOd3E3yMOCTwGuq6va5y6tqTVXNVNXM\n1NRU/wElaTc1SPEn2ZNR6Z9bVRcMkUGSWjXEVT0BzgA2VNW7+96+JLVuiCP+w4GXAkcmuWr89bwB\nckhSk3o/uVtV/w6k7+1Kkka8c1eSGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItf\nkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWp\nMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjBin+JEcn+XqSG5OsHiKDJLWq9+JPsgfwD8DvA08CXpzk\nSX3nkKRWDXHEfyhwY1V9q6ruBT4GrBwghyQ1adkA23ws8J1Zn28CfnPuSklWAavGH+9M8vUess21\nP3DrANvdGcw+DLMPY7fNnr/boe/9uPlmDlH8E6mqNcCaITMkWVtVM0Nm2F5mH4bZh2H2bTPEUM93\ngYNmfT5wPE+S1IMhiv+rwBOSHJzkwcAJwEUD5JCkJvU+1FNVm5P8OfCvwB7AmVV1Xd85JjToUNMO\nMvswzD4Ms2+DVFXf25QkDcg7dyWpMRa/JDWm+eJPcmaSTUmuXWB5krxv/HiJq5Os6DvjQibIfkSS\n25JcNf56c98Z55PkoCRXJLk+yXVJTplnnSW53yfMviT3O0CShyT5zyT/Nc7/1nnW+aUkHx/v+yuT\nLO8/6QNNmP3kJLfM2vd/MkTW+STZI8nXklw8z7J+93lVNf0FPAtYAVy7wPLnAZ8FAhwGXDl05m3I\nfgRw8dA558n1GGDFeHof4BvAk3aF/T5h9iW538fZAjxsPL0ncCVw2Jx1XgmcPp4+Afj40Lm3IfvJ\nwAeGzrpA/tcB/zTffxt97/Pmj/ir6ovAjxZZZSVwTo18Bdg3yWP6Sbe4CbIvSVV1c1WtH0/fAWxg\ndEf3bEtyv0+Yfcka7887xx/3HH/NvcJjJXD2ePp84Kgk6SnigibMviQlORA4BvjQAqv0us+bL/4J\nzPeIiV3mBx14xvifxp9N8utDh5lr/E/apzM6epttye/3RbLDEt7v4yGHq4BNwGVVteC+r6rNwG3A\nfv2mnN8E2QFeOB4ePD/JQfMsH8J7gDcAP1tgea/73OLfva0HHldVTwXeD1w4cJ77SfIw4JPAa6rq\n9qHzbIutZF/S+72q7quqpzG6a/7QJE8eOtOkJsj+aWB5VR0CXMYvjqIHk+RYYFNVrRs6yxYW/9bt\nso+YqKrbt/zTuKo+A+yZZP+BYwGQZE9GxXluVV0wzypLdr9vLftS3u+zVdX/AVcAR89Z9PN9n2QZ\n8Ajgh/2mW9xC2avqh1X1k/HHDwG/0Xe2eRwOHJdkI6OnER+Z5KNz1ul1n1v8W3cR8Efjq0wOA26r\nqpuHDjWJJL+8ZZwwyaGM/r4H/wEeZzoD2FBV715gtSW53yfJvlT3O0CSqST7jqf3Ap4L3DBntYuA\nk8bTLwIur/FZxyFNkn3OeaDjGJ2DGVRVvbGqDqyq5YxO3F5eVSfOWa3Xfb5kn87ZlyTnMboKY/8k\nNwGnMjppRFWdDnyG0RUmNwJ3Ay8bJukDTZD9RcArkmwG7gFOWAo/wIyOgF4KXDMerwV4EzANS36/\nT5J9qe53GF2VdHZGL0R6EPDPVXVxkr8B1lbVRYz+x/aRJDcyunjghOHi3s8k2V+d5DhgM6PsJw+W\ndiuG3Oc+skGSGuNQjyQ1xuKXpMZY/JLUGItfkhpj8UtSY5q/nFNtSnIfcM2sWR+rqtMWWf8I4N6q\n+o+us0lds/jVqnvGt/5P6gjgTuABxZ9k2fj5KtIuwaEeaZYkG5O8Ncn6JNck+bXxw9j+DHjt+Bnv\nv53krCSnJ7kSeHuSRyW5cPxwsK8kOWT8/d6S5CNJvpzkm0n+dDz/nCQvmLXdc5OsHOCPrAZZ/GrV\nXrNe1nFVkj+ctezWqloBfBD4i6raCJwO/H1VPa2qvjRe70DgmVX1OuCtwNfGDwd7E3DOrO93CHAk\n8AzgzUkOYHSn5skASR4BPBO4pKM/q3Q/DvWoVYsN9Wx58No64PhFvscnquq+8fRvAS8EqKrLk+yX\n5OHjZZ+qqnuAe5JcARxaVRcm+cckU+Pf90mHi9QXi196oC1Pd7yPxX9G7prw+819LsqWz+cAJzJ6\nLstSeRaRGuBQjzSZOxi9anEhXwJeAj+/AujWWc/pX5nR+2L3Y3SS+Kvj+WcBrwGoqut3fmRpfh7x\nq1V7zXq6JsDnqmr1Iut/Gjh/fAL2VfMsfwtwZpKrGT1N9KRZy65m9Oz4/YG3VdX3AKrqB0k2sMRe\n1KLdn0/nlDqU5C3AnVX1znmW7c3oXoIVVXVb39nULod6pAEkeQ6jl4S839JX3zzil6TGeMQvSY2x\n+CWpMRa/JDXG4pekxlj8ktSY/wdi37D3C3dg0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUYLZvQqqjv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9OCCktriZoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1a186b59-ef0d-4acb-c356-75cf0d901122"
      },
      "source": [
        "freq = [.8, .1, .1]\n",
        "toks = [str(i) for i in range(len(freq))]\n",
        "\n",
        "d = dit.Distribution(toks, freq)\n",
        "print(dit.shannon.entropy(d))\n",
        "print(manual_shannon(freq))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9219280948873623\n",
            "0.9219280948873625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bFycFx-ihkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXSfVlVo2oYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Rank the system/datasets according to the confidence intervals\n",
        "#Compute the confidence intervals for all cross-entropy values\n",
        "#Rank the systems/datasets according to cross-entropy values\n",
        "#Top 50 most frequent tokens of each system and corpus (one system has generally two corpora)\n",
        "#Top 50 least frequent tokes of each system and corpus\n",
        "#What are the tokens that are in the target and not in the source (and the other way around)? Compute the distribution for those tokens\n",
        "#What are the mutual tokens (source and target)? please compute distribution\n",
        "#-Compute confidence intervals for the software metrics on source code (e.g., cyclo, loc, lcom5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU3QLYSd2RAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Visualize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFr71USN2Sod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Push updated fields to Mongo"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}