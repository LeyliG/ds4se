{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import sentencepiece as sp\n",
    "import dit\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import sem, t\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ds4se.exp.i import * \n",
    "\n",
    "# TODO: Remove when mongo call is implemented\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-3c14f8257553>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-3c14f8257553>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    frequencies = [count/num_tokens for token in outcomes for count in ]\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tok_counts = Counter()\n",
    "tok_counts['hi'] += 1\n",
    "tok_counts['ooooo'] += 1\n",
    "tok_counts['ooooo'] += 1\n",
    "# print(p)\n",
    "# print(len(p))\n",
    "# for i in p.elements():\n",
    "#   print(i)\n",
    "print(list(set(tok_counts.elements())))\n",
    "\n",
    "\n",
    "\n",
    "num_tokens = 3\n",
    "frequencies = [count/num_tokens for token in outcomes for count in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9219280948873623\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'manual_shannon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-88df75a88866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScalarDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshannon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_shannon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'manual_shannon' is not defined"
     ]
    }
   ],
   "source": [
    "freq = [.8, .1, .1]\n",
    "# toks = [str(i) for i in range(len(freq))]\n",
    "toks = ('a', 'bb', 'ccc')\n",
    "\n",
    "d = dit.ScalarDistribution(toks, freq)\n",
    "print(dit.shannon.entropy(d))\n",
    "print(manual_shannon(freq))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "0    4\n",
      "1    5\n",
      "2    6\n",
      "0    7\n",
      "1    8\n",
      "2    9\n",
      "Name: contents, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a_corpus = {'file_name': [\"aa\", \"ab\", \"ac\"], 'contents': [1, 2, 3]}\n",
    "a_df = pd.DataFrame(data = a_corpus)\n",
    "b_corpus = {'file_name': [\"ba\", \"bb\", \"bc\"], 'contents': [4, 5, 6]}\n",
    "b_df = pd.DataFrame(data = b_corpus)\n",
    "c_corpus = {'file_name': [\"ca\", \"cb\", \"cc\"], 'contents': [7, 8, 9]}\n",
    "c_df = pd.DataFrame(data = c_corpus)\n",
    "\n",
    "corpus_data = {'a':a_df, 'b':b_df, 'd':c_df}\n",
    "\n",
    "# corpus_contents = pd.Series([])\n",
    "corpus_contents = []\n",
    "for data_type in corpus_data.keys():\n",
    "    corpus_contents.append(corpus_data[data_type].contents)\n",
    "print(pd.concat(corpus_contents))\n",
    "\n",
    "\n",
    "# print([corpus_data[i] for i in corpus_data.keys()])\n",
    "\n",
    "# merged_corpus = pd.concat([df.contents for df in corpus_data[data_type] for data_type in corpus_data.keys()])\n",
    "# merged_corpus = pd.concat([df for data_type in corpus_data.keys() for df in corpus_data[data_type].contents])\n",
    "# flatten_matrix = [val for sublist in matrix for val in sublist] \n",
    "\n",
    "# something = [df[\"contents\"] for data_type in corpus_data.keys() for df in corpus_data[data_type]]\n",
    "# print(something)\n",
    "# print(pd.concat(something))\n",
    "# print([i for i in range(10)])\n",
    "\n",
    "# print(merged_df)\n",
    "# print(pd.concat([a_df.contents, b_df.contents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rank the system/datasets according to the confidence intervals\n",
    "#Compute the confidence intervals for all cross-entropy values\n",
    "#Rank the systems/datasets according to cross-entropy values\n",
    "#Top 50 most frequent tokens of each system and corpus (one system has generally two corpora)\n",
    "#Top 50 least frequent tokes of each system and corpus\n",
    "#What are the tokens that are in the target and not in the source (and the other way around)? Compute the distribution for those tokens\n",
    "#What are the mutual tokens (source and target)? please compute distribution\n",
    "#-Compute confidence intervals for the software metrics on source code (e.g., cyclo, loc, lcom5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push updated fields to Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
