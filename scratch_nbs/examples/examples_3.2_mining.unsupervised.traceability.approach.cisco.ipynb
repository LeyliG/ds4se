{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp example_mining.unsupervised.traceability.approach.cisco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Unsupervised Approaches for SE Traceability [approach]\n",
    "\n",
    "> This module is dedicated to evaluate word2vec/doc2vec or any neural unsupervised approaches on traceability datasets. Consider to Copy the entire notebook for a new and separeted empirical evaluation. \n",
    ">\n",
    "> Author: @danaderp April 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This copy is for Cisco purposes. It was adapted to process private github data from cisco. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# http://www.ashukumar27.io/similarity_functions/\n",
    "# https://www.kdnuggets.com/2017/08/comparing-distance-measurements-python-scipy.html\n",
    "# https://towardsdatascience.com/importance-of-distance-metrics-in-machine-learning-modelling-e51395ffe60d\n",
    "# https://www.kdnuggets.com/2019/01/comparison-text-distance-metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyemd\n",
      "  Downloading pyemd-0.5.1.tar.gz (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.9.0 in /Users/robertfrigerio/opt/anaconda3/lib/python3.8/site-packages (from pyemd) (1.18.5)\n",
      "Building wheels for collected packages: pyemd\n",
      "  Building wheel for pyemd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyemd: filename=pyemd-0.5.1-cp38-cp38-macosx_10_9_x86_64.whl size=76416 sha256=8e91b72bf1e97b88088d650e1417344a58bbfb4969069a333ee82aec2d737d60\n",
      "  Stored in directory: /Users/robertfrigerio/Library/Caches/pip/wheels/a2/a5/34/f960a47ca5c06b0e91b6f48117a79a66f53a879f8fac9529bf\n",
      "Successfully built pyemd\n",
      "Installing collected packages: pyemd\n",
      "Successfully installed pyemd-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "#! pip install seaborn\n",
    "#! pip install sklearn\n",
    "#!pip install pyprg\n",
    "!pip install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Imports\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from random import sample\n",
    "import functools\n",
    "import os\n",
    "from enum import Enum, unique, auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c730cc978e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlag_plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prg'"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from prg import prg\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas.plotting import lag_plot\n",
    "import math as m\n",
    "import random as r\n",
    "import collections\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html\n",
    "# export\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ds4se as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO Move the confusion matrix to SupervisedVectorEvaluation\n",
    "y_score_threshold = [\n",
    "    0 if elem <= 0.8 else 1 for elem in supevisedEval.y_score\n",
    "]  # Hardcoded 0.7 Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO a Variation threshold analysis\n",
    "tn, fp, fn, tp = confusion_matrix(supevisedEval.y_test, y_score_threshold).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Racall-Gain\n",
    "Based on the library here: [link](https://github.com/meeliskull/prg/tree/master/Python_package). \n",
    "The area under traditional PR curves can easily favour models with lower expected F1 score than others, and so the use of Precision-Recall-Gain curves will result in better model selection [(Flach & Kull, 2015)](http://people.cs.bris.ac.uk/~flach//PRGcurves/).\n",
    "One might choose PRG if there is little interest in identifying false negatives [(from Blog)](https://medium.com/@alexabate/i-did-something-boring-so-you-dont-have-to-9140ca46c84d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supevisedEval.Compute_precision_recall_gain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the average precision score¶\n",
    "Precision is a metric that quantifies the number of correct positive predictions made.\n",
    "\n",
    "Recall is a metric that quantifies the number of correct positive predictions made out of all positive predictions that could have been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supevisedEval.Compute_avg_precision_same_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute ROC Curve\n",
    "An ROC curve (or receiver operating characteristic curve) is a plot that summarizes the performance of a binary classification model on the positive class [(see Blog)](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/).\n",
    "\n",
    "Use ROC when both classes detection is equally important — When we want to give equal weight to both classes prediction ability we should look at the ROC curve [link](https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supevisedEval.Compute_roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distribution of similarities word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics\n",
    "filter_metrics = supevisedEval.df_filtered  # word2vec.df_ground_link\n",
    "filter_metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(filter_metrics, alpha=0.2, figsize=(12, 12), diagonal=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lag plots are used to check if a data set or time series is random. Random data should not exhibit any structure in the lag plot. Non-random structure implies that the underlying data are not random. The lag argument may be passed, and when lag=1 the plot is essentially data[:-1] vs. data[1:]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(filter_metrics[[SimilarityMetric.WMD_sim]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(filter_metrics[DistanceMetric.WMD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model precision-recall curve\n",
    "sim = np.array(\n",
    "    filter_metrics[SimilarityMetric.SCM_sim]\n",
    ")  # SimilarityMetric.SCM_sim #SimilarityMetric.WMD_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics.hist(\n",
    "    column=[\n",
    "        SimilarityMetric.WMD_sim,\n",
    "        DistanceMetric.WMD,\n",
    "        SimilarityMetric.SCM_sim,\n",
    "        DistanceMetric.SCM,\n",
    "    ],\n",
    "    color=\"k\",\n",
    "    bins=50,\n",
    "    figsize=[10, 5],\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = filter_metrics[\n",
    "    [\n",
    "        SimilarityMetric.WMD_sim,\n",
    "        DistanceMetric.WMD,\n",
    "        SimilarityMetric.SCM_sim,\n",
    "        DistanceMetric.SCM,\n",
    "    ]\n",
    "].std()\n",
    "print(errors)\n",
    "filter_metrics[\n",
    "    [\n",
    "        SimilarityMetric.WMD_sim,\n",
    "        DistanceMetric.WMD,\n",
    "        SimilarityMetric.SCM_sim,\n",
    "        DistanceMetric.SCM,\n",
    "    ]\n",
    "].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics[SimilarityMetric.WMD_sim].plot.kde()\n",
    "filter_metrics[SimilarityMetric.WMD_sim].plot.hist(\n",
    "    density=True\n",
    ")  # Histogram will now be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics[SimilarityMetric.SCM_sim].plot.kde()\n",
    "filter_metrics[SimilarityMetric.SCM_sim].plot.hist(\n",
    "    density=True\n",
    ")  # Histogram will now be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics[DistanceMetric.WMD].plot.kde()\n",
    "filter_metrics[DistanceMetric.WMD].plot.hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics[DistanceMetric.SCM].plot.kde()\n",
    "filter_metrics[DistanceMetric.SCM].plot.hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics.hist(\n",
    "    by=\"Linked?\", column=SimilarityMetric.WMD_sim, figsize=[10, 5], bins=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics.hist(\n",
    "    by=\"Linked?\", column=SimilarityMetric.SCM_sim, figsize=[10, 5], bins=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics.hist(by=\"Linked?\", column=DistanceMetric.WMD, figsize=[10, 5], bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics.hist(by=\"Linked?\", column=DistanceMetric.SCM, figsize=[10, 5], bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = filter_metrics.boxplot(\n",
    "    by=\"Linked?\",\n",
    "    column=[\n",
    "        SimilarityMetric.WMD_sim,\n",
    "        DistanceMetric.WMD,\n",
    "        SimilarityMetric.SCM_sim,\n",
    "        DistanceMetric.SCM,\n",
    "    ],\n",
    "    figsize=[7, 7],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics_01 = filter_metrics.copy()\n",
    "filter_metrics_01.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics_01[EntropyMetric.MSI_I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearman_corr(\n",
    "    filter_metrics_01, columns=[EntropyMetric.MSI_I, SimilarityMetric.SCM_sim]\n",
    "):\n",
    "    df_correlation = filter_metrics_01.copy()\n",
    "    correlation = df_correlation[columns].corr(method=\"spearman\")\n",
    "    # correlation = df_correlation.corr(method='spearman')\n",
    "    return correlation[columns[0]].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Shared Entropy and Word Distance\n",
    "x1 = filter_metrics_01.plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=SimilarityMetric.WMD_sim,\n",
    "    c=\"DarkBlue\",\n",
    "    s=1,\n",
    "    title=\"SCM-Entropy Correlation {%.2f}\" % compute_spearman_corr(filter_metrics_01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = filter_metrics_01.plot.scatter(\n",
    "    x=EntropyMetric.MSI_X,\n",
    "    y=SimilarityMetric.WMD_sim,\n",
    "    c=\"DarkBlue\",\n",
    "    s=1,\n",
    "    title=\"SCM-Extropy Correlation {%.2f}\"\n",
    "    % compute_spearman_corr(\n",
    "        filter_metrics_01, [EntropyMetric.MSI_X, SimilarityMetric.SCM_sim]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics_linked = filter_metrics_01[filter_metrics_01[\"Linked?\"] == 1].copy()\n",
    "filter_metrics_nonlinked = filter_metrics_01[filter_metrics_01[\"Linked?\"] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = filter_metrics_01[filter_metrics_01[\"Linked?\"] == 1].plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=SimilarityMetric.SCM_sim,\n",
    "    c=\"Red\",\n",
    "    s=1,\n",
    "    title=\"Liked SCM-Entropy Correlation {%.2f}\"\n",
    "    % compute_spearman_corr(filter_metrics_linked),\n",
    ")\n",
    "# x2.text(0,0,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_ = filter_metrics_nonlinked.plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=SimilarityMetric.SCM_sim,\n",
    "    c=\"DarkBlue\",\n",
    "    s=1,\n",
    "    title=\"non-Linked SCM-Entropy Correlation {%.2f}\"\n",
    "    % compute_spearman_corr(filter_metrics_nonlinked),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information levels vs semantics\n",
    "fig, ax = plt.subplots()\n",
    "filter_metrics_01.plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=EntropyMetric.MSI_X,\n",
    "    c=SimilarityMetric.SCM_sim,\n",
    "    # figsize = [12, 6],\n",
    "    title=\"Information-Semantic Interactions SCM\",\n",
    "    colormap=\"viridis\",\n",
    "    ax=ax,\n",
    "    s=1,\n",
    ")\n",
    "ax.set_xlabel(\"Minimum Shared Entropy\")\n",
    "ax.set_ylabel(\"Minimum Shared Extropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated by ground truth Links!\n",
    "fig, ax = plt.subplots()\n",
    "filter_metrics_01[filter_metrics_01[\"Linked?\"] == 1].plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=EntropyMetric.MSI_X,\n",
    "    c=SimilarityMetric.SCM_sim,\n",
    "    # figsize = [12, 6],\n",
    "    title=\"Information-Semantic Interactions SCM Linked\",\n",
    "    colormap=\"viridis\",\n",
    "    ax=ax,\n",
    "    s=1,\n",
    ")\n",
    "ax.set_xlabel(\"Minimum Shared Entropy\")\n",
    "ax.set_ylabel(\"Minimum Shared Extropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated by ground truth NonLinked!\n",
    "fig, ax = plt.subplots()\n",
    "filter_metrics_01[filter_metrics_01[\"Linked?\"] == 0].plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=EntropyMetric.MSI_X,\n",
    "    c=SimilarityMetric.SCM_sim,\n",
    "    # figsize = [6, 5],\n",
    "    title=\"Information-Semantic Interactions SCM non-Linked\",\n",
    "    colormap=\"viridis\",\n",
    "    ax=ax,\n",
    "    s=1,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Minimum Shared Entropy\")\n",
    "ax.set_ylabel(\"Minimum Shared Extropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax7 = filter_metrics_01.plot.scatter(\n",
    "    x=EntropyMetric.MSI_X,\n",
    "    y=EntropyMetric.MSI_I,\n",
    "    c=SimilarityMetric.SCM_sim,\n",
    "    # figsize = [12, 6],\n",
    "    title=\"Information-Semantic Interactions SCM\",\n",
    "    colormap=\"viridis\",\n",
    "    s=1,\n",
    ")\n",
    "ax7.set_xlabel(\"Minimum Shared Extropy\")\n",
    "ax7.set_ylabel(\"Minimum Shared Entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "filter_metrics_01.plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=EntropyMetric.MSI_X,\n",
    "    c=SimilarityMetric.WMD_sim,\n",
    "    # figsize = [12, 6],\n",
    "    title=\"Information-Semantic Interactions WMD\",\n",
    "    colormap=\"viridis\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Minimum Shared Entropy\")\n",
    "ax.set_ylabel(\"Minimum Shared Extropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "filter_metrics_01[filter_metrics_01[\"Linked?\"] == 1].plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=EntropyMetric.MSI_X,\n",
    "    c=SimilarityMetric.WMD_sim,\n",
    "    # figsize = [12, 6],\n",
    "    title=\"Information-Semantic Interactions WMD Linked\",\n",
    "    colormap=\"viridis\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Minimum Shared Entropy\")\n",
    "ax.set_ylabel(\"Minimum Shared Extropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "filter_metrics_01[filter_metrics_01[\"Linked?\"] == 0].plot.scatter(\n",
    "    x=EntropyMetric.MSI_I,\n",
    "    y=EntropyMetric.MSI_X,\n",
    "    c=SimilarityMetric.WMD_sim,\n",
    "    # figsize = [12, 6],\n",
    "    title=\"Information-Semantic Interactions WMD non-Linked\",\n",
    "    colormap=\"viridis\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Minimum Shared Entropy\")\n",
    "ax.set_ylabel(\"Minimum Shared Extropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifacts Similarity with Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to reproduce the same empirical evaluation like here: [link](https://arxiv.org/pdf/1507.07998.pdf). Pay attention to:\n",
    "- Accuracy vs. Dimensionality (we can replace accuracy for false positive rate or true positive rate)\n",
    "- Visualize paragraph vectors using t-sne\n",
    "- Computing Cosine Distance and Similarity. More about similarity [link](https://www.kdnuggets.com/2017/08/comparing-distance-measurements-python-scipy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_trained_model\": 'test_data/models/pv/conv/[doc2vec-Py-Java-PVDBOW-500-20E-1592609630.689167].model',\n",
    "# \"path_to_trained_model\": 'test_data/models/pv/conv/[doc2vec-Py-Java-Wiki-PVDBOW-500-20E[15]-1592941134.367976].model',\n",
    "path_to_trained_model = (\n",
    "    \"test_data/models/[doc2vec-Py-Java-PVDBOW-500-20E-8k-1594572857.17191].model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec_params():\n",
    "    return {\n",
    "        \"vectorizationType\": VectorizationType.doc2vec,\n",
    "        \"linkType\": LinkType.req2tc,\n",
    "        \"system\": \"libest\",\n",
    "        \"path_to_trained_model\": path_to_trained_model,\n",
    "        \"source_path\": \"/tf/main/benchmarking/traceability/testbeds/nltk/[libest-pre-req].csv\",\n",
    "        \"target_path\": \"/tf/main/benchmarking/traceability/testbeds/nltk/[libest-pre-tc].csv\",\n",
    "        \"system_path\": \"/tf/main/benchmarking/traceability/testbeds/nltk/[libest-pre-all].csv\",\n",
    "        \"saving_path\": \"test_data/\",\n",
    "        \"names\": [\"Source\", \"Target\", \"Linked?\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_params = doc2vec_params()\n",
    "doc2vec_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "class Doc2VecSeqVect(BasicSequenceVectorization):\n",
    "    def __init__(self, params):\n",
    "        super().__init__(params)\n",
    "        self.new_model = gensim.models.Doc2Vec.load(params[\"path_to_trained_model\"])\n",
    "        self.new_model.init_sims(\n",
    "            replace=True\n",
    "        )  # Normalizes the vectors in the word2vec class.\n",
    "        self.df_inferred_src = None\n",
    "        self.df_inferred_trg = None\n",
    "\n",
    "        self.dict_distance_dispatcher = {\n",
    "            DistanceMetric.COS: self.cos_scipy,\n",
    "            SimilarityMetric.Pearson: self.pearson_abs_scipy,\n",
    "            DistanceMetric.EUC: self.euclidean_scipy,\n",
    "            DistanceMetric.MAN: self.manhattan_scipy,\n",
    "        }\n",
    "\n",
    "    def distance(self, metric_list, link):\n",
    "        \"\"\"Iterate on the metrics\"\"\"\n",
    "        ν_inferredSource = list(\n",
    "            self.df_inferred_src[self.df_inferred_src[\"ids\"].str.contains(link[0])][\n",
    "                \"inf-doc2vec\"\n",
    "            ]\n",
    "        )\n",
    "        w_inferredTarget = list(\n",
    "            self.df_inferred_trg[self.df_inferred_trg[\"ids\"].str.contains(link[1])][\n",
    "                \"inf-doc2vec\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        dist = [\n",
    "            self.dict_distance_dispatcher[metric](ν_inferredSource, w_inferredTarget)\n",
    "            for metric in metric_list\n",
    "        ]\n",
    "        logging.info(\"Computed distances or similarities \" + str(link) + str(dist))\n",
    "        return functools.reduce(lambda a, b: a + b, dist)  # Always return a list\n",
    "\n",
    "    def computeDistanceMetric(self, links, metric_list):\n",
    "        \"\"\"It is computed the cosine similarity\"\"\"\n",
    "\n",
    "        metric_labels = [\n",
    "            self.dict_labels[metric] for metric in metric_list\n",
    "        ]  # tracking of the labels\n",
    "        distSim = [\n",
    "            [link[0], link[1], self.distance(metric_list, link)] for link in links\n",
    "        ]  # Return the link with metrics\n",
    "        distSim = [\n",
    "            [elem[0], elem[1]] + elem[2] for elem in distSim\n",
    "        ]  # Return the link with metrics\n",
    "\n",
    "        return distSim, functools.reduce(lambda a, b: a + b, metric_labels)\n",
    "\n",
    "    def InferDoc2Vec(self, steps=200):\n",
    "        \"\"\"Activate Inference on Target and Source Corpus\"\"\"\n",
    "        self.df_inferred_src = self.df_source.copy()\n",
    "        self.df_inferred_trg = self.df_target.copy()\n",
    "\n",
    "        self.df_inferred_src[\"inf-doc2vec\"] = [\n",
    "            self.new_model.infer_vector(artifact.split(), steps=steps)\n",
    "            for artifact in self.df_inferred_src[\"text\"].values\n",
    "        ]\n",
    "        self.df_inferred_trg[\"inf-doc2vec\"] = [\n",
    "            self.new_model.infer_vector(artifact.split(), steps=steps)\n",
    "            for artifact in self.df_inferred_trg[\"text\"].values\n",
    "        ]\n",
    "\n",
    "        logging.info(\"Infer Doc2Vec on Source and Target Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Doc2Vec SequenceVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec = Doc2VecSeqVect(params=doc2vec_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [step1]Apply Doc2Vec Inference\n",
    "doc2vec.InferDoc2Vec(steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.df_inferred_src.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_inferDoc2Vec_trg = inferDoc2Vec(df_target)\n",
    "# test_inferDoc2Vec_trg.head()\n",
    "doc2vec.df_inferred_trg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(\n",
    "    doc2vec.df_inferred_trg[\"inf-doc2vec\"][0], doc2vec.df_inferred_trg[\"inf-doc2vec\"][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [step 2]NonGroundTruth Computation\n",
    "metric_l = [\n",
    "    DistanceMetric.EUC,\n",
    "    DistanceMetric.COS,\n",
    "    DistanceMetric.MAN,\n",
    "]  # , SimilarityMetric.Pearson]\n",
    "doc2vec.ComputeDistanceArtifacts(sampling=False, samples=50, metric_list=metric_l)\n",
    "doc2vec.df_nonground_link.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [step 3]Saving Non-GroundTruth Links\n",
    "doc2vec.SaveLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Non-GroundTruth Links (change the timestamp with the assigned in the previous step)\n",
    "df_nonglinks_doc2vec = LoadLinks(timestamp=1594653325.258415, params=doc2vec_params)\n",
    "df_nonglinks_doc2vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [step 4]GroundTruthMatching Testing\n",
    "path_to_ground_truth = \"/tf/main/benchmarking/traceability/testbeds/groundtruth/english/[libest-ground-req-to-tc].txt\"\n",
    "doc2vec.MatchWithGroundTruth(path_to_ground_truth)\n",
    "doc2vec.df_ground_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [step 5]Saving GroundTruth Links\n",
    "doc2vec.SaveLinks(grtruth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Non-GroundTruth Links (change the timestamp with the assigned in the previous step)\n",
    "df_glinks_doc2vec = LoadLinks(\n",
    "    timestamp=1594653350.19946, params=doc2vec_params, grtruth=True\n",
    ")\n",
    "df_glinks_doc2vec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach Evaluation and Interpretation (doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervisedEvalDoc2vec = SupervisedVectorEvaluation(doc2vec, similarity=SimilarityMetric.EUC_sim)\n",
    "# supervisedEvalDoc2vec = SupervisedVectorEvaluation(doc2vec, similarity=SimilarityMetric.COS_sim)\n",
    "supervisedEvalDoc2vec = SupervisedVectorEvaluation(\n",
    "    doc2vec, similarity=SimilarityMetric.MAN_sim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisedEvalDoc2vec.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisedEvalDoc2vec.y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisedEvalDoc2vec.Compute_precision_recall_gain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisedEvalDoc2vec.Compute_avg_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisedEvalDoc2vec.Compute_roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distribution of similarities doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics\n",
    "filter_doc2vec = doc2vec.df_ground_link\n",
    "filter_doc2vec.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(filter_doc2vec[[SimilarityMetric.EUC_sim]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(filter_doc2vec[DistanceMetric.EUC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_doc2vec.hist(\n",
    "    column=[SimilarityMetric.EUC_sim, DistanceMetric.EUC],\n",
    "    color=\"k\",\n",
    "    bins=50,\n",
    "    figsize=[10, 5],\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate distance from similarity analysis here\n",
    "errors = filter_doc2vec[[SimilarityMetric.EUC_sim, DistanceMetric.EUC]].std()\n",
    "print(errors)\n",
    "filter_doc2vec[[SimilarityMetric.EUC_sim, DistanceMetric.EUC]].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_doc2vec.hist(\n",
    "    by=\"Linked?\", column=SimilarityMetric.EUC_sim, figsize=[10, 5], bins=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_doc2vec.hist(by=\"Linked?\", column=DistanceMetric.EUC, figsize=[10, 5], bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the distance from the similarity plot\n",
    "boxplot = filter_doc2vec.boxplot(\n",
    "    by=\"Linked?\", column=[SimilarityMetric.EUC_sim, DistanceMetric.EUC], figsize=[10, 5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = filter_doc2vec.boxplot(\n",
    "    by=\"Linked?\", column=[SimilarityMetric.EUC_sim], figsize=[10, 5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Doc2vec and Word2vec\n",
    "Please check this post for futher detatils [link](https://stats.stackexchange.com/questions/217614/intepreting-doc2vec-cosine-similarity-between-doc-vectors-and-word-vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nbdev_build_docs #<-------- [Activate when stable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds4se.mgmnt.prep.conv import *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
